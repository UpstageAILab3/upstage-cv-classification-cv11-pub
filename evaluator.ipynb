{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "\n",
    "# WandB 프로젝트 불러오기\n",
    "api = wandb.Api()\n",
    "runs = api.runs(\"document-classification\")\n",
    "\n",
    "# 각 지표를 담을 리스트 초기화\n",
    "run_data = []\n",
    "\n",
    "for run in runs:\n",
    "    # 각 run에서 필요한 지표를 추출\n",
    "    run_data.append({\n",
    "        \"run_name\": run.name,\n",
    "        \"train_loss\": run.summary.get(\"final_train_loss\"),\n",
    "        \"train_accuracy\": run.summary.get(\"final_train_accuracy\"),\n",
    "        \"train_f1\": run.summary.get(\"final_train_f1\"),\n",
    "        \"val_loss\": run.summary.get(\"final_valid_loss\"),\n",
    "        \"val_accuracy\": run.summary.get(\"final_valid_accuracy\"),\n",
    "        \"val_f1\": run.summary.get(\"final_valid_f1\"),\n",
    "        \"test_loss\": run.summary.get(\"final_test_loss\"),\n",
    "        \"test_accuracy\": run.summary.get(\"final_test_accuracy\"),\n",
    "        \"test_f1\": run.summary.get(\"final_test_f1\")\n",
    "    })\n",
    "\n",
    "# DataFrame으로 변환\n",
    "df = pd.DataFrame(run_data)\n",
    "\n",
    "# 각 지표의 중요도 설정 (가중치)\n",
    "# 여기서는 단순히 모든 지표를 동일하게 고려\n",
    "weights = {\n",
    "    \"train_loss\": -1,\n",
    "    \"train_accuracy\": 1,\n",
    "    \"train_f1\": 1,\n",
    "    \"val_loss\": -1,\n",
    "    \"val_accuracy\": 1,\n",
    "    \"val_f1\": 1,\n",
    "    \"test_loss\": -1,\n",
    "    \"test_accuracy\": 1,\n",
    "    \"test_f1\": 1\n",
    "}\n",
    "\n",
    "# 가중치를 이용하여 종합 점수 계산\n",
    "df[\"combined_score\"] = (\n",
    "    weights[\"train_loss\"] * df[\"train_loss\"] +\n",
    "    weights[\"train_accuracy\"] * df[\"train_accuracy\"] +\n",
    "    weights[\"train_f1\"] * df[\"train_f1\"] +\n",
    "    weights[\"val_loss\"] * df[\"val_loss\"] +\n",
    "    weights[\"val_accuracy\"] * df[\"val_accuracy\"] +\n",
    "    weights[\"val_f1\"] * df[\"val_f1\"] +\n",
    "    weights[\"test_loss\"] * df[\"test_loss\"] +\n",
    "    weights[\"test_accuracy\"] * df[\"test_accuracy\"] +\n",
    "    weights[\"test_f1\"] * df[\"test_f1\"]\n",
    ")\n",
    "\n",
    "# 종합 점수 기준 정렬\n",
    "sorted_df = df.sort_values(by=\"combined_score\", ascending=False)\n",
    "\n",
    "# 상위 모델 선택\n",
    "top_models = sorted_df.head(5)\n",
    "\n",
    "# 결과 출력\n",
    "print(top_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# WandB 프로젝트 불러오기\n",
    "api = wandb.Api()\n",
    "runs = api.runs(\"document-classification\")\n",
    "\n",
    "# 각 지표를 담을 리스트 초기화\n",
    "run_data = []\n",
    "\n",
    "for run in runs:\n",
    "    # 각 run에서 필요한 지표를 추출\n",
    "    run_data.append({\n",
    "        \"run_name\": run.name,\n",
    "        \"train_loss\": run.summary.get(\"final_train_loss\"),\n",
    "        \"train_accuracy\": run.summary.get(\"final_train_accuracy\"),\n",
    "        \"train_f1\": run.summary.get(\"final_train_f1\"),\n",
    "        \"val_loss\": run.summary.get(\"final_valid_loss\"),\n",
    "        \"val_accuracy\": run.summary.get(\"final_valid_accuracy\"),\n",
    "        \"val_f1\": run.summary.get(\"final_valid_f1\"),\n",
    "        \"test_loss\": run.summary.get(\"final_test_loss\"),\n",
    "        \"test_accuracy\": run.summary.get(\"final_test_accuracy\"),\n",
    "        \"test_f1\": run.summary.get(\"final_test_f1\")\n",
    "    })\n",
    "\n",
    "# DataFrame으로 변환\n",
    "df = pd.DataFrame(run_data)\n",
    "\n",
    "def calculate_updated_score(row):\n",
    "    # 평가 세트(valid + test) 성능 계산\n",
    "    eval_f1 = (row['val_f1'] + row['test_f1']) / 2\n",
    "    eval_accuracy = (row['val_accuracy'] + row['test_accuracy']) / 2\n",
    "    eval_loss = (row['val_loss'] + row['test_loss']) / 2\n",
    "\n",
    "    # 성능 점수 계산\n",
    "    performance_score = 0.5 * eval_f1 + 0.3 * eval_accuracy - 0.2 * eval_loss\n",
    "\n",
    "    # 과적합 점수 계산\n",
    "    overfitting_score = (row['train_accuracy'] - eval_accuracy) + (row['train_f1'] - eval_f1)\n",
    "    overfitting_penalty = 1 / (1 + np.exp(-5 * (overfitting_score - 0.1)))  # 시그모이드 함수\n",
    "\n",
    "    # 일관성 점수 계산 (valid와 test 간의 차이, 작을수록 좋음)\n",
    "    consistency_score = 1 / (1 + abs(row['val_f1'] - row['test_f1']) + abs(row['val_accuracy'] - row['test_accuracy']))\n",
    "\n",
    "    # 최종 점수 계산\n",
    "    final_score = performance_score * (1 - 0.3 * overfitting_penalty) * consistency_score\n",
    "\n",
    "    return final_score\n",
    "\n",
    "# 종합 점수 계산 및 정렬\n",
    "df['combined_score'] = df.apply(calculate_updated_score, axis=1)\n",
    "sorted_df = df.sort_values(by=\"combined_score\", ascending=False)\n",
    "\n",
    "# 상위 모델 선택\n",
    "top_models = sorted_df.head(5)\n",
    "\n",
    "# 결과 출력\n",
    "print(top_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# 클래스 이름 정의\n",
    "class_names = {\n",
    "    0: \"계좌번호(손글씨)\", 1: \"임신출산 진료비 지급 신청서\", 2: \"자동차 계기판\", 3: \"입퇴원 확인서\", 4: \"진단서\", \n",
    "    5: \"운전면허증\", 6: \"진료비영수증\", 7: \"통원/진료 확인서\", 8: \"주민등록증\", 9: \"여권\", \n",
    "    10: \"진료비 납입 확인서\", 11: \"약제비 영수증\", 12: \"처방전\", 13: \"이력서\", 14: \"소견서\", \n",
    "    15: \"자동차 등록증\", 16: \"자동차 번호판\"\n",
    "}\n",
    "\n",
    "def load_predictions(file_paths):\n",
    "    \"\"\"여러 모델의 예측 결과를 로드합니다.\"\"\"\n",
    "    predictions = {}\n",
    "    for path in file_paths:\n",
    "        model_name = os.path.basename(path).split('.')[0]\n",
    "        df = pd.read_csv(path)\n",
    "        # ID 컬럼 중복 제거 및 예측 컬럼 이름 변경\n",
    "        df = df[['ID', 'target']].rename(columns={'target': model_name})\n",
    "        predictions[model_name] = df\n",
    "    return predictions\n",
    "\n",
    "def find_different_predictions(predictions):\n",
    "    \"\"\"모든 모델에서 다르게 예측한 항목을 찾습니다.\"\"\"\n",
    "    # 모든 예측을 하나의 DataFrame으로 병합\n",
    "    all_predictions = predictions[list(predictions.keys())[0]]\n",
    "    for model, df in list(predictions.items())[1:]:\n",
    "        all_predictions = pd.merge(all_predictions, df, on='ID', suffixes=('', f'_{model}'))\n",
    "    \n",
    "    # 예측 컬럼만 선택\n",
    "    prediction_columns = [col for col in all_predictions.columns if col != 'ID']\n",
    "    \n",
    "    # 예측이 다른 행만 선택\n",
    "    different_predictions = all_predictions[all_predictions[prediction_columns].nunique(axis=1) > 1]\n",
    "    return different_predictions\n",
    "\n",
    "def calculate_macro_f1(ground_truth, predictions):\n",
    "    \"\"\"Macro F1 점수를 계산합니다.\"\"\"\n",
    "    return f1_score(ground_truth, predictions, average='macro')\n",
    "\n",
    "def plot_error_distribution(ground_truth, predictions):\n",
    "    \"\"\"각 클래스별 오류 예측 개수를 bar plot으로 표시합니다.\"\"\"\n",
    "    error_counts = {i: 0 for i in range(len(class_names))}  # 모든 클래스에 대해 초기화\n",
    "    for gt, pred in zip(ground_truth, predictions):\n",
    "        if gt != pred:\n",
    "            error_counts[gt] += 1\n",
    "    \n",
    "    classes = sorted(error_counts.keys())\n",
    "    counts = [error_counts[c] for c in classes]\n",
    "    class_labels = [f\"{c}\\n{class_names[c]}\" for c in classes]\n",
    "    \n",
    "    # 나눔 폰트 설정\n",
    "    font_path = './font/NanumGothic.otf'\n",
    "    font_prop = FontProperties(fname=font_path)\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    bars = plt.bar(class_labels, counts)\n",
    "    plt.title(\"오류 예측 개수 (클래스별)\", fontproperties=font_prop, fontsize=16)\n",
    "    plt.xlabel(\"클래스\", fontproperties=font_prop, fontsize=14)\n",
    "    plt.ylabel(\"오류 개수\", fontproperties=font_prop, fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='center')\n",
    "    \n",
    "    # x축 레이블에 폰트 적용\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels(class_labels, fontproperties=font_prop, fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 각 막대 위에 값 표시\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{height}',\n",
    "                 ha='center', va='bottom', fontproperties=font_prop)\n",
    "    \n",
    "    plt.show()  \n",
    "\n",
    "def display_images_and_predictions(different_predictions, image_dir, ground_truth_name, prediction_name, class_filter=None, max_images_per_class=3):\n",
    "    \"\"\"다르게 예측된 항목의 이미지와 예측 결과를 표시합니다.\"\"\"\n",
    "    # 나눔 폰트 설정\n",
    "    font_path = './font/NanumGothic.otf'\n",
    "    font_prop = FontProperties(fname=font_path)\n",
    "    \n",
    "    # 클래스별로 이미지 분류\n",
    "    class_images = {c: [] for c in range(len(class_names))}\n",
    "    for idx, row in different_predictions.iterrows():\n",
    "        ground_truth = row[ground_truth_name]\n",
    "        if class_filter is None or ground_truth in class_filter:\n",
    "            class_images[ground_truth].append(row)\n",
    "    \n",
    "    # 표시할 이미지 선택\n",
    "    images_to_display = []\n",
    "    for c, imgs in class_images.items():\n",
    "        if class_filter is None or c in class_filter:\n",
    "            images_to_display.extend(imgs[:max_images_per_class])\n",
    "    \n",
    "    # 이미지 표시\n",
    "    num_images = len(images_to_display)\n",
    "    rows = (num_images - 1) // 4 + 1\n",
    "    fig, axs = plt.subplots(rows, 4, figsize=(20, 5*rows))\n",
    "    \n",
    "    for i, row in enumerate(images_to_display):\n",
    "        ax = axs[i//4, i%4] if rows > 1 else axs[i%4]\n",
    "        \n",
    "        image_id = row['ID']\n",
    "        ground_truth = row[ground_truth_name]\n",
    "        prediction = row[prediction_name]\n",
    "        image_path = os.path.join(image_dir, image_id)\n",
    "        \n",
    "        if os.path.exists(image_path):\n",
    "            img = Image.open(image_path)\n",
    "            img = img.resize((300, 300), Image.LANCZOS)\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            id = f\"ID: {image_id}\"\n",
    "            comparison_text = f\"정답: {ground_truth} ({class_names[ground_truth]})\\n예측: {prediction} ({class_names[prediction]})\"\n",
    "            ax.set_title(f\"{id}\\n{comparison_text}\", fontproperties=font_prop, fontsize=10)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f\"Image not found\\nfor ID: {image_id}\", ha='center', va='center')\n",
    "    \n",
    "    # 빈 서브플롯 제거\n",
    "    for i in range(num_images, rows*4):\n",
    "        ax = axs[i//4, i%4] if rows > 1 else axs[i%4]\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"총 {num_images}개의 이미지가 표시되었습니다.\")\n",
    "\n",
    "# # 예측 파일 경로\n",
    "# file_paths = [\n",
    "#     \"output/9609.csv\",\n",
    "#     \"output/20240808-194900_final.pt.csv\",\n",
    "# ]\n",
    "\n",
    "# # 이미지 디렉토리 경로\n",
    "# image_dir = \"data/test\"\n",
    "\n",
    "# # 예측 로드\n",
    "# predictions = load_predictions(file_paths)\n",
    "\n",
    "# # 다른 예측 찾기\n",
    "# different_predictions = find_different_predictions(predictions)\n",
    "\n",
    "# # # 결과 출력\n",
    "# # print(different_predictions)\n",
    "\n",
    "# # Macro F1 점수 계산\n",
    "# ground_truth_name = os.path.basename(file_paths[0]).split('.')[0]\n",
    "# prediction_name = os.path.basename(file_paths[-1]).split('.')[0]\n",
    "# ground_truth = predictions[ground_truth_name][ground_truth_name]\n",
    "# prediction = predictions[prediction_name][prediction_name]\n",
    "# macro_f1 = calculate_macro_f1(ground_truth, prediction)\n",
    "# print(f\"Macro F1 Score: {macro_f1}\")\n",
    "\n",
    "# # 오류 분포 그래프 표시\n",
    "# plot_error_distribution(ground_truth, prediction)\n",
    "\n",
    "# # 모든 클래스에 대해 클래스당 1개씩 이미지 표시\n",
    "# # display_images_and_predictions(different_predictions, image_dir, ground_truth_name, prediction_name, class_filter=None, max_images_per_class=2)\n",
    "\n",
    "# # 특정 클래스(예: 0, 1, 2)에 대해 클래스당 최대 3개씩 이미지 표시\n",
    "# display_images_and_predictions(different_predictions, image_dir, ground_truth_name, prediction_name, class_filter=[3, 7, 14], max_images_per_class=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
