{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OliaDaX_lwou"
   },
   "source": [
    "## Contents\n",
    "- Import Library & Define Functions\n",
    "- Hyper-parameters\n",
    "- Load Data\n",
    "- Train Model\n",
    "- Inference & Save File\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## Import Library & Define Functions\n",
    "* 학습 및 추론에 필요한 라이브러리를 로드합니다.\n",
    "* 학습 및 추론에 필요한 함수와 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "from zoneinfo import ZoneInfo\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time = datetime.fromtimestamp(time.time(), tz=ZoneInfo(\"Asia/Seoul\")).strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_time\n",
    "\n",
    "wandb.init(project=\"document-classification-renew\", name=f\"run-{train_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스를 정의합니다.\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.data = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.data.iloc[idx, 0])\n",
    "        image = np.array(Image.open(img_name).convert('RGB'))\n",
    "        label = self.data.iloc[idx, 1]\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## Hyper-parameters\n",
    "* 학습 및 추론에 필요한 하이퍼파라미터들을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model config\n",
    "MODEL_NAME = 'tf_efficientnetv2_s.in21k_ft_in1k'\n",
    "\n",
    "# training config\n",
    "IMG_SIZE = 384\n",
    "LR = 1e-3\n",
    "WD = 1e-4\n",
    "EPOCHS = 25\n",
    "PATIENCE = 5\n",
    "WARM_UP_EPOCHS = 3\n",
    "WARM_UP_LR = 1e-5\n",
    "MIN_LR = 1e-6\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "NUM_WORKERS = 16\n",
    "DELTA = 1e-4\n",
    "SHAPE = 'RESIZE' # 'RESIZE' or 'PADDING'\n",
    "DROP_RATE=0.2\n",
    "\n",
    "# label smoothing\n",
    "SA = 0.05 # 강도\n",
    "ST = 0.9 # 적용 기준\n",
    "\n",
    "wandb.config.update({\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"img_size\": IMG_SIZE,\n",
    "    \"learning_rate\": LR,\n",
    "    'weight_decay': WD,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"num_workers\": NUM_WORKERS,\n",
    "    'patience': PATIENCE,\n",
    "    'delta': DELTA,\n",
    "    'shape': SHAPE,\n",
    "    'drop_rate': DROP_RATE,\n",
    "    'smoothing_alpha': SA,\n",
    "    'smoothing_threshold': ST,\n",
    "})\n",
    "\n",
    "# 데이터셋\n",
    "TRAIN_CSV_FILE = 'train_temp_fixed_augmented_balanced_150.csv'\n",
    "TRAIN_IMG_DIR = 'train_augmented_balanced_150'\n",
    "TEST_IMG_DIR = \"test\"\n",
    "wandb.log({\n",
    "    'train_csv_file' : TRAIN_CSV_FILE,\n",
    "    \"train_dir\" : TRAIN_IMG_DIR,\n",
    "    \"test_dir\" : TEST_IMG_DIR,\n",
    "})\n",
    "\n",
    "TRAIN_RATIO = 1.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## Load Data\n",
    "* 학습, 테스트 데이터셋과 로더를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "if SHAPE == 'PADDING':\n",
    "    transform = A.Compose([\n",
    "        A.LongestMaxSize(max_size=IMG_SIZE),\n",
    "        A.PadIfNeeded(min_height=IMG_SIZE, min_width=IMG_SIZE, border_mode=cv2.BORDER_CONSTANT, value=[124, 116, 104]), # 평균 색상으로 패딩\n",
    "        normalize,\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "else:\n",
    "    transform = A.Compose([\n",
    "        A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "        normalize,\n",
    "        ToTensorV2(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(csv_file, img_dir, train_ratio=0.8):\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # 원본 이미지 ID 추출 (확장자 제거)\n",
    "    original_df = df[df['is_augmented'] == False].copy()\n",
    "    original_df['original_id'] = original_df['ID'].apply(lambda x: os.path.splitext(x)[0].split('.')[0])\n",
    "\n",
    "    if train_ratio >= 1.0 :\n",
    "        train_df, valid_df = original_df, original_df\n",
    "    else:\n",
    "        # Stratified split : 원본 이미지만 선택하여 분할\n",
    "        train_df, valid_df = train_test_split(original_df, train_size=train_ratio, stratify=original_df['target'], random_state=SEED)\n",
    "\n",
    "    # 증강된 이미지 포함\n",
    "    df = df[df['is_augmented'] == True]\n",
    "    \n",
    "    train = pd.concat([train_df, df[df['ID'].str.contains('|'.join(train_df['original_id']))]])\n",
    "    valid = pd.concat([valid_df, df[df['ID'].str.contains('|'.join(valid_df['original_id']))]])\n",
    "\n",
    "    train_count = len(train)\n",
    "    valid_count = len(valid)\n",
    "    wandb.log({\n",
    "        \"train_ratio\" : train_ratio,\n",
    "        \"train_count\" : train_count,\n",
    "        \"valid_count\" : valid_count\n",
    "    })\n",
    "\n",
    "    print(f\"Train set: {train_count} images (Original: {len(train_df)}, Augmented: {train_count - len(train_df)})\")\n",
    "    print(f\"Valid set: {valid_count} images (Original: {len(valid_df)}, Augmented: {valid_count - len(valid_df)})\")\n",
    "    \n",
    "    print(\"\\nClass distribution:\")\n",
    "    print(\"Train:\", train['target'].value_counts(normalize=True))\n",
    "    print(\"Valid:\", valid['target'].value_counts(normalize=True))\n",
    "\n",
    "    # ImageDataset 생성\n",
    "    train_dataset = ImageDataset(train, img_dir, transform=transform)\n",
    "    valid_dataset = ImageDataset(valid, img_dir, transform=transform)\n",
    "    \n",
    "    return train_dataset, valid_dataset\n",
    "\n",
    "train_dataset, val_dataset = split_dataset(csv_file=f\"data/{TRAIN_CSV_FILE}\", img_dir=f\"data/{TRAIN_IMG_DIR}\", train_ratio=TRAIN_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700315112808,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "INxdmsStop2L",
    "outputId": "49f0d412-8ce6-4d2f-ae78-d5cf3d056340"
   },
   "outputs": [],
   "source": [
    "test_dataset = ImageDataset(\n",
    "    pd.read_csv(\"data/sample_submission.csv\"),\n",
    "    f\"data/{TEST_IMG_DIR}\",\n",
    "    transform\n",
    ")\n",
    "print(f\"Test set: {len(test_dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112808,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "_sO03fWaQj1h"
   },
   "outputs": [],
   "source": [
    "# DataLoader 정의\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True) # 마지막 배치가 batch_size보다 작으면 버림\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## Train Model\n",
    "* 모델을 로드하고, 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(loader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    total_loss /= len(loader)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    return total_loss, acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif np.isclose(score, self.best_score, atol=self.delta) or score < self.best_score:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one epoch 학습을 위한 함수입니다.\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    # wandb에 훈련 메트릭 로깅\n",
    "    wandb.log(ret)\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def genOptimizer(model):\n",
    "    return AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "\n",
    "def genScheduler(optimizer):    \n",
    "    return CosineLRScheduler(\n",
    "        optimizer,\n",
    "        t_initial=EPOCHS,\n",
    "        lr_min=MIN_LR,\n",
    "        warmup_lr_init=WARM_UP_LR,\n",
    "        warmup_t=WARM_UP_EPOCHS,\n",
    "        cycle_limit=1,\n",
    "        t_in_epochs=True,\n",
    "    )\n",
    "\n",
    "def train(loader, model, optimizer, scheduler):\n",
    "    model_file_path = f'model/{train_time}_best.pt'\n",
    "\n",
    "    # Early stopping 설정\n",
    "    early_stopping = EarlyStopping(PATIENCE, verbose=True, delta=DELTA, path=model_file_path)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        ret = train_one_epoch(loader, model, optimizer, loss_fn, device=DEVICE)\n",
    "        val_loss, val_acc, val_f1 = evaluate(val_loader, model, loss_fn, DEVICE)\n",
    "        scheduler.step(epoch)\n",
    "        \n",
    "        ret['epoch_count'] = epoch+1\n",
    "        ret['val_loss'] = val_loss\n",
    "        ret['val_acc'] = val_acc\n",
    "        ret['val_f1'] = val_f1\n",
    "\n",
    "        # wandb에 에폭 로깅\n",
    "        wandb.log(ret)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        print(f\"Train - Loss: {ret['train_loss']:.4f}, Acc: {ret['train_acc']:.4f}, Macro F1: {ret['train_f1']:.4f}\")\n",
    "        print(f\"Val - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, Macro F1: {val_f1:.4f}\")\n",
    "\n",
    "        # Early stopping 체크\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    # 최종 모델 저장\n",
    "    model_file_path = f'model/{train_time}_final.pt'\n",
    "    torch.save(model.state_dict(), model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = timm.create_model(\n",
    "    MODEL_NAME,\n",
    "    pretrained=True,\n",
    "    num_classes=17,\n",
    "    drop_rate=DROP_RATE\n",
    ").to(DEVICE)\n",
    "\n",
    "train_optimizer = genOptimizer(model)\n",
    "wandb.log({\"optimizer\" : {train_optimizer.__class__.__name__}})\n",
    "train(train_loader, model, train_optimizer, genScheduler(train_optimizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'model/{train_time}_best.pt'))\n",
    "model.to(DEVICE)\n",
    "\n",
    "# 학습 후 각 데이터셋에 대한 평가\n",
    "train_results = evaluate(train_loader, model, loss_fn, DEVICE)\n",
    "valid_results = evaluate(val_loader, model, loss_fn, DEVICE)\n",
    "\n",
    "total_results = {\n",
    "    \"final_train_loss\": train_results[0],\n",
    "    \"final_train_accuracy\": train_results[1],\n",
    "    \"final_train_f1\": train_results[2],\n",
    "    \"final_valid_loss\": valid_results[0],\n",
    "    \"final_valid_accuracy\": valid_results[1],\n",
    "    \"final_valid_f1\": valid_results[2]\n",
    "}\n",
    "\n",
    "# 평가 결과 로깅\n",
    "print(total_results)\n",
    "wandb.log(total_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_and_visualize_errors(model, dataloader, device, num_samples=10):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    error_images = []\n",
    "    error_preds = []\n",
    "    error_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # 오류 식별\n",
    "            errors = preds != labels\n",
    "            error_images.extend(images[errors].cpu())\n",
    "            error_preds.extend(preds[errors].cpu().numpy())\n",
    "            error_labels.extend(labels[errors].cpu().numpy())\n",
    "\n",
    "    # 정확도 계산\n",
    "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # 오류 시각화\n",
    "    num_samples = min(num_samples, len(error_images))\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(20, 4))\n",
    "    for i in range(num_samples):\n",
    "        img = error_images[i].permute(1, 2, 0).numpy()\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Pred: {error_preds[i]}, True: {error_labels[i]}\")\n",
    "        axes[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 혼동 행렬 생성 및 시각화\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "    return error_images, error_preds, error_labels\n",
    "\n",
    "# 오류 분석\n",
    "def analyze_errors(error_preds, error_labels):\n",
    "    error_pairs = list(zip(error_preds, error_labels))\n",
    "    error_counts = {}\n",
    "    for pred, true in error_pairs:\n",
    "        key = f\"Pred: {pred}, True: {true}\"\n",
    "        error_counts[key] = error_counts.get(key, 0) + 1\n",
    "    \n",
    "    print(\"Most common errors:\")\n",
    "    for error, count in sorted(error_counts.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "        print(f\"{error}: {count} times\")\n",
    "\n",
    "# 검증 세트에 대한 평가 및 오류 시각화\n",
    "print(\"Valid Set Errors:\")\n",
    "val_errors = evaluate_and_visualize_errors(model, val_loader, DEVICE)\n",
    "\n",
    "print(\"Valid Set Error Analysis:\")\n",
    "analyze_errors(val_errors[1], val_errors[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_predictions(predictions, alpha=0.1):\n",
    "    num_classes = predictions.shape[1]\n",
    "    smoothed = alpha / num_classes + (1 - alpha) * predictions\n",
    "    return smoothed\n",
    "\n",
    "def pred(model_file_name, alpha=0.1, threshold=0.5):\n",
    "    print(f\"Generating predictions for submission...{model_file_name}\")\n",
    "    preds_list = []\n",
    "    smooth_preds_list = []\n",
    "    probs_list = []\n",
    "    \n",
    "    model.load_state_dict(torch.load(f'model/{model_file_name}'))\n",
    "    model.eval()\n",
    "    \n",
    "    for image, _ in tqdm(test_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = model(image)\n",
    "        \n",
    "        # 예측\n",
    "        probs = torch.softmax(preds, dim=1).detach().cpu().numpy()\n",
    "        preds_list.extend(np.argmax(probs, axis=1))\n",
    "        probs_list.extend(probs)\n",
    "    \n",
    "    probs_array = np.array(probs_list)\n",
    "    max_probs = np.max(probs_array, axis=1)\n",
    "    \n",
    "    # threshold를 넘는 예측에 대해서만 라벨 스무딩 적용\n",
    "    smooth_probs = np.where(\n",
    "        max_probs[:, np.newaxis] >= threshold,\n",
    "        smooth_predictions(probs_array, alpha),\n",
    "        probs_array\n",
    "    )\n",
    "    \n",
    "    smooth_preds_list = np.argmax(smooth_probs, axis=1)\n",
    "    normal_preds_list = np.array(preds_list)\n",
    "\n",
    "    for orig, smooth, orig_prob, smooth_prob in zip(normal_preds_list[:10], smooth_preds_list[:10], probs_array[:10], smooth_probs[:10]):\n",
    "        print(f\"Original: {orig} (max prob: {np.max(orig_prob):.4f}), Smoothed: {smooth} (max prob: {np.max(smooth_prob):.4f})\")\n",
    "    \n",
    "    return normal_preds_list, smooth_preds_list, probs_array, smooth_probs\n",
    "\n",
    "best_preds, best_smooth_preds, best_probs, best_smooth_probs = pred(f'{train_time}_best.pt', alpha=SA, threshold=ST)\n",
    "final_preds, final_smooth_preds, final_probs, final_smooth_probs = pred(f'{train_time}_final.pt', alpha=SA, threshold=ST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import evaluator\n",
    "\n",
    "def calc(path):\n",
    "    file_paths = [\n",
    "        \"output/9766.csv\",\n",
    "        path\n",
    "    ]\n",
    "\n",
    "    predictions = evaluator.load_predictions(file_paths)\n",
    "\n",
    "    # 다른 예측 찾기\n",
    "    different_predictions = evaluator.find_different_predictions(predictions)\n",
    "\n",
    "    # 결과 출력\n",
    "    print(different_predictions)\n",
    "\n",
    "    # Macro F1 점수 계산\n",
    "    ground_truth_name = os.path.basename(file_paths[0]).split('.')[0]\n",
    "    prediction_name = os.path.basename(file_paths[-1]).split('.')[0]\n",
    "    ground_truth = predictions[ground_truth_name][ground_truth_name]\n",
    "    prediction = predictions[prediction_name][prediction_name]\n",
    "    macro_f1 = evaluator.calculate_macro_f1(ground_truth, prediction)\n",
    "    print(f\"Macro F1 Score: {macro_f1}\")\n",
    "\n",
    "    return [macro_f1, different_predictions, ground_truth_name, prediction_name, ground_truth, prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pred_csv(preds, file_name):\n",
    "    df = pd.read_csv(\"data/sample_submission.csv\")\n",
    "    df['target'] = preds\n",
    "    path = os.path.join('output_temp', file_name)\n",
    "    df.to_csv(path, index=False)\n",
    "    return path, df\n",
    "\n",
    "best_datas = gen_pred_csv(best_preds, f'{train_time}_best.csv')\n",
    "best_smooth_datas = gen_pred_csv(best_smooth_preds, f'{train_time}_best_smooth.csv')\n",
    "final_datas = gen_pred_csv(final_preds, f'{train_time}_final.csv')\n",
    "final_smooth_datas = gen_pred_csv(final_smooth_preds, f'{train_time}_final_smooth.csv')\n",
    "\n",
    "best_predictions = [calc(best_datas[0]), best_datas[1]]\n",
    "best_smooth_predictions = [calc(best_smooth_datas[0]), best_smooth_datas[1]]\n",
    "final_predictions = [calc(final_datas[0]), final_datas[1]]\n",
    "final_smooth_predictions = [calc(final_smooth_datas[0]), final_smooth_datas[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_results(best, final, best_smooth, final_smooth):\n",
    "    print(f\"Best F1: {best[0]:.4f}, Final F1: {final[0]:.4f}\")\n",
    "    print(f\"Best Smooth F1: {best_smooth[0]:.4f}, Final Smooth F1: {final_smooth[0]:.4f}\")\n",
    "    \n",
    "    wandb.log({\n",
    "        \"best f1\": best[0],\n",
    "        \"final f1\": final[0],\n",
    "        \"best smooth f1\": best_smooth[0],\n",
    "        \"final smooth f1\": final_smooth[0]\n",
    "    })\n",
    "\n",
    "def select_best_prediction(best, final, best_smooth, final_smooth):\n",
    "    all_predictions = [\n",
    "        (\"Best\", best[0][0], best),\n",
    "        (\"Final\", final[0][0], final),\n",
    "        (\"Best Smooth\", best_smooth[0][0], best_smooth),\n",
    "        (\"Final Smooth\", final_smooth[0][0], final_smooth)\n",
    "    ]\n",
    "    \n",
    "    best_name, best_f1, param = max(all_predictions, key=lambda x: x[1])\n",
    "    \n",
    "    print(f\"Selected prediction: {best_name} (F1: {best_f1:.4f})\")\n",
    "    return best_f1, param\n",
    "\n",
    "# 결과 로깅\n",
    "log_results(best_predictions[0], final_predictions[0], best_smooth_predictions[0], final_smooth_predictions[0])\n",
    "\n",
    "# 최상의 예측 선택\n",
    "selected_prediction = select_best_prediction(best_predictions, final_predictions, best_smooth_predictions, final_smooth_predictions)\n",
    "predictions = selected_prediction[1][0]\n",
    "pred_df = selected_prediction[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315238836,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "VDBXQqAzVvLY"
   },
   "outputs": [],
   "source": [
    "sample_submission_df = pd.read_csv(\"data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1700315244710,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "ePx2vCELVnuS"
   },
   "outputs": [],
   "source": [
    "submission_file_path = os.path.join('output', f'{train_time}.csv')\n",
    "sample_submission_df.to_csv(submission_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import evaluator\n",
    "\n",
    "# 이미지 디렉토리 경로\n",
    "image_dir = test_dataset.img_dir\n",
    "\n",
    "# 예측 로드\n",
    "macro_f1 = predictions[0]\n",
    "different_predictions = predictions[1]\n",
    "ground_truth_name = predictions[2]\n",
    "prediction_name = predictions[3]\n",
    "ground_truth = predictions[4]\n",
    "prediction = predictions[5]\n",
    "\n",
    "# 오류 분포 그래프 표시\n",
    "evaluator.plot_error_distribution(ground_truth, prediction)\n",
    "\n",
    "# 모든 클래스에 대해 클래스당 1개씩 이미지 표시\n",
    "# evaluator.display_images_and_predictions(different_predictions, image_dir, ground_truth_name, prediction_name, class_filter=None, max_images_per_class=2)\n",
    "\n",
    "# 특정 클래스(예: 0, 1, 2)에 대해 클래스당 최대 3개씩 이미지 표시\n",
    "evaluator.display_images_and_predictions(different_predictions, image_dir, ground_truth_name, prediction_name, class_filter=[3, 7, 14], max_images_per_class=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"prov macro_f1 : {macro_f1}\")\n",
    "wandb.log({\"prov f1\": macro_f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
