{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OliaDaX_lwou"
   },
   "source": [
    "## Contents\n",
    "- Import Library & Define Functions\n",
    "- Hyper-parameters\n",
    "- Load Data\n",
    "- Train Model\n",
    "- Inference & Save File\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## Import Library & Define Functions\n",
    "* 학습 및 추론에 필요한 라이브러리를 로드합니다.\n",
    "* 학습 및 추론에 필요한 함수와 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "from zoneinfo import ZoneInfo\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/projects/document-classification/wandb/run-20240731_114356-ian4gr22</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/upstage-ai-lab-3rd-cv11/document-classification/runs/ian4gr22' target=\"_blank\">run-20240731-204356</a></strong> to <a href='https://wandb.ai/upstage-ai-lab-3rd-cv11/document-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/upstage-ai-lab-3rd-cv11/document-classification' target=\"_blank\">https://wandb.ai/upstage-ai-lab-3rd-cv11/document-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/upstage-ai-lab-3rd-cv11/document-classification/runs/ian4gr22' target=\"_blank\">https://wandb.ai/upstage-ai-lab-3rd-cv11/document-classification/runs/ian4gr22</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/upstage-ai-lab-3rd-cv11/document-classification/runs/ian4gr22?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ff4b8c09780>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_time = datetime.fromtimestamp(time.time(), tz=ZoneInfo(\"Asia/Seoul\")).strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_time\n",
    "\n",
    "wandb.init(project=\"document-classification\", name=f\"run-{train_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1700314772722,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "Hyl8oAy6TZAu"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 클래스를 정의합니다.\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1700315066028,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "kTECBJfVTbdl"
   },
   "outputs": [],
   "source": [
    "# one epoch 학습을 위한 함수입니다.\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    # wandb에 훈련 메트릭 로깅\n",
    "    wandb.log(ret)\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## Hyper-parameters\n",
    "* 학습 및 추론에 필요한 하이퍼파라미터들을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = 'data/'\n",
    "\n",
    "# model config\n",
    "model_name = 'efficientnet_b0'\n",
    "\n",
    "# training config\n",
    "img_size = 224\n",
    "LR = 1e-3\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 0\n",
    "\n",
    "retrain_full_dataset = False # 최종 예측 시 전체 train 데이터로 재학습할지 여부\n",
    "reinitialize_model = False # 최종 예측 재학습 시 모델 초기화할지 여부\n",
    "\n",
    "# 설정 로깅\n",
    "wandb.config.update({\n",
    "    \"model\": model_name,\n",
    "    \"img_size\": img_size,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"retrain_full_dataset\": retrain_full_dataset,\n",
    "    \"reinitialize_model\": reinitialize_model\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## Load Data\n",
    "* 학습, 테스트 데이터셋과 로더를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "llh5C7ZKoq2S"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# augmentation을 위한 transform 코드\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.GaussNoise(p=0.2),\n",
    "    A.Cutout(num_holes=8, max_h_size=8, max_w_size=8, p=0.3),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# test image 변환을 위한 transform 코드\n",
    "pred_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_dataset_split(train_csv_path, img_dir, trn_transform, tst_transform, train_size=0.7, val_size=0.15, test_size=0.15, random_state=42):\n",
    "    # CSV 파일 읽기\n",
    "    train_df = pd.read_csv(train_csv_path)\n",
    "    \n",
    "    # 첫 번째 split: 훈련 세트와 나머지(검증+테스트) 세트로 분할\n",
    "    train_df, temp_df = train_test_split(\n",
    "        train_df, \n",
    "        train_size=train_size, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # 두 번째 split: 나머지를 검증 세트와 테스트 세트로 분할\n",
    "    val_size_adjusted = val_size / (val_size + test_size)\n",
    "    val_df, test_df = train_test_split(\n",
    "        temp_df, \n",
    "        train_size=val_size_adjusted, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    print(f\"훈련 세트: {len(train_df)} 샘플\")\n",
    "    print(f\"검증 세트: {len(val_df)} 샘플\")\n",
    "    print(f\"테스트 세트: {len(test_df)} 샘플\")\n",
    "    \n",
    "    # 각 데이터프레임을 임시 CSV 파일로 저장\n",
    "    train_df.to_csv('temp_train.csv', index=False)\n",
    "    val_df.to_csv('temp_val.csv', index=False)\n",
    "    test_df.to_csv('temp_test.csv', index=False)\n",
    "    \n",
    "    # ImageDataset 생성\n",
    "    train_dataset = ImageDataset('temp_train.csv', img_dir, transform=trn_transform)\n",
    "    val_dataset = ImageDataset('temp_val.csv', img_dir, transform=tst_transform)\n",
    "    test_dataset = ImageDataset('temp_test.csv', img_dir, transform=tst_transform)\n",
    "    \n",
    "    # 임시 파일 삭제\n",
    "    os.remove('temp_train.csv')\n",
    "    os.remove('temp_val.csv')\n",
    "    os.remove('temp_test.csv')\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700315112808,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "INxdmsStop2L",
    "outputId": "49f0d412-8ce6-4d2f-ae78-d5cf3d056340"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트: 1099 샘플\n",
      "검증 세트: 235 샘플\n",
      "테스트 세트: 236 샘플\n",
      "1099 235 236 3140\n"
     ]
    }
   ],
   "source": [
    "# Dataset 정의\n",
    "train_dataset, val_dataset, test_dataset = random_dataset_split(\n",
    "    'data/train.csv',\n",
    "    'data/train/',\n",
    "    train_transform,\n",
    "    pred_transform\n",
    ")\n",
    "\n",
    "pred_dataset = ImageDataset(\n",
    "    \"data/sample_submission.csv\",\n",
    "    \"data/test/\",\n",
    "    transform=pred_transform\n",
    ")\n",
    "\n",
    "print(len(train_dataset), len(val_dataset), len(test_dataset), len(pred_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112808,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "_sO03fWaQj1h"
   },
   "outputs": [],
   "source": [
    "# DataLoader 정의\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "pred_loader = DataLoader(\n",
    "    pred_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## Train Model\n",
    "* 모델을 로드하고, 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = timm.create_model(\n",
    "    model_name,\n",
    "    pretrained=True,\n",
    "    num_classes=17,\n",
    "    drop_rate=0.3\n",
    ").to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6774: 100%|██████████| 35/35 [00:06<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.9841\n",
      "train_acc: 0.7043\n",
      "train_f1: 0.6744\n",
      "epoch: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6178: 100%|██████████| 35/35 [00:06<00:00,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.3511\n",
      "train_acc: 0.8954\n",
      "train_f1: 0.8840\n",
      "epoch: 1.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4630: 100%|██████████| 35/35 [00:06<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.2392\n",
      "train_acc: 0.9318\n",
      "train_f1: 0.9274\n",
      "epoch: 2.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1936: 100%|██████████| 35/35 [00:06<00:00,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.2140\n",
      "train_acc: 0.9254\n",
      "train_f1: 0.9171\n",
      "epoch: 3.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5089: 100%|██████████| 35/35 [00:06<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.1690\n",
      "train_acc: 0.9500\n",
      "train_f1: 0.9471\n",
      "epoch: 4.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0564: 100%|██████████| 35/35 [00:06<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.1248\n",
      "train_acc: 0.9536\n",
      "train_f1: 0.9530\n",
      "epoch: 5.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3440: 100%|██████████| 35/35 [00:06<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.1499\n",
      "train_acc: 0.9591\n",
      "train_f1: 0.9570\n",
      "epoch: 6.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0138: 100%|██████████| 35/35 [00:06<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.0810\n",
      "train_acc: 0.9700\n",
      "train_f1: 0.9689\n",
      "epoch: 7.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0390: 100%|██████████| 35/35 [00:06<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.0577\n",
      "train_acc: 0.9800\n",
      "train_f1: 0.9785\n",
      "epoch: 8.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0117: 100%|██████████| 35/35 [00:06<00:00,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.0522\n",
      "train_acc: 0.9763\n",
      "train_f1: 0.9734\n",
      "epoch: 9.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    ret = train_one_epoch(train_loader, model, optimizer, loss_fn, device=device)\n",
    "    ret['epoch'] = epoch\n",
    "\n",
    "    # wandb에 에폭 로깅\n",
    "    wandb.log({\"epoch\": epoch})\n",
    "\n",
    "    log = \"\"\n",
    "    for k, v in ret.items():\n",
    "      log += f\"{k}: {v:.4f}\\n\"\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 35/35 [00:05<00:00,  6.52it/s]\n",
      "Evaluating: 100%|██████████| 8/8 [00:00<00:00,  8.43it/s]\n",
      "Evaluating: 100%|██████████| 8/8 [00:00<00:00,  8.44it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, targets in tqdm(loader, desc=\"Evaluating\"):\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            all_preds.extend(preds.argmax(dim=1).cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "\n",
    "    # wandb에 평가 메트릭 로깅\n",
    "    results = {\n",
    "        \"loss\": avg_loss,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "    wandb.log(results)\n",
    "\n",
    "    return avg_loss, accuracy, f1\n",
    "\n",
    "# 학습 후 각 데이터셋에 대한 평가\n",
    "model.to(device)\n",
    "train_results = evaluate(train_loader, model, loss_fn, device)\n",
    "valid_results = evaluate(val_loader, model, loss_fn, device)\n",
    "test_results = evaluate(test_loader, model, loss_fn, device)\n",
    "\n",
    "# 평가 결과 로깅\n",
    "wandb.log({\n",
    "    \"final_train_loss\": train_results[0],\n",
    "    \"final_train_accuracy\": train_results[1],\n",
    "    \"final_train_f1\": train_results[2],\n",
    "    \"final_valid_loss\": valid_results[0],\n",
    "    \"final_valid_accuracy\": valid_results[1],\n",
    "    \"final_valid_f1\": valid_results[2],\n",
    "    \"final_test_loss\": test_results[0],\n",
    "    \"final_test_accuracy\": test_results[1],\n",
    "    \"final_test_f1\": test_results[2]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 성능 해석:\n",
      "\n",
      "훈련 세트 - Loss: 0.0192, Accuracy: 0.9927, F1: 0.9925\n",
      "검증 세트 - Loss: 0.5436, Accuracy: 0.8894, F1: 0.8820\n",
      "테스트 세트 - Loss: 0.5691, Accuracy: 0.9068, F1: 0.9139\n",
      "\n",
      "과적합 징후가 있습니다. 훈련 세트의 성능이 검증 및 테스트 세트보다 현저히 높습니다.\n",
      "모델이 비교적 좋은 성능을 보이고 있습니다. 미세 조정을 통해 더 개선할 수 있습니다.\n",
      "\n",
      "개선을 위한 제안:\n",
      "- 정규화 기법 (예: dropout, L2 정규화)을 적용해 보세요.\n",
      "- 데이터 증강 기법을 강화해 보세요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def interpret_results(train_results, valid_results, test_results):\n",
    "    \"\"\"\n",
    "    훈련, 검증, 테스트 결과를 해석하는 함수\n",
    "    \n",
    "    :param train_results: (train_loss, train_acc, train_f1)\n",
    "    :param valid_results: (valid_loss, valid_acc, valid_f1)\n",
    "    :param test_results: (test_loss, test_acc, test_f1)\n",
    "    :return: 해석 문자열\n",
    "    \"\"\"\n",
    "    train_loss, train_acc, train_f1 = train_results\n",
    "    valid_loss, valid_acc, valid_f1 = valid_results\n",
    "    test_loss, test_acc, test_f1 = test_results\n",
    "    \n",
    "    interpretation = \"모델 성능 해석:\\n\\n\"\n",
    "    \n",
    "    # 각 세트의 성능 출력\n",
    "    interpretation += f\"훈련 세트 - Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}, F1: {train_f1:.4f}\\n\"\n",
    "    interpretation += f\"검증 세트 - Loss: {valid_loss:.4f}, Accuracy: {valid_acc:.4f}, F1: {valid_f1:.4f}\\n\"\n",
    "    interpretation += f\"테스트 세트 - Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1: {test_f1:.4f}\\n\\n\"\n",
    "    \n",
    "    # 과적합 여부 확인\n",
    "    if train_acc - valid_acc > 0.05 and train_acc - test_acc > 0.05:\n",
    "        interpretation += \"과적합 징후가 있습니다. 훈련 세트의 성능이 검증 및 테스트 세트보다 현저히 높습니다.\\n\"\n",
    "    elif valid_acc - test_acc > 0.05:\n",
    "        interpretation += \"검증 세트에 과적합되었을 가능성이 있습니다. 테스트 세트의 성능이 상대적으로 낮습니다.\\n\"\n",
    "    else:\n",
    "        interpretation += \"과적합의 징후가 크지 않습니다. 세 세트의 성능이 비교적 일관적입니다.\\n\"\n",
    "    \n",
    "    # 전반적인 성능 평가\n",
    "    avg_acc = (train_acc + valid_acc + test_acc) / 3\n",
    "    if avg_acc < 0.3:\n",
    "        interpretation += \"전반적인 성능이 낮습니다. 모델 개선이 필요합니다.\\n\"\n",
    "    elif avg_acc < 0.6:\n",
    "        interpretation += \"모델이 어느 정도의 학습을 보이지만, 상당한 개선의 여지가 있습니다.\\n\"\n",
    "    else:\n",
    "        interpretation += \"모델이 비교적 좋은 성능을 보이고 있습니다. 미세 조정을 통해 더 개선할 수 있습니다.\\n\"\n",
    "    \n",
    "    # F1 점수 해석\n",
    "    if min(train_f1, valid_f1, test_f1) < 0.3:\n",
    "        interpretation += \"F1 점수가 낮습니다. 클래스 불균형 문제를 고려해야 할 수 있습니다.\\n\"\n",
    "    \n",
    "    # 개선 제안\n",
    "    interpretation += \"\\n개선을 위한 제안:\\n\"\n",
    "    if train_acc - valid_acc > 0.05:\n",
    "        interpretation += \"- 정규화 기법 (예: dropout, L2 정규화)을 적용해 보세요.\\n\"\n",
    "        interpretation += \"- 데이터 증강 기법을 강화해 보세요.\\n\"\n",
    "    if avg_acc < 0.5:\n",
    "        interpretation += \"- 더 복잡한 모델 아키텍처를 시도해 보세요.\\n\"\n",
    "        interpretation += \"- 학습률과 배치 크기를 조정해 보세요.\\n\"\n",
    "        interpretation += \"- 전이 학습을 고려해 보세요.\\n\"\n",
    "    if min(train_f1, valid_f1, test_f1) < 0.3:\n",
    "        interpretation += \"- 클래스 가중치 조정을 통해 불균형 문제를 해결해 보세요.\\n\"\n",
    "        interpretation += \"- 앙상블 기법을 시도해 보세요.\\n\"\n",
    "    \n",
    "    return interpretation\n",
    "\n",
    "interpret = interpret_results(train_results, valid_results, test_results)\n",
    "print(interpret)\n",
    "wandb.log({\"interpretation\": interpret})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# Inference & Save File\n",
    "* 테스트 이미지에 대한 추론을 진행하고, 결과 파일을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if retrain_full_dataset:\n",
    "    print(\"Starting final training on entire dataset for submission...\")\n",
    "\n",
    "    # 전체 데이터셋 생성\n",
    "    full_dataset = ImageDataset(\n",
    "        \"data/train.csv\",\n",
    "        \"data/train/\",\n",
    "        transform=train_transform\n",
    "    )\n",
    "\n",
    "    full_loader = DataLoader(\n",
    "        full_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    # 모델 재초기화\n",
    "    if reinitialize_model:\n",
    "        model = timm.create_model(model_name, pretrained=True, num_classes=17, drop_rate=0.3).to(device)\n",
    "        optimizer = Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    # 전체 데이터셋으로 재학습\n",
    "    for epoch in range(EPOCHS):\n",
    "        ret = train_one_epoch(full_loader, model, optimizer, loss_fn, device=device)\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        print(f\"Loss: {ret['train_loss']:.4f}, Accuracy: {ret['train_acc']:.4f}, F1: {ret['train_f1']:.4f}\")\n",
    "\n",
    "    print(\"Final training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12776,
     "status": "ok",
     "timestamp": 1700315185336,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "uRYe6jlPU_Om",
    "outputId": "2a08690c-9ffe-418d-8679-eb9280147110"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for submission...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:12<00:00,  7.82it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating predictions for submission...\")\n",
    "preds_list = []\n",
    "\n",
    "model.eval()\n",
    "for image, _ in tqdm(pred_loader):\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(image)\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1700315216829,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "aClN7Qi7VZoh"
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315238836,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "VDBXQqAzVvLY"
   },
   "outputs": [],
   "source": [
    "sample_submission_df = pd.read_csv(\"data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1700315244710,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "ePx2vCELVnuS"
   },
   "outputs": [],
   "source": [
    "submission_file_path = os.path.join('output', f'{train_time}.csv')\n",
    "pred_df.to_csv(submission_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1700315247734,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "9yMO8s6GqAwZ",
    "outputId": "9a30616f-f0ea-439f-a906-dd806737ce00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg       6\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg       0\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af81bf00276743ce8ba6dde9dc41e286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>█▁▂</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>f1</td><td>█▁▃</td></tr><tr><td>final_test_accuracy</td><td>▁</td></tr><tr><td>final_test_f1</td><td>▁</td></tr><tr><td>final_test_loss</td><td>▁</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_train_f1</td><td>▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_valid_accuracy</td><td>▁</td></tr><tr><td>final_valid_f1</td><td>▁</td></tr><tr><td>final_valid_loss</td><td>▁</td></tr><tr><td>loss</td><td>▁██</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇███</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.90678</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>f1</td><td>0.91392</td></tr><tr><td>final_test_accuracy</td><td>0.90678</td></tr><tr><td>final_test_f1</td><td>0.91392</td></tr><tr><td>final_test_loss</td><td>0.56909</td></tr><tr><td>final_train_accuracy</td><td>0.99272</td></tr><tr><td>final_train_f1</td><td>0.99247</td></tr><tr><td>final_train_loss</td><td>0.01925</td></tr><tr><td>final_valid_accuracy</td><td>0.88936</td></tr><tr><td>final_valid_f1</td><td>0.88195</td></tr><tr><td>final_valid_loss</td><td>0.54358</td></tr><tr><td>interpretation</td><td>모델 성능 해석:\n",
       "\n",
       "훈련 세트 - L...</td></tr><tr><td>loss</td><td>0.56909</td></tr><tr><td>train_acc</td><td>0.97634</td></tr><tr><td>train_f1</td><td>0.97344</td></tr><tr><td>train_loss</td><td>0.05222</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run-20240731-204356</strong> at: <a href='https://wandb.ai/upstage-ai-lab-3rd-cv11/document-classification/runs/ian4gr22' target=\"_blank\">https://wandb.ai/upstage-ai-lab-3rd-cv11/document-classification/runs/ian4gr22</a><br/> View project at: <a href='https://wandb.ai/upstage-ai-lab-3rd-cv11/document-classification' target=\"_blank\">https://wandb.ai/upstage-ai-lab-3rd-cv11/document-classification</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240731_114356-ian4gr22/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
