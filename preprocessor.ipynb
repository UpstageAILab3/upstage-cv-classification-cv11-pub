{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 클래스 이름 한글 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# class_names 딕셔너리 정의\n",
    "class_names = {\n",
    "    0: \"계좌번호(손글씨)\", 1: \"임신출산 진료비 지급 신청서\", 2: \"자동차 계기판\", 3: \"입퇴원 확인서\", 4: \"진단서\", \n",
    "    5: \"운전면허증\", 6: \"진료비영수증\", 7: \"통원 진료 확인서\", 8: \"주민등록증\", 9: \"여권\", \n",
    "    10: \"진료비 납입 확인서\", 11: \"약제비 영수증\", 12: \"처방전\", 13: \"이력서\", 14: \"소견서\", \n",
    "    15: \"자동차 등록증\", 16: \"자동차 번호판\"\n",
    "}\n",
    "\n",
    "# CSV 파일 경로\n",
    "meta_csv_file = 'data/meta.csv'\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv(meta_csv_file)\n",
    "\n",
    "# 한글 클래스 이름 열 추가\n",
    "df['class_name_kor'] = df['target'].map(class_names)\n",
    "\n",
    "# 수정된 CSV 파일 저장\n",
    "output_csv_file = 'data/meta_kor.csv'\n",
    "df.to_csv(output_csv_file, index=False)\n",
    "\n",
    "print(\"한글 클래스 이름이 추가된 CSV 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 이미지 폴더별로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from shutil import copy2\n",
    "\n",
    "# 파일 경로 설정\n",
    "csv_file = 'data/train.csv'\n",
    "meta_csv_file = 'data/meta_kor.csv'\n",
    "image_folder = 'data/train'  # 이미지 파일들이 있는 폴더\n",
    "output_folder = 'data/train_by_class'  # 클래스별 폴더를 생성할 위치\n",
    "\n",
    "# CSV 파일 읽기\n",
    "train_df = pd.read_csv(csv_file)\n",
    "\n",
    "# meta_csv 파일 읽기\n",
    "meta_df = pd.read_csv(meta_csv_file)\n",
    "\n",
    "# target을 기준으로 class_name_kor과 합치기\n",
    "train_df = train_df.merge(meta_df[['target', 'class_name_kor']], on='target', how='left')\n",
    "\n",
    "# 각 클래스별 폴더 생성 및 이미지 이동\n",
    "for index, row in train_df.iterrows():\n",
    "    image_id = row['ID']\n",
    "    class_id = row['target']\n",
    "    class_name_kor = row['class_name_kor']\n",
    "    \n",
    "    # 클래스별 폴더 이름 설정\n",
    "    class_folder_name = f\"{class_id}_{class_name_kor}\"\n",
    "    class_folder = os.path.join(output_folder, class_folder_name)\n",
    "    \n",
    "    # 클래스별 폴더가 없으면 생성\n",
    "    if not os.path.exists(class_folder):\n",
    "        os.makedirs(class_folder)\n",
    "    \n",
    "    # 이미지 파일 경로 설정\n",
    "    src_image_path = os.path.join(image_folder, image_id)\n",
    "    dest_image_path = os.path.join(class_folder, image_id)\n",
    "    \n",
    "    # 이미지 파일을 클래스 폴더로 복사\n",
    "    copy2(src_image_path, dest_image_path)\n",
    "\n",
    "print(\"이미지 분류가 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data 라벨링 오류 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 설정\n",
    "csv_file = 'data/train.csv'\n",
    "new_csv_file = 'data/train_fixed.csv'\n",
    "\n",
    "# CSV 파일 읽기\n",
    "train_df = pd.read_csv(csv_file)\n",
    "\n",
    "train_df['target'][train_df['ID'] == '45f0d2dfc7e47c03.jpg'] = 7 # 입퇴원확인서->진료확인서\n",
    "train_df['target'][train_df['ID'] == 'aec62dced7af97cd.jpg'] = 14 # 3 입퇴원확인서->소견서\n",
    "train_df['target'][train_df['ID'] == '8646f2c3280a4f49.jpg'] = 3 # 7 통원진료확인서->입퇴원확인서\n",
    "train_df['target'][train_df['ID'] == '1ec14a14bbe633db.jpg'] = 7 # 14 소견서->진료확인서\n",
    "train_df['target'][train_df['ID'] == '7100c5c67aecadc5.jpg'] = 7 # 3 입퇴원확인서->진료확인서\n",
    "train_df['target'][train_df['ID'] == 'c5182ab809478f12.jpg'] = 14 # 4 진단서->소견서\n",
    "train_df['target'][train_df['ID'] == '38d1796b6ad99ddd.jpg'] = 10 # 11 약제비 영수증 -> 진료비(약제비) 납입 확인서\n",
    "train_df['target'][train_df['ID'] == '0583254a73b48ece.jpg'] = 10 # 11 약제비 영수증 -> 진료비(약제비) 납입 확인서\n",
    "train_df['target'][train_df['ID'] == '02ebb92c43006832.jpg'] = 10 # 11 약제비 영수증 -> 진료비(약제비) 납입 확인서\n",
    "\n",
    "# 새 파일 저장\n",
    "train_df.to_csv(new_csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 로드\n",
    "df = pd.read_csv('data/train_augmented_balanced_150.csv')\n",
    "\n",
    "# 수정하고자 하는 파일들과 새로운 target 값들을 딕셔너리로 정의\n",
    "files_to_update = {\n",
    "    '45f0d2dfc7e47c03.jpg': 7,\n",
    "    'aec62dced7af97cd.jpg': 14,\n",
    "    '8646f2c3280a4f49.jpg': 3,\n",
    "    '1ec14a14bbe633db.jpg': 7,\n",
    "    '7100c5c67aecadc5.jpg': 7,\n",
    "    'c5182ab809478f12.jpg': 14,\n",
    "    '38d1796b6ad99ddd.jpg': 10,\n",
    "    '0583254a73b48ece.jpg': 10,\n",
    "    '02ebb92c43006832.jpg': 10,\n",
    "}\n",
    "\n",
    "total_updated = 0\n",
    "\n",
    "for original_file, new_target in files_to_update.items():\n",
    "    # 원본 파일의 target 변경\n",
    "    original_updated = df.loc[df['ID'] == original_file, 'target'].shape[0]\n",
    "    df.loc[df['ID'] == original_file, 'target'] = new_target\n",
    "\n",
    "    # 증강 파일의 target 변경\n",
    "    augmented_files = df[df['ID'].str.startswith(original_file.split('.')[0])]\n",
    "    df.loc[augmented_files.index, 'target'] = new_target\n",
    "\n",
    "    total_updated += original_updated + len(augmented_files)\n",
    "    print(f\"Updated {original_file} and its {len(augmented_files)} augmented files.\")\n",
    "\n",
    "# 변경된 내용 저장\n",
    "df.to_csv('data/train_fixed_augmented_balanced_150.csv', index=False)\n",
    "\n",
    "print(f\"Total updated entries: {total_updated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "from shutil import rmtree\n",
    "\n",
    "def enhance_image(image, gray_scale=False):\n",
    "    try:\n",
    "        if gray_scale:\n",
    "            # 이미지 채널 수 확인\n",
    "            if len(image.shape) == 2:\n",
    "                # 이미 그레이스케일\n",
    "                image = image\n",
    "            elif len(image.shape) == 3:\n",
    "                # 컬러 이미지를 그레이스케일로 변환\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                raise ValueError(\"Unexpected image format\")\n",
    "        \n",
    "        # 언샤프 마스킹을 사용한 샤프닝\n",
    "        blurred = cv2.GaussianBlur(image, (0, 0), 4)\n",
    "        result = cv2.addWeighted(image, 1.55, blurred, -0.5, 0)\n",
    "\n",
    "        # 최종 결과를 3채널로 변환\n",
    "        if gray_scale:\n",
    "            result = cv2.cvtColor(result, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error in enhance_image: {e}\")\n",
    "        return image  # 오류 발생 시 원본 이미지 반환\n",
    "    \n",
    "def process_chunk(chunk, input_dir, output_dir, gray_scale=False):\n",
    "    processed_images = []\n",
    "    enhanced_files = []\n",
    "    \n",
    "    for filename in chunk:\n",
    "        img_path = os.path.join(input_dir, filename)\n",
    "        if gray_scale :\n",
    "            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        else : \n",
    "            image = cv2.imread(img_path)\n",
    "\n",
    "        if image is not None:\n",
    "            enhanced = enhance_image(image, gray_scale)\n",
    "            \n",
    "            output_path = os.path.join(output_dir, filename)\n",
    "            cv2.imwrite(output_path, enhanced)\n",
    "            processed_images.append((filename, enhanced))\n",
    "    \n",
    "    return enhanced_files, processed_images\n",
    "\n",
    "def process(input_dir, output_dir, gray_scale=False, num_processes=multiprocessing.cpu_count()):\n",
    "    if os.path.exists(output_dir):\n",
    "        rmtree(output_dir)\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "    filenames = [f for f in os.listdir(input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    chunk_size = len(filenames) // num_processes + 1\n",
    "    chunks = [filenames[i:i+chunk_size] for i in range(0, len(filenames), chunk_size)]\n",
    "    \n",
    "    with multiprocessing.Pool(num_processes) as pool:\n",
    "        results = list(tqdm(\n",
    "            pool.imap(partial(process_chunk, input_dir=input_dir, output_dir=output_dir, gray_scale=gray_scale), chunks),\n",
    "            total=len(chunks),\n",
    "            desc=\"Processing image chunks\"\n",
    "        ))\n",
    "    \n",
    "    enhanced_files = [file for sublist in results for file in sublist[0]]\n",
    "    processed_images = [img for sublist in results for img in sublist[1]]\n",
    "    \n",
    "    print(f\"Processed {len(processed_images)} images saved to {output_dir}\")\n",
    "    return enhanced_files, processed_images\n",
    "\n",
    "def show_sample_images(original_images, processed_images, num_samples=3):\n",
    "    sample_indices = random.sample(range(len(original_images)), num_samples)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(12, 4*num_samples))\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        original_filename, original_image = original_images[idx]\n",
    "        _, processed_image = processed_images[idx]\n",
    "        \n",
    "        axes[i, 0].imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "        axes[i, 0].set_title(f\"Original: {original_filename}\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB))\n",
    "        axes[i, 1].set_title(f\"Processed: {original_filename}\")\n",
    "        axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def enhance(input_dir, output_dir, gray_scale=False):\n",
    "    enhanced_files, processed_images = process(input_dir, output_dir, gray_scale)\n",
    "\n",
    "    print(\"Enhanced files:\")\n",
    "    for filename in enhanced_files:\n",
    "        print(filename)\n",
    "\n",
    "    # 원본 이미지 로드 (샘플 이미지 표시를 위해)\n",
    "    original_images = [(f, cv2.imread(os.path.join(input_dir, f))) for f in os.listdir(input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    # 샘플 이미지 표시\n",
    "    show_sample_images(original_images, processed_images, 3)\n",
    "\n",
    "enhance('data/train', 'data/train_enhanced', False)\n",
    "enhance('data/test', 'data/test_enhanced', False)\n",
    "enhance('data/train', 'data/train_enhanced_gray', True)\n",
    "enhance('data/test', 'data/test_enhanced_gray', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 이미지 오프라인 증강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "import augraphy\n",
    "from augraphy import AugraphyPipeline\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import random\n",
    "from shutil import rmtree\n",
    "\n",
    "image_width = 224\n",
    "image_height = 224\n",
    "\n",
    "document_classes = [1, 3, 4, 6, 7, 10, 12, 13, 14] # 11 : 약제비 영수증?\n",
    "\n",
    "class SaltAndPepper(A.ImageOnlyTransform):\n",
    "    '''\n",
    "    salt_prob는 흰색 픽셀(소금)이 추가될 확률입니다.\n",
    "    pepper_prob는 검은색 픽셀(후추)이 추가될 확률입니다.\n",
    "    p는 이 변환이 적용될 전체 확률입니다\n",
    "    '''\n",
    "    def __init__(self, salt_prob=0.01, pepper_prob=0.01, p=0.5):\n",
    "        super().__init__(p)\n",
    "        self.salt_prob = salt_prob\n",
    "        self.pepper_prob = pepper_prob\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        noise = np.zeros(image.shape, np.uint8)\n",
    "        salt = np.random.random(image.shape) < self.salt_prob\n",
    "        pepper = np.random.random(image.shape) < self.pepper_prob\n",
    "        noise[salt] = 255\n",
    "        noise[pepper] = 0\n",
    "        return cv2.add(image, noise)\n",
    "\n",
    "def overlay_images(image1, image2, alpha_image1):\n",
    "    # 이미지 크기 맞추기\n",
    "    h1, w1 = image1.shape[:2]\n",
    "    h2, w2 = image2.shape[:2]\n",
    "    \n",
    "    # 크기가 다르면 image2를 image1 크기에 맞게 리사이즈\n",
    "    if h1 != h2 or w1 != w2:\n",
    "        image2 = cv2.resize(image2, (w1, h1))\n",
    "    \n",
    "    # 채널 수 확인 및 맞추기\n",
    "    if len(image1.shape) != len(image2.shape):\n",
    "        if len(image1.shape) == 2:\n",
    "            image1 = cv2.cvtColor(image1, cv2.COLOR_GRAY2BGR)\n",
    "        elif len(image2.shape) == 2:\n",
    "            image2 = cv2.cvtColor(image2, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # 이미지 합성\n",
    "    return cv2.addWeighted(image1, alpha_image1, image2,1 - alpha_image1, 0)    \n",
    "\n",
    "def combine_augmentations(image, target, overlay_image=None, overlay_class_image=None):\n",
    "\n",
    "    # 확률에 따라 한 이미지에 여러 변환이 동시에 적용될 수 있음\n",
    "    albu_pipeline = A.Compose([\n",
    "        A.RandomResizedCrop(height=image_height, width=image_width, scale=(0.6, 1.0), p=0.5), # 40% 확률로 적용됨. 이미지를 지정된 크기로 무작위 크롭 및 리사이즈\n",
    "        A.OneOf([ # 아래 두 변환 중 하나가 70% 확률로 선택되어 적용됨\n",
    "            A.RandomRotate90(p=0.5),  # 50% 확률로 90도 단위 회전\n",
    "            A.Rotate(limit=180, p=0.5),  # 50% 확률로 -180~180도 사이 회전\n",
    "        ], p=0.7),\n",
    "        A.Flip(p=0.5), # 50% 확률로 이미지를 뒤집음 (수평 또는 수직)\n",
    "        A.Blur(blur_limit=7, p=0.5),\n",
    "        A.GaussNoise(var_limit=(10.0, 80.0), p=0.7), # 70% 확률로 가우시안 노이즈 추가\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3), # 30% 확률로 밝기와 대비 무작위 조정\n",
    "        SaltAndPepper(salt_prob=0.005, pepper_prob=0.01, p=0.2),\n",
    "    ])    \n",
    "\n",
    "    augraphy_pipeline = AugraphyPipeline([\n",
    "        augraphy.DirtyDrum(line_width_range=(1, 2), line_concentration=0.05, p=0.3), # 20% 확률로 더러운 프린터 드럼 효과 적용 (가는 선 추가)\n",
    "        augraphy.Letterpress(n_samples=(50, 200), n_clusters=(100, 200), std_range=(500, 1500), p=0.3), # 20% 확률로 옛날 인쇄기 효과 적용 (텍스트에 불규칙한 압력 적용)\n",
    "        augraphy.Markup(num_lines_range=(1, 3), markup_length_range=(0.5, 1.0), p=0.1), # 10% 확률로 수동 마크업 효과 추가 (펜으로 그은 선 등)\n",
    "        augraphy.NoiseTexturize(sigma_range=(5, 15), turbulence_range=(2, 5), p=0.7),  # 70% 확률로 노이즈 텍스처 추가 (종이의 질감이나 오염 시뮬레이션)\n",
    "        augraphy.Folding(fold_count=1, fold_angle_range=(0, 30), p=0.2), # 20% 확률로 종이 접힘 효과 추가\n",
    "    ])\n",
    "    \n",
    "    image = albu_pipeline(image=image)['image']\n",
    "\n",
    "    # 문서 클래스에 대해서만 Augraphy 적용\n",
    "    if target in document_classes:\n",
    "        image = augraphy_pipeline(image)\n",
    "    # 원본 이미지 overlay (5% 확률)\n",
    "    elif overlay_image is not None and random.random() < 0.05:\n",
    "        image = overlay_images(image, overlay_image, random.uniform(0.6, 0.8))\n",
    "    # 다른 클래스 이미지 overlay (5% 확률)\n",
    "    elif overlay_class_image is not None and random.random() < 0.05:\n",
    "        image = overlay_images(image, overlay_class_image, random.uniform(0.8, 0.95))\n",
    "\n",
    "    return image\n",
    "\n",
    "def augment_and_save(data, all_images, input_dir, output_dir):\n",
    "    img_name = data['ID']\n",
    "    target = data['target']\n",
    "    is_augmented = data['is_augmented']\n",
    "    \n",
    "    if is_augmented:\n",
    "        original_name = img_name.split('_aug_')[0] + os.path.splitext(img_name)[1]\n",
    "        img_path = os.path.join(input_dir, original_name)\n",
    "    else:\n",
    "        img_path = os.path.join(input_dir, img_name)\n",
    "\n",
    "    img = np.array(Image.open(img_path).convert('RGB'))\n",
    "    \n",
    "    if is_augmented:\n",
    "        other_class_images = [img for img in all_images if img[2] != target]\n",
    "        if other_class_images:\n",
    "            overlay_class_img_path = random.choice(other_class_images)[0]\n",
    "            overlay_class_img = np.array(Image.open(overlay_class_img_path).convert('RGB'))\n",
    "        else:\n",
    "            overlay_class_img = None\n",
    "\n",
    "        augmented = combine_augmentations(img, target, img, overlay_class_img)\n",
    "    else:\n",
    "        augmented = img\n",
    "    \n",
    "    Image.fromarray(augmented).save(os.path.join(output_dir, img_name))\n",
    "    \n",
    "    return data\n",
    "\n",
    "def process_chunk(chunk, all_images, input_dir, output_dir):\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results = list(executor.map(partial(augment_and_save, all_images=all_images, input_dir=input_dir, output_dir=output_dir), chunk))\n",
    "    return results\n",
    "\n",
    "def process_by_min_class(input_dir, output_dir, input_csv, output_csv, augmentation_ratio, chunk_size=500):\n",
    "    if os.path.exists(output_dir):\n",
    "        rmtree(output_dir)\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    print(f\"시작: 총 {len(df)}개의 원본 이미지 처리 중...\")\n",
    "    \n",
    "    class_counts = df['target'].value_counts()\n",
    "    min_count = class_counts.min()\n",
    "    print(f\"min_count : {min_count}\")\n",
    "    target_count = int(min_count * augmentation_ratio)\n",
    "    print(f\"target_count : {target_count}\")\n",
    "\n",
    "    # 각 클래스별 증강해야 할 이미지 수 계산\n",
    "    class_augment_counts = {target: max(0, target_count - count) for target, count in class_counts.items()}\n",
    "    print(f\"class_augment_counts : {class_augment_counts}\")\n",
    "    \n",
    "    all_images = [\n",
    "        (os.path.join(input_dir, row['ID']), row['ID'], row['target'])\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    # 원본 이미지 추가\n",
    "    for _, row in df.iterrows():\n",
    "        all_data.append({\n",
    "            'ID': row['ID'],\n",
    "            'target': row['target'],\n",
    "            'is_augmented': False\n",
    "        })\n",
    "    \n",
    "    # 증강 이미지 생성 및 추가\n",
    "    for target, augment_count in class_augment_counts.items():\n",
    "        target_images = [img for img in all_images if img[2] == target]\n",
    "        for i in range(augment_count):\n",
    "            original_img = random.choice(target_images)\n",
    "            aug_name = f\"{os.path.splitext(original_img[1])[0]}_aug_{i+1}{os.path.splitext(original_img[1])[1]}\"\n",
    "            all_data.append({\n",
    "                'ID': aug_name,\n",
    "                'target': target,\n",
    "                'is_augmented': True\n",
    "            })\n",
    "    \n",
    "    # 청크 단위로 처리\n",
    "    for i in tqdm(range(0, len(all_data), chunk_size), desc=\"Processing chunks\"):\n",
    "        chunk = all_data[i:i+chunk_size]\n",
    "        process_chunk(chunk, all_images, input_dir, output_dir)\n",
    "    \n",
    "    augmented_df = pd.DataFrame(all_data)\n",
    "    augmented_df.to_csv(output_csv, index=False)\n",
    "    \n",
    "    print(f\"\\n완료: 총 {len(df)}개의 원본 이미지에서 {len(augmented_df)}개의 이미지 데이터 생성 (원본 + 증강)\")\n",
    "    print(f\"증강 비율: {len(augmented_df) / len(df):.2f}배\")\n",
    "    \n",
    "    final_class_counts = augmented_df['target'].value_counts()\n",
    "    print(\"\\n클래스별 최종 이미지 수:\")\n",
    "    print(final_class_counts)\n",
    "\n",
    "augmentation_ratio = 150  # 원하는 증강 비율 (예: 1.5배)\n",
    "chunk_size = 50  # 한 번에 처리할 이미지 수\n",
    "\n",
    "process_by_min_class('data/train', f'data/train_augmented_balanced_{augmentation_ratio}', 'data/train.csv', f'data/train_augmented_balanced_{augmentation_ratio}.csv', augmentation_ratio, chunk_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
