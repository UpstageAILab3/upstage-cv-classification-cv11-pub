{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import common\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_filename_list = [\n",
    "                                    'model_bak/cp-efficientnet_b3.ra2_in1k_sd_42_epc_2_isFull_False_vl0.0596_va_0.9802_vf1_0.9795.pt', \n",
    "                                    'model_bak/cp-tiny_vit_21m_384.dist_in22k_ft_in1k_sd_42_epc_0_isFull_False_vl_0.1706_va_0.9366_vf1_0.9290.pt',\n",
    "                                    'model_bak/cp-tiny_vit_21m_384.dist_in22k_ft_in1k_sd_42_epc_2_isFull_False_vl_0.1526_va_0.9711_vf1_0.9714.pt',\n",
    "                                 ]\n",
    "is_soft_voting = True\n",
    "augment_ratio = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b3.ra2_in1k 320 32\n",
      "tiny_vit_21m_384.dist_in22k_ft_in1k 384 32\n",
      "tiny_vit_21m_384.dist_in22k_ft_in1k 384 32\n",
      "3 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_list = []\n",
    "tst_loader_list = []\n",
    "\n",
    "for cp_filename in model_checkpoint_filename_list:\n",
    "    checkpoint = torch.load(cp_filename, map_location = device)\n",
    "    \n",
    "    print(checkpoint['model'], checkpoint['tst_img_size'], checkpoint['batch_size'])\n",
    "    \n",
    "    model = timm.create_model(\n",
    "        checkpoint['model'],\n",
    "        pretrained = True,\n",
    "        num_classes = 17,\n",
    "    ).to(device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])    \n",
    "    model_list.append(model)\n",
    "    \n",
    "    ##\n",
    "    tst_transform = common.create_tst_transform(checkpoint['tst_img_size'])\n",
    "    tst_aug_transform = common.create_trn_aug_transform(checkpoint['tst_img_size'])\n",
    "\n",
    "    # tst_dataset = common.ImageDataset(\n",
    "    #     \"datasets_fin/sample_submission.csv\",\n",
    "    #     \"datasets_fin/test/\",\n",
    "    #     transform = tst_transform\n",
    "    # )\n",
    "    \n",
    "    tst_dataset = common.ImageDataset(\n",
    "        \"datasets_fin/sample_submission.csv\",\n",
    "        \"datasets_fin/test/\",\n",
    "        transform=tst_transform, \n",
    "        aug_transform=tst_aug_transform, \n",
    "        augment_ratio=augment_ratio)\n",
    "\n",
    "    tst_loader = DataLoader(\n",
    "        tst_dataset,\n",
    "        batch_size = checkpoint['batch_size'],\n",
    "        shuffle = False,\n",
    "        num_workers = 12,\n",
    "        pin_memory = True\n",
    "    )\n",
    "    \n",
    "    tst_loader_list.append(tst_loader)\n",
    "\n",
    "print(len(model_list), len(tst_loader_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1963/1963 [12:48<00:00,  2.55it/s]\n",
      "100%|██████████| 1963/1963 [16:52<00:00,  1.94it/s]\n",
      "100%|██████████| 1963/1963 [16:21<00:00,  2.00it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "\n",
    "for model, tst_loader in zip(model_list, tst_loader_list):\n",
    "    preds = common.get_preds_list_by_tst_loader(model, tst_loader, device, is_soft_voting)\n",
    "    preds_list.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_targets_count():\n",
    "    sample_submission_df = pd.read_csv(\"datasets_fin/sample_submission.csv\")\n",
    "    return len(sample_submission_df)\n",
    "    \n",
    "def hard_voting(predictions):\n",
    "    predictions = np.asarray(predictions)\n",
    "    return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
    "\n",
    "def soft_voting(predictions):\n",
    "    predictions = np.asarray(predictions)\n",
    "    mean_axis0 = np.mean(predictions, axis=0)\n",
    "    \n",
    "    # 증강된 데이터에 대한 예측값도 고려하기.\n",
    "    all_targets_count = get_all_targets_count()\n",
    "    \n",
    "    aug_size = len(mean_axis0) / all_targets_count\n",
    "    assert len(mean_axis0) % all_targets_count == 0\n",
    "    aug_size = int(aug_size)\n",
    "    \n",
    "    if aug_size > 1:\n",
    "        bulk_list = []\n",
    "        step = 0\n",
    "        \n",
    "        for i in range(0, aug_size):\n",
    "            bulk_list.append(mean_axis0[step:step + all_targets_count])\n",
    "            step += all_targets_count\n",
    "        \n",
    "        bulk_list = np.asarray(bulk_list)\n",
    "        mean_axis0 = np.mean(bulk_list, axis=0)\n",
    "        \n",
    "    return mean_axis0.argmax(axis=1)\n",
    "\n",
    "# 최종 예측\n",
    "if is_soft_voting:\n",
    "    final_pred = soft_voting(preds_list)\n",
    "else:\n",
    "    final_pred = hard_voting(preds_list)\n",
    "\n",
    "# # csv 로 저장\n",
    "common.preds_list_to_save_to_csv(final_pred, tst_loader, 'pred_ensemble.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
