{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import common\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_filename_list = [\n",
    "                                    'model_bak/cp-efficientnet_b3.ra2_in1k_sd_42_epc_2_isFull_False_vl0.0596_va_0.9802_vf1_0.9795.pt', \n",
    "                                    'model_bak/cp-tiny_vit_21m_384.dist_in22k_ft_in1k_sd_42_epc_0_isFull_False_vl_0.1706_va_0.9366_vf1_0.9290.pt'\n",
    "                                 ]\n",
    "is_soft_voting = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b3.ra2_in1k 320 32\n",
      "tiny_vit_21m_384.dist_in22k_ft_in1k 384 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489d4c05cd7949f08918952d76d15b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/85.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jjam\\anaconda3\\envs\\pytorch_test3\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jjam\\.cache\\huggingface\\hub\\models--timm--tiny_vit_21m_384.dist_in22k_ft_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_list = []\n",
    "tst_loader_list = []\n",
    "\n",
    "for cp_filename in model_checkpoint_filename_list:\n",
    "    checkpoint = torch.load(cp_filename, map_location = device)\n",
    "    \n",
    "    print(checkpoint['model'], checkpoint['tst_img_size'], checkpoint['batch_size'])\n",
    "    \n",
    "    model = timm.create_model(\n",
    "        checkpoint['model'],\n",
    "        pretrained = True,\n",
    "        num_classes = 17,\n",
    "    ).to(device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])    \n",
    "    model_list.append(model)\n",
    "    \n",
    "    ##\n",
    "    tst_transform = common.create_tst_transform(checkpoint['tst_img_size'])\n",
    "\n",
    "    tst_dataset = common.ImageDataset(\n",
    "        \"datasets_fin/sample_submission.csv\",\n",
    "        \"datasets_fin/test/\",\n",
    "        transform = tst_transform\n",
    "    )\n",
    "\n",
    "    tst_loader = DataLoader(\n",
    "        tst_dataset,\n",
    "        batch_size = checkpoint['batch_size'],\n",
    "        shuffle = False,\n",
    "        num_workers = 2,\n",
    "        pin_memory = True\n",
    "    )\n",
    "    \n",
    "    tst_loader_list.append(tst_loader)\n",
    "\n",
    "print(len(model_list), len(tst_loader_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:29<00:00,  3.34it/s]\n",
      "100%|██████████| 99/99 [00:43<00:00,  2.26it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "\n",
    "for model, tst_loader in zip(model_list, tst_loader_list):\n",
    "    preds = common.get_preds_list_by_tst_loader(model, tst_loader, device, is_soft_voting)\n",
    "    preds_list.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard voting 구현\n",
    "def hard_voting(predictions):\n",
    "    predictions = np.asarray(predictions)\n",
    "    return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
    "\n",
    "def soft_voting(predictions):\n",
    "    predictions = np.asarray(predictions)\n",
    "    mean_axis0 = np.mean(predictions, axis=0)\n",
    "    return mean_axis0.argmax(axis=1)\n",
    "\n",
    "# 최종 예측\n",
    "if is_soft_voting:\n",
    "    final_pred = soft_voting(preds_list)\n",
    "else:\n",
    "    final_pred = hard_voting(preds_list)\n",
    "\n",
    "# csv 로 저장\n",
    "common.preds_list_to_save_to_csv(final_pred, tst_loader, 'pred_ensemble.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
