{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam, AdamW\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 인스턴스 생성\n",
    "model_name = 'tf_efficientnet_b5.ns_jft_in1k'#'tiny_vit_21m_384.dist_in22k_ft_in1k'#'efficientnetv2_rw_m.agc_in1k' #'vit_base_patch16_224.augreg_in1k' #'efficientnet_b3.ra2_in1k'#'densenet121.ra_in1k'# #'resnet101' #'resnet34' # 'resnet50' 'efficientnet-b0', ...\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# training config\n",
    "pre_img_size = 600\n",
    "img_size = 456 #224 #256\n",
    "LR = 5e-4\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 8\n",
    "num_workers = 4\n",
    "early_stopping_patience = 5  # Early Stopping 설정\n",
    "augment_ratio = 200\n",
    "num_classes=17\n",
    "\n",
    "model = timm.create_model(\n",
    "    model_name,\n",
    "    pretrained=True,\n",
    "    num_classes=17,\n",
    "    drop_rate=0.2\n",
    ").to(device)\n",
    "\n",
    "# 가중치 로드\n",
    "model.load_state_dict(torch.load(r'/data/ephemeral/home/notebook/tf_efficientnet_b5.ns_jft_in1k_epoch_4.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://demo.albumentations.ai/\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# horizontal_flip, vertical_flip, double_flip, transpose 등 변환 정의\n",
    "horizontal_flip = A.HorizontalFlip(p=1)\n",
    "vertical_flip = A.VerticalFlip(p=1)\n",
    "double_flip = A.Compose([\n",
    "    A.HorizontalFlip(p=1),\n",
    "    A.VerticalFlip(p=1),\n",
    "])\n",
    "transpose = A.Transpose(p=1)\n",
    "transpose_hflip = A.Compose([\n",
    "    A.Transpose(p=1), \n",
    "    A.HorizontalFlip(p=1),\n",
    "])\n",
    "transpose_vflip = A.Compose([\n",
    "    A.Transpose(p=1),\n",
    "    A.VerticalFlip(p=1),\n",
    "])\n",
    "transpose_dflip = A.Compose([\n",
    "    A.Transpose(p=1),  \n",
    "    A.HorizontalFlip(p=1),\n",
    "    A.VerticalFlip(p=1),\n",
    "])\n",
    "\n",
    "# Augmentation을 위한 transform 코드\n",
    "trn_transform = A.Compose([\n",
    "    A.LongestMaxSize(max_size=pre_img_size, always_apply=True),\n",
    "    A.PadIfNeeded(min_height=pre_img_size, min_width=pre_img_size, border_mode=0, value=(255, 255, 255)),\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(var_limit=(10.0, 800.0), p=1),\n",
    "        A.GaussianBlur(blur_limit=(1, 7), p=1),\n",
    "        A.MotionBlur(blur_limit=(3, 7), p=1),\n",
    "        A.MedianBlur(blur_limit=3, p=1)\n",
    "    ], p=1),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=30, p=0.25),\n",
    "    A.Rotate(limit=(0, 360), p=0.75),\n",
    "    A.GridDistortion(always_apply=False, p=0.75, num_steps=6, distort_limit=(-0.3, 0.3), interpolation=0, border_mode=0, value=(0, 0, 0), mask_value=None, normalized=False),\n",
    "    A.OneOf([\n",
    "        horizontal_flip,\n",
    "        vertical_flip,\n",
    "        double_flip,\n",
    "        transpose,\n",
    "        transpose_hflip,\n",
    "        transpose_vflip,\n",
    "        transpose_dflip\n",
    "    ], p=1.0),\n",
    "    A.OneOf([\n",
    "        A.OpticalDistortion(always_apply=False, p=1.0, distort_limit=(-0.3, 0.3), shift_limit=(-0.05, 0.09), interpolation=0, border_mode=0, value=(0, 0, 0), mask_value=None),\n",
    "        A.MultiplicativeNoise(always_apply=False, p=1.0, multiplier=(0.93, 2.22), per_channel=True, elementwise=True),\n",
    "        A.ISONoise(always_apply=False, p=1.0, intensity=(0.38, 1.0), color_shift=(0.18, 0.47)),\n",
    "        A.RandomBrightnessContrast(always_apply=False, p=1.0, brightness_limit=(0.19, 0.62), contrast_limit=(-0.02, 0.62), brightness_by_max=True)\n",
    "    ], p=0.75),\n",
    "    \n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# test image 변환을 위한 transform 코드\n",
    "tst_transform = A.Compose([\n",
    "    #Adjust(always_apply=True),\n",
    "    A.LongestMaxSize(max_size=pre_img_size, always_apply=True),\n",
    "    A.PadIfNeeded(min_height=pre_img_size, min_width=pre_img_size, border_mode=0, value=(255, 255, 255)),\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스를 정의합니다.\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None, oversample=False, augment_ratio=1):\n",
    "        self.df = pd.read_csv(csv)\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.oversample = oversample\n",
    "        self.augment_ratio = augment_ratio\n",
    "\n",
    "        # 클래스간 불균형 해소를 위한 샘플 증식\n",
    "        if self.oversample:\n",
    "            # 각 클래스별로 데이터 수 계산\n",
    "            class_counts = np.bincount(self.df.values[:, 1].astype(int))\n",
    "\n",
    "            # 각 클래스별로 증식할 횟수 설정 (이 예제에서는 최대 데이터 수에 맞춤)\n",
    "            max_class_count = max(class_counts)\n",
    "            oversample_factors = [max_class_count // count for count in class_counts]\n",
    "            # Class 3, 7 가중치 2로 변경\n",
    "            # oversample_factors[3] = 2\n",
    "            # oversample_factors[7] = 2 \n",
    "            # oversample_factors[14] = 3 \n",
    "\n",
    "            # 각 클래스별로 데이터를 증식한 새로운 데이터 프레임 생성\n",
    "            oversampled_data = [self.df.values[self.df.values[:, 1] == cls].repeat(factor, axis=0) for cls, factor in enumerate(oversample_factors)]\n",
    "            oversampled_data = np.vstack(oversampled_data)\n",
    "\n",
    "            self.df = pd.DataFrame(oversampled_data, columns=self.df.columns)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) * self.augment_ratio\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = idx % len(self.df)\n",
    "        name, target = self.df.iloc[real_idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert(\"RGB\"))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n",
    "    \n",
    "    \n",
    "# meta.csv 파일 읽기\n",
    "meta_data = pd.read_csv('/data/ephemeral/home/datasets_fin/meta.csv')\n",
    "label_to_class_name = dict(zip(meta_data['target'], meta_data['class_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training data count: 1666\n",
      "Augmented training data count: 333200\n",
      "Test data count: 3140\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 및 데이터 로더 정의\n",
    "trn_dataset = ImageDataset(\n",
    "    \"/data/ephemeral/home/datasets_fin/train_labelupdate.csv\",\n",
    "    \"/data/ephemeral/home/datasets_fin/combined_train/train\",\n",
    "    transform=trn_transform,\n",
    "    oversample=True,\n",
    "    augment_ratio=augment_ratio\n",
    ")\n",
    "\n",
    "\n",
    "tst_dataset = ImageDataset(\n",
    "    \"/data/ephemeral/home/datasets_fin/sample_submission.csv\",\n",
    "    \"/data/ephemeral/home/datasets_fin/wdnx4/wdnx4\",\n",
    "    transform=tst_transform,\n",
    "    oversample=False,\n",
    "    augment_ratio=1\n",
    ")\n",
    "\n",
    "\n",
    "ori_traindata_num = int(len(trn_dataset)/augment_ratio)\n",
    "print(f\"Original training data count: {ori_traindata_num}\")\n",
    "print(f\"Augmented training data count: {len(trn_dataset)}\")\n",
    "print(f\"Test data count: {len(tst_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 정의\n",
    "trn_loader = DataLoader(\n",
    "    trn_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [03:20<00:00,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ID  target  prob_class_0  prob_class_1  prob_class_2  \\\n",
      "0  0008fdb22ddce0ce.jpg       2  3.686680e-12  3.041082e-13  9.999992e-01   \n",
      "1  00091bffdffd83de.jpg      12  5.598677e-11  1.882266e-08  3.200946e-11   \n",
      "2  00396fbc1f6cc21d.jpg       5  3.481447e-15  5.992583e-17  1.695421e-15   \n",
      "3  00471f8038d9c4b6.jpg      12  4.267822e-09  1.425181e-07  4.010682e-07   \n",
      "4  00901f504008d884.jpg       2  2.306215e-11  4.956328e-17  1.000000e+00   \n",
      "\n",
      "   prob_class_3  prob_class_4  prob_class_5  prob_class_6  prob_class_7  \\\n",
      "0  3.284950e-07  1.482153e-13  7.416641e-11  1.066299e-10  1.534541e-12   \n",
      "1  5.146481e-11  1.454109e-11  2.926739e-11  1.333111e-07  1.134807e-12   \n",
      "2  5.550253e-13  3.708128e-16  1.000000e+00  4.406705e-16  5.967123e-14   \n",
      "3  3.882549e-06  6.846597e-06  3.906863e-08  2.736593e-06  2.220130e-05   \n",
      "4  1.360666e-10  1.746026e-12  5.230599e-11  4.736079e-16  5.024436e-11   \n",
      "\n",
      "   prob_class_8  prob_class_9  prob_class_10  prob_class_11  prob_class_12  \\\n",
      "0  3.046381e-10  5.367837e-07   6.597570e-10   1.242240e-11   8.686393e-11   \n",
      "1  1.029448e-07  1.470534e-11   3.794361e-09   1.165436e-11   9.999998e-01   \n",
      "2  3.040352e-14  6.466962e-16   7.175190e-14   1.945871e-13   5.047193e-14   \n",
      "3  4.405042e-06  4.116054e-08   6.174685e-09   8.516694e-07   9.995129e-01   \n",
      "4  6.213392e-13  2.297812e-10   2.575964e-12   1.463527e-13   1.258816e-11   \n",
      "\n",
      "   prob_class_13  prob_class_14  prob_class_15  prob_class_16  \n",
      "0   7.387740e-11   1.503843e-13   2.114401e-10   4.207654e-13  \n",
      "1   2.260758e-08   1.586307e-10   7.424575e-10   7.798856e-09  \n",
      "2   6.282168e-15   1.371654e-11   1.718214e-13   3.221822e-18  \n",
      "3   2.565685e-04   4.646673e-05   1.282107e-05   1.297079e-04  \n",
      "4   2.542025e-14   1.583131e-10   1.992557e-15   4.520477e-22  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 모델 평가 모드 설정\n",
    "model.eval()\n",
    "preds_list = []\n",
    "probs_list = []  # 확률을 저장할 리스트\n",
    "\n",
    "# DataLoader를 통해 이미지를 반복 처리\n",
    "for image, _ in tqdm(tst_loader):\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = model(image)\n",
    "        probs = softmax(preds, dim=1)  # Softmax를 적용하여 확률 계산\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "    probs_list.extend(probs.detach().cpu().numpy())  # 확률 값 저장\n",
    "\n",
    "# 예측 결과와 확률을 데이터프레임으로 저장\n",
    "pred_df = pd.DataFrame({\n",
    "    'ID': tst_dataset.df['ID'],\n",
    "    'target': preds_list\n",
    "})\n",
    "# 확률을 데이터프레임에 추가\n",
    "for i in range(num_classes):\n",
    "    pred_df[f'prob_class_{i}'] = [probs[i] for probs in probs_list]\n",
    "\n",
    "# 제출 형식 파일을 읽어와 ID 열이 일치하는지 확인\n",
    "sample_submission_df = pd.read_csv(\"/data/ephemeral/home/datasets_fin/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()\n",
    "\n",
    "# 예측 결과와 확률을 CSV 파일로 저장\n",
    "pred_df.to_csv(f\"{model_name}_{img_size}SIZE_{BATCH_SIZE}BATCH_{EPOCHS}EPOCH_0810_pred.csv\", index=False)\n",
    "print(pred_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [06:22<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ID  target\n",
      "0  0008fdb22ddce0ce.jpg       2\n",
      "1  00091bffdffd83de.jpg      12\n",
      "2  00396fbc1f6cc21d.jpg       5\n",
      "3  00471f8038d9c4b6.jpg      12\n",
      "4  00901f504008d884.jpg       2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageEnhance\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Albumentations transform 정의\n",
    "pre_img_size = 512  # 사전 정의된 이미지 크기 (필요에 따라 수정)\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.LongestMaxSize(max_size=pre_img_size, always_apply=True),\n",
    "    A.PadIfNeeded(min_height=pre_img_size, min_width=pre_img_size, border_mode=0, value=(255, 255, 255)),\n",
    "    # A.Resize(height=pre_img_size, width=pre_img_size),  # 모든 이미지를 같은 크기로 리사이징\n",
    "    #A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), 여기서 normalize넣으면 완전히 잘못됨 후에 또 하기 때문\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "\n",
    "class ImageDataset2(Dataset):\n",
    "    def __init__(self, csv_file, path, transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = idx % len(self.df)\n",
    "        name, target = self.df.iloc[real_idx]\n",
    "        img_path = os.path.join(self.path, name)\n",
    "        \n",
    "        try:\n",
    "            img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            img = np.zeros((pre_img_size, pre_img_size, 3), dtype=np.uint8)  # 빈 이미지로 대체\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n",
    "\n",
    "# TTA 변환 정의\n",
    "tta_transforms = [\n",
    "    A.Compose([\n",
    "        # A.GaussNoise(var_limit=(10.0, 800.0), p=0.75),\n",
    "        # A.GaussianBlur(blur_limit=(1, 7), p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        # A.GaussNoise(var_limit=(10.0, 800.0), p=0.75),\n",
    "        # A.GaussianBlur(blur_limit=(1, 7), p=0.5),\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        # A.GaussNoise(var_limit=(10.0, 800.0), p=0.75),\n",
    "        # A.GaussianBlur(blur_limit=(1, 7), p=0.5),\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        # A.GaussNoise(var_limit=(10.0, 800.0), p=0.75),\n",
    "        # A.GaussianBlur(blur_limit=(1, 7), p=0.5),\n",
    "        A.Transpose(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.Transpose(p=1.0),\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        # A.GaussNoise(var_limit=(10.0, 800.0), p=0.75),\n",
    "        # A.GaussianBlur(blur_limit=(1, 7), p=0.5),\n",
    "        A.Transpose(p=1.0),\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        # A.GaussNoise(var_limit=(10.0, 800.0), p=0.75),\n",
    "        # A.GaussianBlur(blur_limit=(1, 7), p=0.5),\n",
    "        A.Transpose(p=1.0),\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ]),\n",
    "    # A.Compose([\n",
    "    #     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    #     ToTensorV2()\n",
    "    # ])  # 원본 이미지\n",
    "]\n",
    "\n",
    "tta_dataset = ImageDataset2(\n",
    "    \"/data/ephemeral/home/datasets_fin/sample_submission.csv\",\n",
    "    \"/data/ephemeral/home/datasets_fin/test/\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "tta_loader = DataLoader(\n",
    "    tta_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# TTA inference function\n",
    "def tta_inference(loader, model, device, tta_transforms):\n",
    "    model.eval()\n",
    "    all_outputs = []\n",
    "    \n",
    "    weights = [0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2]  # 각 변환에 대한 가중치 설정\n",
    "    \n",
    "    for images, _ in tqdm(loader):\n",
    "        images = images.to(device).float()  # 이미지 텐서를 float 형식으로 변환\n",
    "        batch_outputs = torch.zeros(images.size(0), 17).to(device)  # 17은 클래스 수\n",
    "        \n",
    "        for weight, tta_transform in zip(weights, tta_transforms):\n",
    "            tta_images = []\n",
    "            for image in images:\n",
    "                tta_image = tta_transform(image=image.permute(1, 2, 0).cpu().numpy().astype(np.float32))['image']\n",
    "                tta_images.append(tta_image.to(device).float())\n",
    "            tta_images = torch.stack(tta_images)\n",
    "            with torch.no_grad():\n",
    "                preds = model(tta_images)\n",
    "                batch_outputs += weight * preds  # 가중치 적용\n",
    "        \n",
    "        # TTA 평균 내기 (Soft Voting)\n",
    "        batch_outputs /= len(tta_transforms)\n",
    "        \n",
    "        # 최종 예측 값을 리스트에 저장\n",
    "        all_outputs.append(batch_outputs.cpu().numpy())\n",
    "    \n",
    "    # 모든 배치의 예측 값을 연결\n",
    "    all_outputs = np.concatenate(all_outputs, axis=0)\n",
    "    return all_outputs\n",
    "\n",
    "# TTA를 적용한 예측\n",
    "all_outputs = tta_inference(tta_loader, model, device, tta_transforms)\n",
    "preds_list = np.argmax(all_outputs, axis=1)\n",
    "\n",
    "# 예측 결과를 데이터프레임으로 저장\n",
    "pred_df = pd.DataFrame(tta_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "\n",
    "# 제출 형식 파일을 읽어와 ID 열이 일치하는지 확인\n",
    "sample_submission_df = pd.read_csv(\"/data/ephemeral/home/datasets_fin/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()\n",
    "\n",
    "# 예측 결과를 CSV 파일로 저장\n",
    "pred_df.to_csv(f\"{model_name}_{pre_img_size}SIZE_{BATCH_SIZE}BATCH_{EPOCHS}EPOCH_0811_TTA_pred.csv\", index=False)\n",
    "print(pred_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "\n",
    "def load_predictions(file_paths):\n",
    "    \"\"\"여러 모델의 예측 결과를 로드합니다.\"\"\"\n",
    "    predictions = {}\n",
    "    for path in file_paths:\n",
    "        model_name = os.path.basename(path).split('.')[0]\n",
    "        df = pd.read_csv(path)\n",
    "        # ID 컬럼 중복 제거 및 예측 컬럼 이름 변경\n",
    "        df = df[['ID', 'target']].rename(columns={'target': model_name})\n",
    "        predictions[model_name] = df\n",
    "    return predictions\n",
    "\n",
    "def find_different_predictions(predictions):\n",
    "    \"\"\"모든 모델에서 다르게 예측한 항목을 찾습니다.\"\"\"\n",
    "    # 모든 예측을 하나의 DataFrame으로 병합\n",
    "    all_predictions = predictions[list(predictions.keys())[0]]\n",
    "    for model, df in list(predictions.items())[1:]:\n",
    "        all_predictions = pd.merge(all_predictions, df, on='ID', suffixes=('', f'_{model}'))\n",
    "    \n",
    "    # 예측 컬럼만 선택\n",
    "    prediction_columns = [col for col in all_predictions.columns if col != 'ID']\n",
    "    \n",
    "    # 예측이 다른 행만 선택\n",
    "    different_predictions = all_predictions[all_predictions[prediction_columns].nunique(axis=1) > 1]\n",
    "    return different_predictions\n",
    "\n",
    "def calculate_macro_f1(ground_truth, predictions):\n",
    "    \"\"\"Macro F1 점수를 계산합니다.\"\"\"\n",
    "    return f1_score(ground_truth, predictions, average='macro')\n",
    "\n",
    "def plot_error_distribution(ground_truth, predictions):\n",
    "    \"\"\"각 클래스별 오류 예측 개수를 bar plot으로 표시합니다.\"\"\"\n",
    "    # 클래스 이름 정의\n",
    "    class_names = {\n",
    "        0: \"계좌번호(손글씨)\", 1: \"임신출산 진료비 지급 신청서\", 2: \"자동차 계기판\", 3: \"입퇴원 확인서\", 4: \"진단서\", \n",
    "        5: \"운전면허증\", 6: \"진료비영수증\", 7: \"통원/진료 확인서\", 8: \"주민등록증\", 9: \"여권\", \n",
    "        10: \"진료비 납입 확인서\", 11: \"약제비 영수증\", 12: \"처방전\", 13: \"이력서\", 14: \"소견서\", \n",
    "        15: \"자동차 등록증\", 16: \"자동차 번호판\"\n",
    "    }\n",
    "\n",
    "    error_counts = {i: 0 for i in range(len(class_names))}  # 모든 클래스에 대해 초기화\n",
    "    for gt, pred in zip(ground_truth, predictions):\n",
    "        if gt != pred:\n",
    "            error_counts[gt] += 1\n",
    "    \n",
    "    classes = sorted(error_counts.keys())\n",
    "    counts = [error_counts[c] for c in classes]\n",
    "    class_labels = [f\"{c}\\n{class_names[c]}\" for c in classes]\n",
    "    \n",
    "    # 나눔 폰트 설정\n",
    "    # font_path = './font/NanumGothic.otf'\n",
    "    # font_prop = FontProperties(fname=font_path)\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    bars = plt.bar(class_labels, counts)\n",
    "    plt.title(\"오류 예측 개수 (클래스별)\", fontsize=16)# fontproperties=font_prop, \n",
    "    plt.xlabel(\"클래스\", fontsize=14)# fontproperties=font_prop, \n",
    "    plt.ylabel(\"오류 개수\", fontsize=14)# fontproperties=font_prop, \n",
    "    plt.xticks(rotation=45, ha='center')\n",
    "    \n",
    "    # x축 레이블에 폰트 적용\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels(class_labels, fontsize=10) # fontproperties=font_prop, \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 각 막대 위에 값 표시\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{height}',\n",
    "                 ha='center', va='bottom')# fontproperties=font_prop, \n",
    "    \n",
    "    plt.show()  \n",
    "    \n",
    "    \n",
    "def display_images_and_predictions(different_predictions, image_dir, ground_truth_name, prediction_name, class_filter=None, max_images_per_class=3):\n",
    "    \"\"\"다르게 예측된 항목의 이미지와 예측 결과를 표시합니다.\"\"\"\n",
    "    # 나눔 폰트 설정\n",
    "    # font_path = './font/NanumGothic.otf'\n",
    "    # font_prop = FontProperties(fname=font_path)\n",
    "    class_names = {\n",
    "        0: \"계좌번호(손글씨)\", 1: \"임신출산 진료비 지급 신청서\", 2: \"자동차 계기판\", 3: \"입퇴원 확인서\", 4: \"진단서\", \n",
    "        5: \"운전면허증\", 6: \"진료비영수증\", 7: \"통원/진료 확인서\", 8: \"주민등록증\", 9: \"여권\", \n",
    "        10: \"진료비 납입 확인서\", 11: \"약제비 영수증\", 12: \"처방전\", 13: \"이력서\", 14: \"소견서\", \n",
    "        15: \"자동차 등록증\", 16: \"자동차 번호판\"\n",
    "    }\n",
    "    \n",
    "    # 클래스별로 이미지 분류\n",
    "    class_images = {c: [] for c in range(len(class_names))}\n",
    "    for idx, row in different_predictions.iterrows():\n",
    "        ground_truth = row[ground_truth_name]\n",
    "        if class_filter is None or ground_truth in class_filter:\n",
    "            class_images[ground_truth].append(row)\n",
    "    \n",
    "    # 표시할 이미지 선택\n",
    "    images_to_display = []\n",
    "    for c, imgs in class_images.items():\n",
    "        if class_filter is None or c in class_filter:\n",
    "            images_to_display.extend(imgs[:max_images_per_class])\n",
    "    \n",
    "    # 이미지 표시\n",
    "    num_images = len(images_to_display)\n",
    "    rows = (num_images - 1) // 3 + 1\n",
    "    fig, axs = plt.subplots(rows, 4, figsize=(20, 5*rows))\n",
    "    \n",
    "    for i, row in enumerate(images_to_display):\n",
    "        ax = axs[i//4, i%4] if rows > 1 else axs[i%4]\n",
    "        \n",
    "        image_id = row['ID']\n",
    "        ground_truth = row[ground_truth_name]\n",
    "        prediction = row[prediction_name]\n",
    "        image_path = os.path.join(image_dir, image_id)\n",
    "        \n",
    "        if os.path.exists(image_path):\n",
    "            img = Image.open(image_path)\n",
    "            img = img.resize((300, 300), Image.LANCZOS)\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            id = f\"ID: {image_id}\"\n",
    "            comparison_text = f\"정답: {ground_truth} ({class_names[ground_truth]})\\n예측: {prediction} ({class_names[prediction]})\"\n",
    "            ax.set_title(f\"{id}\\n{comparison_text}\", fontsize=10) # fontproperties=font_prop, \n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f\"Image not found\\nfor ID: {image_id}\", ha='center', va='center')\n",
    "    \n",
    "    # 빈 서브플롯 제거\n",
    "    for i in range(num_images, rows*4):\n",
    "        ax = axs[i//4, i%4] if rows > 1 else axs[i%4]\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"총 {num_images}개의 이미지가 표시되었습니다.\")    \n",
    "\n",
    "# 예측 파일 경로\n",
    "file_paths = [\n",
    "    \"/data/ephemeral/home/notebook/EASY_pred_ocr_0811_9766_en14_final_submission.csv\",\n",
    "    # \"/data/ephemeral/home/notebook/efficientnet_b2.ra_in1k_384SIZE_32BATCH_2EPOCH_100_0806_PADOS_pred.csv\", # 수정해야할 부분\n",
    "    \"/data/ephemeral/home/notebook/tf_efficientnet_b5.ns_jft_in1k_456SIZE_8BATCH_5EPOCH_0811_pred_epoch4.csv\"\n",
    "]\n",
    "\n",
    "\n",
    "# 이미지 디렉토리 경로\n",
    "image_dir = \"/data/ephemeral/home/datasets_fin/test\"\n",
    "\n",
    "# 예측 로드\n",
    "predictions = load_predictions(file_paths)\n",
    "\n",
    "# 다른 예측 찾기\n",
    "different_predictions = find_different_predictions(predictions)\n",
    "\n",
    "# # 결과 출력\n",
    "# print(different_predictions)\n",
    "\n",
    "# Macro F1 점수 계산\n",
    "ground_truth_name = os.path.basename(file_paths[0]).split('.')[0]\n",
    "prediction_name = os.path.basename(file_paths[-1]).split('.')[0]\n",
    "ground_truth = predictions[ground_truth_name][ground_truth_name]\n",
    "prediction = predictions[prediction_name][prediction_name]\n",
    "macro_f1 = calculate_macro_f1(ground_truth, prediction)\n",
    "print(f\"Macro F1 Score: {macro_f1}\")\n",
    "\n",
    "# 오류 분포 그래프 표시\n",
    "plot_error_distribution(ground_truth, prediction)\n",
    "\n",
    "\n",
    "# 특정 클래스(예: 0, 1, 2)에 대해 클래스당 최대 3개씩 이미지 표시\n",
    "display_images_and_predictions(different_predictions, image_dir, ground_truth_name, prediction_name, class_filter=[1,2], max_images_per_class=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
