{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OliaDaX_lwou"
   },
   "source": [
    "## Contents\n",
    "- Import Library & Define Functions\n",
    "- Hyper-parameters\n",
    "- Load Data\n",
    "- Train Model\n",
    "- Inference & Save File\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## Import Library & Define Functions\n",
    "* 학습 및 추론에 필요한 라이브러리를 로드합니다.\n",
    "* 학습 및 추론에 필요한 함수와 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "from zoneinfo import ZoneInfo\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time = datetime.fromtimestamp(time.time(), tz=ZoneInfo(\"Asia/Seoul\")).strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_time\n",
    "\n",
    "wandb.init(project=\"document-classification\", name=f\"run-{train_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1700314772722,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "Hyl8oAy6TZAu"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 클래스를 정의합니다.\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None, augraphy_pipeline=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.augraphy_pipeline = augraphy_pipeline\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.data.iloc[idx, 0])\n",
    "        image = np.array(Image.open(img_name).convert('RGB'))\n",
    "        label = self.data.iloc[idx, 1]\n",
    "\n",
    "        if self.augraphy_pipeline:\n",
    "            image = self.augraphy_pipeline(image)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    return val_loss / len(val_loader), correct / total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## Hyper-parameters\n",
    "* 학습 및 추론에 필요한 하이퍼파라미터들을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = 'data/'\n",
    "\n",
    "# model config\n",
    "model_name = 'efficientnet_b0'\n",
    "\n",
    "# training config\n",
    "img_size = 224\n",
    "LR = 1e-3\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 16\n",
    "PATIENCE = 10\n",
    "FOLD = 2\n",
    "CLASS = 17\n",
    "\n",
    "# 설정 로깅\n",
    "wandb.config.update({\n",
    "    \"model\": model_name,\n",
    "    \"img_size\": img_size,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"num_workers\": num_workers,\n",
    "    'patience': PATIENCE,\n",
    "    'fold': FOLD\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## Load Data\n",
    "* 학습, 테스트 데이터셋과 로더를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "llh5C7ZKoq2S"
   },
   "outputs": [],
   "source": [
    "import augraphy\n",
    "from augraphy import *\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# augmentation을 위한 transform 코드\n",
    "def get_augraphy_pipeline():\n",
    "    return AugraphyPipeline([\n",
    "        BleedThrough(p=0.5),\n",
    "        DirtyRollers(p=0.5),\n",
    "        InkBleed(p=0.5),\n",
    "        Faxify(p=0.3),\n",
    "        NoiseTexturize(p=0.5),\n",
    "        Letterpress(p=0.5),\n",
    "        LowInkPeriodicLines(p=0.5),\n",
    "        LowInkRandomLines(p=0.5),\n",
    "        Folding(p=0.5),\n",
    "        Markup(p=0.3),  # PencilScribbles 대신\n",
    "        Stains(p=0.3),  # Watermark 대신\n",
    "        ])\n",
    "\n",
    "def get_train_transforms(height, width):\n",
    "    return A.Compose([\n",
    "        A.RandomResizedCrop(height=height, width=width, scale=(0.8, 1.0), ratio=(0.75, 1.3333333333333333)),\n",
    "        A.OneOf([\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.Rotate(limit=180, p=0.5),\n",
    "        ], p=0.7),\n",
    "        A.Flip(p=0.5),\n",
    "        A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.7),\n",
    "        A.GaussNoise(var_limit=(10.0, 150.0), p=0.5),\n",
    "        A.GaussianBlur(blur_limit=(3, 15), p=0.5),\n",
    "        A.OneOf([\n",
    "            A.OpticalDistortion(distort_limit=0.1, shift_limit=0.1, p=1.0),\n",
    "            A.GridDistortion(num_steps=5, distort_limit=0.1, p=1.0),\n",
    "        ], p=0.5),\n",
    "        A.ImageCompression(quality_lower=50, quality_upper=100, p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "def get_pred_transforms(height, width):\n",
    "    return A.Compose([\n",
    "        A.Resize(height=height, width=width),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700315112808,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "INxdmsStop2L",
    "outputId": "49f0d412-8ce6-4d2f-ae78-d5cf3d056340"
   },
   "outputs": [],
   "source": [
    "# Dataset 정의\n",
    "full_dataset = ImageDataset(\n",
    "        'data/train.csv',\n",
    "        'data/train/',\n",
    "        transform=get_train_transforms(img_size, img_size),\n",
    "        augraphy_pipeline=get_augraphy_pipeline()\n",
    "    )\n",
    "\n",
    "pred_dataset = ImageDataset(\n",
    "    \"data/sample_submission.csv\",\n",
    "    \"data/test/\",\n",
    "    transform=get_pred_transforms(img_size, img_size)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## Train Model\n",
    "* 모델을 로드하고, 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = timm.create_model(\n",
    "    model_name,\n",
    "    pretrained=True,\n",
    "    num_classes=CLASS\n",
    ").to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "def create_kfold_loaders(dataset, batch_size, num_workers, n_splits=5):\n",
    "    labels = [dataset[i][1] for i in range(len(dataset))]\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    train_loaders = []\n",
    "    val_loaders = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(labels)), labels)):\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_subset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_subset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        train_loaders.append(train_loader)\n",
    "        val_loaders.append(val_loader)\n",
    "        \n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Training samples: {len(train_subset)}\")\n",
    "        print(f\"  Validation samples: {len(val_subset)}\")\n",
    "    \n",
    "    return train_loaders, val_loaders\n",
    "\n",
    "train_loaders, val_loaders = create_kfold_loaders(full_dataset, BATCH_SIZE, num_workers, n_splits=FOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = (y_true == y_pred).mean()\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return accuracy, macro_f1\n",
    "\n",
    "def train_one_fold(fold, train_loader, val_loader, model, criterion, optimizer, device, num_epochs, patience):\n",
    "    best_val_f1 = 0\n",
    "    early_stopping_counter = 0\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "    train_f1_scores, val_f1_scores = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_preds, train_labels = [], []\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Fold {fold+1}, Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_preds.extend(predicted.cpu().numpy())\n",
    "            train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_accuracy, train_f1 = calculate_metrics(np.array(train_labels), np.array(train_preds))\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds, val_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=f\"Fold {fold+1}, Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_preds.extend(predicted.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_accuracy, val_f1 = calculate_metrics(np.array(val_labels), np.array(val_preds))\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        train_f1_scores.append(train_f1)\n",
    "        val_f1_scores.append(val_f1)\n",
    "\n",
    "        print(f\"Fold {fold+1}, Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Train F1: {train_f1:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "        wandb.log({\n",
    "            f\"fold_{fold+1}/train_loss\": train_loss,\n",
    "            f\"fold_{fold+1}/train_accuracy\": train_accuracy,\n",
    "            f\"fold_{fold+1}/train_f1\": train_f1,\n",
    "            f\"fold_{fold+1}/val_loss\": val_loss,\n",
    "            f\"fold_{fold+1}/val_accuracy\": val_accuracy,\n",
    "            f\"fold_{fold+1}/val_f1\": val_f1,\n",
    "            \"epoch\": epoch\n",
    "        })\n",
    "\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), f'model/{train_time}_fold{fold+1}_best.pt')\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "        if early_stopping_counter >= patience:\n",
    "            print(f\"Early stopping triggered after epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies, train_f1_scores, val_f1_scores\n",
    "\n",
    "def train_kfold(train_loaders, val_loaders, model_name, num_classes, device, num_epochs, patience):\n",
    "    all_train_losses, all_val_losses = [], []\n",
    "    all_train_accuracies, all_val_accuracies = [], []\n",
    "    all_train_f1_scores, all_val_f1_scores = [], []\n",
    "\n",
    "    for fold, (train_loader, val_loader) in enumerate(zip(train_loaders, val_loaders)):\n",
    "        print(f\"\\nTraining Fold {fold+1}\")\n",
    "\n",
    "        model = timm.create_model(model_name, pretrained=True, num_classes=num_classes).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = Adam(model.parameters(), lr=LR)\n",
    "\n",
    "        train_losses, val_losses, train_accuracies, val_accuracies, train_f1_scores, val_f1_scores = train_one_fold(\n",
    "            fold, train_loader, val_loader, model, criterion, optimizer, device, num_epochs, patience\n",
    "        )\n",
    "\n",
    "        all_train_losses.append(train_losses)\n",
    "        all_val_losses.append(val_losses)\n",
    "        all_train_accuracies.append(train_accuracies)\n",
    "        all_val_accuracies.append(val_accuracies)\n",
    "        all_train_f1_scores.append(train_f1_scores)\n",
    "        all_val_f1_scores.append(val_f1_scores)\n",
    "\n",
    "    return all_train_losses, all_val_losses, all_train_accuracies, all_val_accuracies, all_train_f1_scores, all_val_f1_scores\n",
    "\n",
    "results = train_kfold(train_loaders, val_loaders, model_name, CLASS, device, EPOCHS, PATIENCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 추가 라이브러리 import\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 결과 분석 및 시각화 함수들\n",
    "\n",
    "def plot_learning_curves(all_train_losses, all_val_losses, all_train_f1_scores, all_val_f1_scores):\n",
    "    num_folds = len(all_train_losses)\n",
    "    num_epochs = len(all_train_losses[0])\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 16))\n",
    "    \n",
    "    # Loss curves\n",
    "    for fold in range(num_folds):\n",
    "        ax1.plot(range(1, num_epochs+1), all_train_losses[fold], label=f'Fold {fold+1} Train')\n",
    "        ax1.plot(range(1, num_epochs+1), all_val_losses[fold], label=f'Fold {fold+1} Val')\n",
    "    \n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training and Validation Loss Curves')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # F1 score curves\n",
    "    for fold in range(num_folds):\n",
    "        ax2.plot(range(1, num_epochs+1), all_train_f1_scores[fold], label=f'Fold {fold+1} Train')\n",
    "        ax2.plot(range(1, num_epochs+1), all_val_f1_scores[fold], label=f'Fold {fold+1} Val')\n",
    "    \n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Macro F1 Score')\n",
    "    ax2.set_title('Training and Validation Macro F1 Score Curves')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the figure\n",
    "    fig.savefig('learning_curves.png')\n",
    "    wandb.log({\"learning_curves\": wandb.Image('learning_curves.png')})\n",
    "\n",
    "def plot_fold_comparison(all_val_accuracies, all_val_f1_scores):\n",
    "    num_folds = len(all_val_accuracies)\n",
    "    final_accuracies = [acc[-1] for acc in all_val_accuracies]\n",
    "    final_f1_scores = [f1[-1] for f1 in all_val_f1_scores]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Accuracy comparison\n",
    "    ax1.bar(range(1, num_folds+1), final_accuracies)\n",
    "    ax1.set_xlabel('Fold')\n",
    "    ax1.set_ylabel('Validation Accuracy')\n",
    "    ax1.set_title('Final Validation Accuracy by Fold')\n",
    "    ax1.set_ylim(0, 1)\n",
    "    \n",
    "    # F1 score comparison\n",
    "    ax2.bar(range(1, num_folds+1), final_f1_scores)\n",
    "    ax2.set_xlabel('Fold')\n",
    "    ax2.set_ylabel('Validation Macro F1 Score')\n",
    "    ax2.set_title('Final Validation Macro F1 Score by Fold')\n",
    "    ax2.set_ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the figure\n",
    "    fig.savefig('fold_comparison.png')\n",
    "    wandb.log({\"fold_comparison\": wandb.Image('fold_comparison.png')})\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    wandb.log({\"confusion_matrix\": wandb.Image('confusion_matrix.png')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def interpret_results(all_val_accuracies, all_val_f1_scores, final_accuracy, final_macro_f1, class_f1_scores):\n",
    "    mean_val_accuracy = np.mean([acc[-1] for acc in all_val_accuracies])\n",
    "    std_val_accuracy = np.std([acc[-1] for acc in all_val_accuracies])\n",
    "    mean_val_f1 = np.mean([f1[-1] for f1 in all_val_f1_scores])\n",
    "    std_val_f1 = np.std([f1[-1] for f1 in all_val_f1_scores])\n",
    "    \n",
    "    best_fold = np.argmax([f1[-1] for f1 in all_val_f1_scores]) + 1\n",
    "    worst_fold = np.argmin([f1[-1] for f1 in all_val_f1_scores]) + 1\n",
    "    \n",
    "    best_class = np.argmax(class_f1_scores)\n",
    "    worst_class = np.argmin(class_f1_scores)\n",
    "    \n",
    "    interpretation = f\"\"\"\n",
    "    결과 해석:\n",
    "    \n",
    "    1. 모델 성능:\n",
    "       - 평균 검증 정확도: {mean_val_accuracy:.4f} ± {std_val_accuracy:.4f}\n",
    "       - 평균 검증 Macro F1 점수: {mean_val_f1:.4f} ± {std_val_f1:.4f}\n",
    "       - 최종 테스트 정확도: {final_accuracy:.4f}\n",
    "       - 최종 테스트 Macro F1 점수: {final_macro_f1:.4f}\n",
    "       \n",
    "       해석: {'모델이 양호한 성능을 보입니다.' if final_macro_f1 > 0.7 else '모델 성능에 개선의 여지가 있습니다.'}\n",
    "       {'검증 세트와 테스트 세트의 성능 차이가 크지 않아 일반화가 잘 되었습니다.' if abs(mean_val_f1 - final_macro_f1) < 0.05 else '검증 세트와 테스트 세트의 성능 차이가 있어 추가적인 일반화 작업이 필요할 수 있습니다.'}\n",
    "    \n",
    "    2. 모델 일관성:\n",
    "       - 폴드 간 Macro F1 점수 표준편차: {std_val_f1:.4f}\n",
    "       - 최고 성능 폴드: {best_fold}, 최저 성능 폴드: {worst_fold}\n",
    "       \n",
    "       해석: {'폴드 간 성능 차이가 작아 모델이 안정적입니다.' if std_val_f1 < 0.05 else '폴드 간 성능 차이가 있어 모델의 안정성을 개선할 필요가 있습니다.'}\n",
    "    \n",
    "    3. 클래스별 성능:\n",
    "       - 최고 성능 클래스 (F1 점수): 클래스 {best_class} ({class_f1_scores[best_class]:.4f})\n",
    "       - 최저 성능 클래스 (F1 점수): 클래스 {worst_class} ({class_f1_scores[worst_class]:.4f})\n",
    "       \n",
    "       해석: {'클래스 간 성능 차이가 크지 않습니다.' if (class_f1_scores.max() - class_f1_scores.min()) < 0.2 else '클래스 간 성능 차이가 큽니다. 클래스 불균형 문제를 해결할 필요가 있습니다.'}\n",
    "    \n",
    "    4. 과적합 여부:\n",
    "       {'검증 세트와 테스트 세트의 성능이 비슷하여 과적합 문제는 크지 않아 보입니다.' if abs(mean_val_f1 - final_macro_f1) < 0.05 else '검증 세트와 테스트 세트의 성능 차이가 있어 과적합의 가능성이 있습니다.'}\n",
    "    \n",
    "    5. 개선 방안:\n",
    "    \"\"\"\n",
    "    \n",
    "    if final_macro_f1 < 0.7:\n",
    "        interpretation += \"   - 모델의 복잡도를 높이거나 학습률을 조정해 보세요.\\n\"\n",
    "        interpretation += \"   - 더 많은 에폭 동안 학습을 진행해 보세요.\\n\"\n",
    "    \n",
    "    if std_val_f1 > 0.05:\n",
    "        interpretation += \"   - 더 강력한 정규화 기법을 적용해 보세요 (예: L2 정규화, 드롭아웃 증가).\\n\"\n",
    "        interpretation += \"   - 데이터 증강 기법을 다양화하거나 강화해 보세요.\\n\"\n",
    "    \n",
    "    if abs(mean_val_f1 - final_macro_f1) > 0.05:\n",
    "        interpretation += \"   - 교차 검증 과정에서 조기 종료(early stopping)를 적용해 보세요.\\n\"\n",
    "        interpretation += \"   - 검증 세트의 크기를 늘려 보세요.\\n\"\n",
    "    \n",
    "    if (class_f1_scores.max() - class_f1_scores.min()) > 0.2:\n",
    "        interpretation += \"   - 클래스 가중치를 조정하거나 언더/오버 샘플링 기법을 적용해 보세요.\\n\"\n",
    "        interpretation += \"   - 성능이 낮은 클래스에 대해 추가 데이터를 수집하거나 데이터 증강을 강화해 보세요.\\n\"\n",
    "    \n",
    "    interpretation += \"   - 앙상블 기법을 적용하여 여러 모델의 예측을 결합해 보세요.\\n\"\n",
    "    \n",
    "    return interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_losses, all_val_losses, all_train_accuracies, all_val_accuracies, all_train_f1_scores, all_val_f1_scores = results\n",
    "\n",
    "# 학습 곡선 플롯\n",
    "plot_learning_curves(all_train_losses, all_val_losses, all_train_f1_scores, all_val_f1_scores)\n",
    "\n",
    "# 폴드 간 성능 비교 플롯\n",
    "plot_fold_comparison(all_val_accuracies, all_val_f1_scores)\n",
    "\n",
    "# 전체 데이터에 대한 예측 수행 (마지막 폴드의 모델 사용)\n",
    "model.load_state_dict(torch.load(f'model/{train_time}_fold{FOLD}_best.pt'))\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "pred_loader = DataLoader(pred_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(pred_loader, desc=\"Generating predictions\"):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# 혼동 행렬 플롯\n",
    "class_names = [str(i) for i in range(CLASS)]  # 클래스 이름이 있다면 이를 사용\n",
    "plot_confusion_matrix(all_labels, all_preds, class_names)\n",
    "\n",
    "# 클래스별 F1 점수 계산 및 출력\n",
    "class_f1_scores = f1_score(all_labels, all_preds, average=None)\n",
    "for i, f1 in enumerate(class_f1_scores):\n",
    "    print(f\"Class {i} F1 Score: {f1:.4f}\")\n",
    "    wandb.log({f\"class_{i}_f1_score\": f1})\n",
    "\n",
    "# 전체 테스트 세트에 대한 최종 성능 출력\n",
    "final_accuracy = accuracy_score(all_labels, all_preds)\n",
    "final_macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f\"Final Test Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Final Test Macro F1 Score: {final_macro_f1:.4f}\")\n",
    "\n",
    "wandb.log({\n",
    "    \"final_test_accuracy\": final_accuracy,\n",
    "    \"final_test_macro_f1\": final_macro_f1\n",
    "})\n",
    "\n",
    "# 결과 해석\n",
    "interpretation = interpret_results(all_val_accuracies, all_val_f1_scores, final_accuracy, final_macro_f1, class_f1_scores)\n",
    "print(interpretation)\n",
    "wandb.log({\"results_interpretation\": interpretation})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# Inference & Save File\n",
    "* 테스트 이미지에 대한 추론을 진행하고, 결과 파일을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_inference(model_name, num_folds, pred_loader, device):\n",
    "    print(\"Generating predictions for submission using k-fold models...\")\n",
    "    all_preds = []\n",
    "    \n",
    "    for fold in range(num_folds):\n",
    "        print(f\"Inferencing with fold {fold + 1} model\")\n",
    "        \n",
    "        # 각 폴드의 모델 로드\n",
    "        model = timm.create_model(model_name, pretrained=False, num_classes=CLASS).to(device)\n",
    "        model.load_state_dict(torch.load(f'model/{train_time}_fold{fold+1}_best.pt'))\n",
    "        model.eval()\n",
    "        \n",
    "        preds_list = []\n",
    "        \n",
    "        for batch in tqdm(pred_loaders[fold], desc=f\"Fold {fold+1} - Inference\"):\n",
    "            # pred_loader가 단일 값 반환 또는 두 개의 값 반환에 대응\n",
    "            if isinstance(batch, (list, tuple)):\n",
    "                image = batch[0]\n",
    "            else:\n",
    "                image = batch\n",
    "            \n",
    "            image = image.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                preds = model(image)\n",
    "            preds_list.extend(preds.softmax(dim=1).detach().cpu().numpy())\n",
    "        \n",
    "        all_preds.append(preds_list)\n",
    "    \n",
    "    # 모든 폴드의 예측을 평균하여 최종 예측 생성\n",
    "    final_preds = np.mean(all_preds, axis=0)\n",
    "    return final_preds.argmax(axis=1)\n",
    "\n",
    "pred_loaders = [\n",
    "    DataLoader(\n",
    "        pred_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    ) for _ in range(FOLD)  # 테스트 데이터는 모든 폴드에 대해 동일\n",
    "]\n",
    "\n",
    "preds_list = k_fold_inference(model_name, FOLD, pred_loaders, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1700315216829,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "aClN7Qi7VZoh"
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred_dataset.data, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315238836,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "VDBXQqAzVvLY"
   },
   "outputs": [],
   "source": [
    "# 결과 검증\n",
    "sample_submission_df = pd.read_csv(\"data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1700315244710,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "ePx2vCELVnuS"
   },
   "outputs": [],
   "source": [
    "submission_file_path = os.path.join('output', f'{train_time}.csv')\n",
    "pred_df.to_csv(submission_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1700315247734,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "9yMO8s6GqAwZ",
    "outputId": "9a30616f-f0ea-439f-a906-dd806737ce00"
   },
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
