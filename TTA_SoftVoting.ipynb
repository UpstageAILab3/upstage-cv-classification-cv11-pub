{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Numpy 배열을 pandas DataFrame으로 변환하여 고유 클래스 수를 확인\n",
    "df = pd.DataFrame(trn_dataset.df, columns=[\"name\", \"target\"])\n",
    "num_classes = df[\"target\"].nunique()\n",
    "class_counts = df['target'].value_counts().sort_index()\n",
    "target_count = class_counts.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import random\n",
    "\n",
    "\n",
    "# 학습에 사용할 장치를 설정합니다.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 학습 설정\n",
    "img_size = 224 \n",
    "LR = 1e-3\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "num_workers = 12  # 일단 0으로 설정하여 멀티프로세싱 비활성화\n",
    "early_stopping_patience = 5  # Early Stopping 설정\n",
    "augment_ratio_num = 100\n",
    "transform_probablity = 0.9\n",
    "\n",
    "model_path = 'tiny_vit_21m_384.dist_in22k_ft_in1k_384SIZE_16BATCH_5EPOCH_200_AUG_0.9_best_model.pth'\n",
    "# 모델 로드\n",
    "model_name = 'tiny_vit_21m_384.dist_in22k_ft_in1k'\n",
    "model = timm.create_model(model_name, pretrained=False, num_classes=17).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "\n",
    "img_size = 384\n",
    "# 기존 변환 설정\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# TTA를 위한 변환 설정\n",
    "tta_transforms = [\n",
    "    A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size, interpolation=1),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size, interpolation=1),\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size, interpolation=1),\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size, interpolation=1),\n",
    "        A.RandomRotate90(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size, interpolation=1),\n",
    "        A.GaussianBlur(blur_limit=(3, 5), p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size, interpolation=1),\n",
    "        A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size, interpolation=1),\n",
    "        A.MedianBlur(blur_limit=5, p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    \n",
    "    A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size, interpolation=1),\n",
    "        A.Downscale(scale_min=0.5, scale_max=0.75, p=1.0, interpolation=1),\n",
    "        A.Resize(height=img_size, width=img_size, interpolation=1),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size, interpolation=1),\n",
    "        A.RandomRotate90(p=0.8),\n",
    "        A.MedianBlur(blur_limit=5, p=0.8),\n",
    "        A.GaussianBlur(blur_limit=(3, 5), p=0.8),\n",
    "        A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.8),\n",
    "        A.VerticalFlip(p=0.8),\n",
    "        A.HorizontalFlip(p=0.8),\n",
    "        A.Rotate(limit=60, p=0.8),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size, interpolation=1),\n",
    "        A.RandomRotate90(p=0.8),\n",
    "        A.MedianBlur(blur_limit=5, p=0.8),\n",
    "        A.GaussianBlur(blur_limit=(3, 5), p=0.8),\n",
    "        A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.8),\n",
    "        A.VerticalFlip(p=0.8),\n",
    "        A.HorizontalFlip(p=0.8),\n",
    "        A.Rotate(limit=60, p=0.8),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size, interpolation=1),\n",
    "        A.RandomRotate90(p=0.8),\n",
    "        A.MedianBlur(blur_limit=5, p=0.8),\n",
    "        A.GaussianBlur(blur_limit=(3, 5), p=0.8),\n",
    "        A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.8),\n",
    "        A.VerticalFlip(p=0.8),\n",
    "        A.HorizontalFlip(p=0.8),\n",
    "        A.Rotate(limit=60, p=0.8),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size, interpolation=1),\n",
    "        A.RandomRotate90(p=0.8),\n",
    "        A.MedianBlur(blur_limit=5, p=0.8),\n",
    "        A.GaussianBlur(blur_limit=(3, 5), p=0.8),\n",
    "        A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.8),\n",
    "        A.VerticalFlip(p=0.8),\n",
    "        A.HorizontalFlip(p=0.8),\n",
    "        A.Rotate(limit=60, p=0.8),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]\n",
    "\n",
    "# Dataset 정의\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None, augment_ratios=None):\n",
    "        self.df = pd.read_csv(csv)\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.augment_ratios = augment_ratios\n",
    "        self.indices = self._get_augmented_indices()\n",
    "\n",
    "    def _get_augmented_indices(self):\n",
    "        indices = []\n",
    "        for i, row in self.df.iterrows():\n",
    "            label = row['target']\n",
    "            augment_count = self.augment_ratios.get(label, 1)\n",
    "            indices.extend([i] * augment_count)\n",
    "        return indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.indices[idx]\n",
    "        name, target = self.df.iloc[real_idx]\n",
    "        img_path = os.path.join(self.path, name)\n",
    "        \n",
    "        try:\n",
    "            img = np.array(Image.open(img_path))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            img = np.zeros((img_size, img_size, 3), dtype=np.uint8)  # 빈 이미지로 대체\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n",
    "\n",
    "# TTA를 적용한 예측을 수행하는 함수입니다.\n",
    "def tta_predict(model, loader, tta_transforms, device):\n",
    "    model.eval()\n",
    "    all_preds = np.zeros((len(loader.dataset), 17), dtype=np.float32)\n",
    "\n",
    "    for tta_transform in tta_transforms:\n",
    "        tta_dataset = ImageDataset(\"datasets_fin/sample_submission.csv\", \"datasets_fin/test/\", transform=tta_transform, augment_ratios={i: 1 for i in range(17)})\n",
    "        tta_loader = DataLoader(\n",
    "            tta_dataset,\n",
    "            batch_size=loader.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=loader.num_workers,\n",
    "            pin_memory=loader.pin_memory\n",
    "        )\n",
    "\n",
    "        tta_preds = []\n",
    "        for images, _ in tqdm(tta_loader):\n",
    "            images = images.to(device)\n",
    "            with torch.no_grad():\n",
    "                preds = model(images)\n",
    "            tta_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        tta_preds = np.array(tta_preds)\n",
    "        all_preds += tta_preds\n",
    "\n",
    "    all_preds /= len(tta_transforms)  # 평균을 사용합니다.\n",
    "    final_preds = np.argmax(all_preds, axis=1)  # 클래스 예측을 수행합니다.\n",
    "    return final_preds\n",
    "\n",
    "# 기존 데이터셋과 로더 정의\n",
    "tst_dataset = ImageDataset(\n",
    "    \"datasets_fin/sample_submission.csv\",\n",
    "    \"datasets_fin/test/\",\n",
    "    transform=tst_transform,\n",
    "    augment_ratios={i: 1 for i in range(17)}\n",
    ")\n",
    "\n",
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# TTA를 이용한 예측 수행\n",
    "preds_list = tta_predict(model, tst_loader, tta_transforms, device)\n",
    "\n",
    "# 예측 결과를 데이터프레임으로 저장합니다.\n",
    "pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "\n",
    "# 제출 형식 파일을 읽어와 ID 열이 일치하는지 확인합니다.\n",
    "sample_submission_df = pd.read_csv(\"datasets_fin/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()\n",
    "\n",
    "# 예측 결과를 CSV 파일로 저장합니다.\n",
    "# pred_df.to_csv(f\"{model_name}_{img_size}SIZE_{BATCH_SIZE}BATCH_{EPOCHS}EPOCH_{augment_ratio_num}AUG_TST_pred.csv\", index=False)\n",
    "pred_df.to_csv(f\"tiny_vit_21m_384.dist_in22k_ft_in1k_384SIZE_16BATCH_5EPOCH_200_AUG_0.9__TST_pred.csv\", index=False)\n",
    "print(pred_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [00:03<00:00, 53.47it/s]\n",
      "100%|██████████| 197/197 [00:03<00:00, 55.37it/s]\n",
      "100%|██████████| 197/197 [00:03<00:00, 55.54it/s]\n",
      "100%|██████████| 197/197 [00:03<00:00, 52.14it/s]\n",
      "100%|██████████| 197/197 [00:03<00:00, 53.39it/s]\n",
      "100%|██████████| 197/197 [00:03<00:00, 52.86it/s]\n",
      "100%|██████████| 197/197 [00:03<00:00, 49.38it/s]\n",
      "100%|██████████| 197/197 [00:04<00:00, 48.56it/s]\n",
      "100%|██████████| 197/197 [00:11<00:00, 16.85it/s]\n",
      "100%|██████████| 197/197 [00:11<00:00, 16.98it/s]\n",
      "100%|██████████| 197/197 [00:11<00:00, 16.94it/s]\n",
      "100%|██████████| 197/197 [00:11<00:00, 16.92it/s]\n",
      "100%|██████████| 197/197 [00:11<00:00, 16.90it/s]\n",
      "100%|██████████| 197/197 [00:11<00:00, 16.94it/s]\n",
      "100%|██████████| 197/197 [00:11<00:00, 16.87it/s]\n",
      "100%|██████████| 197/197 [00:11<00:00, 16.85it/s]\n",
      "100%|██████████| 197/197 [00:06<00:00, 31.79it/s]\n",
      "100%|██████████| 197/197 [00:06<00:00, 32.23it/s]\n",
      "100%|██████████| 197/197 [00:06<00:00, 32.42it/s]\n",
      "100%|██████████| 197/197 [00:06<00:00, 32.45it/s]\n",
      "100%|██████████| 197/197 [00:06<00:00, 32.54it/s]\n",
      "100%|██████████| 197/197 [00:06<00:00, 32.48it/s]\n",
      "100%|██████████| 197/197 [00:06<00:00, 31.97it/s]\n",
      "100%|██████████| 197/197 [00:06<00:00, 31.47it/s]\n",
      "100%|██████████| 197/197 [00:11<00:00, 17.36it/s]\n",
      "100%|██████████| 197/197 [00:11<00:00, 17.50it/s]\n",
      "100%|██████████| 197/197 [00:11<00:00, 17.52it/s]\n",
      "100%|██████████| 197/197 [00:11<00:00, 17.48it/s]\n",
      "100%|██████████| 197/197 [00:11<00:00, 17.49it/s]\n",
      "100%|██████████| 197/197 [00:11<00:00, 17.48it/s]\n",
      "100%|██████████| 197/197 [00:11<00:00, 17.49it/s]\n",
      "100%|██████████| 197/197 [00:11<00:00, 17.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ID  target\n",
      "0  0008fdb22ddce0ce.jpg       2\n",
      "1  00091bffdffd83de.jpg      12\n",
      "2  00396fbc1f6cc21d.jpg       5\n",
      "3  00471f8038d9c4b6.jpg      12\n",
      "4  00901f504008d884.jpg       2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import timm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 장치 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 모델 정보\n",
    "models_info = [\n",
    "    {\n",
    "        'path': 'efficientnet_b3.ra2_in1k_256SIZE_16BATCH_5EPOCH_200AUG_best_model.pth',\n",
    "        'arch': 'efficientnet_b3.ra2_in1k',\n",
    "        'img_size': 256\n",
    "    },\n",
    "    {\n",
    "        'path': 'efficientnet_b5.sw_in12k_ft_in1k_384SIZE_16BATCH_5EPOCH_200_AUG_0.8_best_model.pth',\n",
    "        'arch': 'efficientnet_b5.sw_in12k_ft_in1k',\n",
    "        'img_size': 384\n",
    "    },\n",
    "    {\n",
    "        'path': 'efficientnetv2_rw_m.agc_in1k_256SIZE_16BATCH_5EPOCH_200AUG_best_model.pth',\n",
    "        'arch': 'efficientnetv2_rw_m.agc_in1k',\n",
    "        'img_size': 256\n",
    "    },\n",
    "    {\n",
    "        'path': 'tiny_vit_21m_384.dist_in22k_ft_in1k_384SIZE_16BATCH_5EPOCH_200_AUG_0.9_best_model.pth',\n",
    "        'arch': 'tiny_vit_21m_384.dist_in22k_ft_in1k',\n",
    "        'img_size': 384\n",
    "    }\n",
    "]\n",
    "\n",
    "# Dataset 정의\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, path, transform=None):\n",
    "        self.df = df\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.path, name)\n",
    "        \n",
    "        try:\n",
    "            img = np.array(Image.open(img_path))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            img = np.zeros((img_size, img_size, 3), dtype=np.uint8)  # 빈 이미지로 대체\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n",
    "\n",
    "# TTA를 적용한 예측을 수행하는 함수입니다.\n",
    "def tta_predict(model, loader, tta_transforms, device):\n",
    "    model.eval()\n",
    "    all_preds = np.zeros((len(loader.dataset), model.num_classes), dtype=np.float32)\n",
    "\n",
    "    for tta_transform in tta_transforms:\n",
    "        tta_dataset = ImageDataset(loader.dataset.df, loader.dataset.path, transform=tta_transform)\n",
    "        tta_loader = DataLoader(\n",
    "            tta_dataset,\n",
    "            batch_size=loader.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=loader.num_workers,\n",
    "            pin_memory=loader.pin_memory\n",
    "        )\n",
    "\n",
    "        tta_preds = []\n",
    "        for images, _ in tqdm(tta_loader):\n",
    "            images = images.to(device)\n",
    "            with torch.no_grad():\n",
    "                preds = model(images)\n",
    "            tta_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        tta_preds = np.array(tta_preds)\n",
    "        all_preds += tta_preds\n",
    "\n",
    "    all_preds /= len(tta_transforms)  # 평균을 사용합니다.\n",
    "    return all_preds\n",
    "\n",
    "# 모델들의 예측 결과를 소프트 보팅으로 결합합니다.\n",
    "def soft_voting(models_info, csv_path, img_path, batch_size, num_workers):\n",
    "    final_preds = None\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    for model_info in models_info:\n",
    "        # 모델 로드\n",
    "        model = timm.create_model(model_info['arch'], pretrained=False, num_classes=17).to(device)\n",
    "        model.load_state_dict(torch.load(model_info['path'], map_location=device))\n",
    "\n",
    "        # TTA 변환 설정\n",
    "        img_size = model_info['img_size']\n",
    "        tta_transforms = [\n",
    "            A.Compose([\n",
    "                A.Resize(height=img_size, width=img_size),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            A.Compose([\n",
    "                A.Resize(height=img_size, width=img_size),\n",
    "                A.HorizontalFlip(p=1.0),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            A.Compose([\n",
    "                A.Resize(height=img_size, width=img_size),\n",
    "                A.VerticalFlip(p=1.0),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            A.Compose([\n",
    "                A.Resize(height=img_size, width=img_size),\n",
    "                A.RandomRotate90(p=1.0),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            A.Compose([\n",
    "                A.Resize(height=img_size, width=img_size),\n",
    "                A.GaussianBlur(blur_limit=(3, 5), p=1.0),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            A.Compose([\n",
    "                A.Resize(height=img_size, width=img_size),\n",
    "                A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=1.0),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            A.Compose([\n",
    "                A.Resize(height=img_size, width=img_size),\n",
    "                A.MedianBlur(blur_limit=5, p=1.0),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            A.Compose([\n",
    "                A.Resize(height=img_size, width=img_size),\n",
    "                A.Downscale(scale_min=0.5, scale_max=0.75, p=1.0, interpolation=1),\n",
    "                A.Resize(height=img_size, width=img_size),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            A.Compose([\n",
    "                A.Resize(height=img_size, width=img_size, interpolation=1),\n",
    "                A.RandomRotate90(p=0.8),\n",
    "                A.MedianBlur(blur_limit=5, p=0.8),\n",
    "                A.GaussianBlur(blur_limit=(3, 5), p=0.8),\n",
    "                A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.8),\n",
    "                A.VerticalFlip(p=0.8),\n",
    "                A.HorizontalFlip(p=0.8),\n",
    "                A.Rotate(limit=60, p=0.8),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            A.Compose([\n",
    "                A.Resize(height=img_size, width=img_size, interpolation=1),\n",
    "                A.RandomRotate90(p=0.8),\n",
    "                A.MedianBlur(blur_limit=5, p=0.8),\n",
    "                A.GaussianBlur(blur_limit=(3, 5), p=0.8),\n",
    "                A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.8),\n",
    "                A.VerticalFlip(p=0.8),\n",
    "                A.HorizontalFlip(p=0.8),\n",
    "                A.Rotate(limit=60, p=0.8),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            A.Compose([\n",
    "                A.Resize(height=img_size, width=img_size, interpolation=1),\n",
    "                A.RandomRotate90(p=0.8),\n",
    "                A.MedianBlur(blur_limit=5, p=0.8),\n",
    "                A.GaussianBlur(blur_limit=(3, 5), p=0.8),\n",
    "                A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.8),\n",
    "                A.VerticalFlip(p=0.8),\n",
    "                A.HorizontalFlip(p=0.8),\n",
    "                A.Rotate(limit=60, p=0.8),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            A.Compose([\n",
    "                A.Resize(height=img_size, width=img_size, interpolation=1),\n",
    "                A.RandomRotate90(p=0.8),\n",
    "                A.MedianBlur(blur_limit=5, p=0.8),\n",
    "                A.GaussianBlur(blur_limit=(3, 5), p=0.8),\n",
    "                A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.8),\n",
    "                A.VerticalFlip(p=0.8),\n",
    "                A.HorizontalFlip(p=0.8),\n",
    "                A.Rotate(limit=60, p=0.8),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "        ]\n",
    "\n",
    "        # 데이터셋 및 로더 정의\n",
    "        dataset = ImageDataset(df, img_path, transform=tta_transforms[0])\n",
    "        loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "        # TTA 예측\n",
    "        preds = tta_predict(model, loader, tta_transforms, device)\n",
    "\n",
    "        if final_preds is None:\n",
    "            final_preds = preds\n",
    "        else:\n",
    "            final_preds += preds\n",
    "\n",
    "    final_preds /= len(models_info)  # 모델의 평균 예측을 사용합니다.\n",
    "    final_preds = np.argmax(final_preds, axis=1)  # 클래스 예측을 수행합니다.\n",
    "    return final_preds\n",
    "\n",
    "# CSV 경로 및 이미지 경로\n",
    "csv_path = \"datasets_fin/sample_submission.csv\"\n",
    "img_path = \"datasets_fin/test/\"\n",
    "\n",
    "# 소프트 보팅을 통한 최종 예측 수행\n",
    "final_preds = soft_voting(models_info, csv_path, img_path, batch_size=16, num_workers=4)\n",
    "\n",
    "# 예측 결과를 데이터프레임으로 저장합니다.\n",
    "sample_submission_df = pd.read_csv(csv_path)\n",
    "sample_submission_df['target'] = final_preds\n",
    "\n",
    "# 예측 결과를 CSV 파일로 저장합니다.\n",
    "sample_submission_df.to_csv(\"final_submission.csv\", index=False)\n",
    "print(sample_submission_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
