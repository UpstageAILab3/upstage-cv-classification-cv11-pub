{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import common\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_soft_voting = True\n",
    "augment_ratio = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_targets_count():\n",
    "    sample_submission_df = pd.read_csv(\"datasets_fin/sample_submission.csv\")\n",
    "    return len(sample_submission_df)\n",
    "    \n",
    "def hard_voting(predictions):\n",
    "    predictions = np.asarray(predictions)\n",
    "    return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
    "\n",
    "def soft_voting(predictions):\n",
    "    predictions = np.asarray(predictions)\n",
    "    mean_axis0 = np.mean(predictions, axis=0)\n",
    "    \n",
    "    # 증강된 데이터에 대한 예측값도 고려하기.\n",
    "    all_targets_count = get_all_targets_count()\n",
    "    \n",
    "    aug_size = len(mean_axis0) / all_targets_count\n",
    "    assert len(mean_axis0) % all_targets_count == 0\n",
    "    aug_size = int(aug_size)\n",
    "    \n",
    "    if aug_size > 1:\n",
    "        bulk_list = []\n",
    "        step = 0\n",
    "        \n",
    "        for i in range(0, aug_size):\n",
    "            bulk_list.append(mean_axis0[step:step + all_targets_count])\n",
    "            step += all_targets_count\n",
    "        \n",
    "        bulk_list = np.asarray(bulk_list)\n",
    "        mean_axis0 = np.mean(bulk_list, axis=0)\n",
    "        \n",
    "    return mean_axis0.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_1_file_list = [\n",
    "    'model_bak3/cp-densenet121.ra_in1k_sd_42_epc_1_aug_200_vl_0.3414_va_0.9158_vf1_0.9147_fold_1_folds_2.pt',\n",
    "    'model_bak3/cp-densenet121.ra_in1k_sd_42_epc_2_aug_200_vl_0.3114_va_0.9193_vf1_0.9192_fold_1_folds_2.pt',\n",
    "    'model_bak3/cp-densenet121.ra_in1k_sd_42_epc_3_aug_200_vl_0.4536_va_0.9146_vf1_0.9121_fold_1_folds_2.pt',\n",
    "    'model_bak3/cp-densenet121.ra_in1k_sd_42_epc_4_aug_200_vl_0.4589_va_0.9204_vf1_0.9195_fold_1_folds_2_PICK.pt',\n",
    "    'model_bak3/cp-densenet121.ra_in1k_sd_42_epc_5_aug_200_vl_0.6567_va_0.8950_vf1_0.8920_fold_1_folds_2.pt',\n",
    "    'model_bak3/cp-densenet121.ra_in1k_sd_42_epc_6_aug_200_vl_0.6449_va_0.8916_vf1_0.8892_fold_1_folds_2.pt',\n",
    "]\n",
    "\n",
    "fold_2_file_list = [\n",
    "    'model_bak3/cp-densenet121.ra_in1k_sd_42_epc_1_aug_200_vl_0.3597_va_0.8939_vf1_0.8987_fold_2_folds_2.pt',\n",
    "    'model_bak3/cp-densenet121.ra_in1k_sd_42_epc_2_aug_200_vl_0.4646_va_0.8754_vf1_0.8716_fold_2_folds_2.pt',\n",
    "    'model_bak3/cp-densenet121.ra_in1k_sd_42_epc_3_aug_200_vl_0.5112_va_0.8939_vf1_0.8987_fold_2_folds_2.pt',\n",
    "    'model_bak3/cp-densenet121.ra_in1k_sd_42_epc_4_aug_200_vl_0.4933_va_0.9262_vf1_0.9213_fold_2_folds_2.pt',\n",
    "    'model_bak3/cp-densenet121.ra_in1k_sd_42_epc_5_aug_200_vl_0.6814_va_0.9077_vf1_0.9041_fold_2_folds_2.pt',\n",
    "    'model_bak3/cp-densenet121.ra_in1k_sd_42_epc_6_aug_200_vl_0.8049_va_0.9031_vf1_0.9027_fold_2_folds_2_PICK.pt',\n",
    "    'model_bak3/cp-densenet121.ra_in1k_sd_42_epc_7_aug_200_vl_0.4791_va_0.9135_vf1_0.9131_fold_2_folds_2.pt',\n",
    "    'model_bak3/cp-densenet121.ra_in1k_sd_42_epc_8_aug_200_vl_0.6528_va_0.9008_vf1_0.8995_fold_2_folds_2.pt',\n",
    "    'model_bak3/cp-densenet121.ra_in1k_sd_42_epc_9_aug_200_vl_0.8085_va_0.9031_vf1_0.9043_fold_2_folds_2.pt',\n",
    "    'model_bak3/cp-densenet121.ra_in1k_sd_42_epc_10_aug_200_vl_0.5794_va_0.9239_vf1_0.9237_fold_2_folds_2.pt',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_1 = 0\n",
    "cnt_2 = 0\n",
    "\n",
    "for fold_1_filename in fold_1_file_list:\n",
    "    for fold_2_filename in fold_2_file_list:\n",
    "        print(f'fold 1 filename: {fold_1_filename}')\n",
    "        print(f'fold 2 filename: {fold_2_filename}')\n",
    "        \n",
    "        model_checkpoint_filename_list = [\n",
    "            fold_1_filename,\n",
    "            fold_2_filename,\n",
    "        ]\n",
    "\n",
    "        model_list = []\n",
    "        tst_loader_list = []\n",
    "\n",
    "        for cp_filename in model_checkpoint_filename_list:\n",
    "            checkpoint = torch.load(cp_filename, map_location = device)\n",
    "            \n",
    "            print(checkpoint['model'], checkpoint['tst_img_size'], checkpoint['batch_size'])\n",
    "            \n",
    "            model = timm.create_model(\n",
    "                checkpoint['model'],\n",
    "                pretrained = True,\n",
    "                num_classes = 17,\n",
    "            ).to(device)\n",
    "            \n",
    "            model.load_state_dict(checkpoint['model_state_dict'])    \n",
    "            model_list.append(model)\n",
    "            \n",
    "            ##\n",
    "            tst_transform = common.create_tst_transform(checkpoint['tst_img_size'])\n",
    "            tst_aug_transform = common.create_trn_aug_transform(checkpoint['tst_img_size'])\n",
    "\n",
    "            # tst_dataset = common.ImageDataset(\n",
    "            #     \"datasets_fin/sample_submission.csv\",\n",
    "            #     \"datasets_fin/test/\",\n",
    "            #     transform = tst_transform\n",
    "            # )\n",
    "            \n",
    "            tst_dataset = common.ImageDataset(\n",
    "                \"datasets_fin/sample_submission.csv\",\n",
    "                \"datasets_fin/test/\",\n",
    "                transform=tst_transform, \n",
    "                aug_transform=tst_aug_transform, \n",
    "                augment_ratio=augment_ratio)\n",
    "\n",
    "            tst_loader = DataLoader(\n",
    "                tst_dataset,\n",
    "                batch_size = checkpoint['batch_size'],\n",
    "                shuffle = False,\n",
    "                num_workers = 12,\n",
    "                pin_memory = True\n",
    "            )\n",
    "            \n",
    "            tst_loader_list.append(tst_loader)\n",
    "\n",
    "        print(len(model_list), len(tst_loader_list))\n",
    "        \n",
    "        preds_list = []\n",
    "\n",
    "        for model, tst_loader in zip(model_list, tst_loader_list):\n",
    "            preds = common.get_preds_list_by_tst_loader(model, tst_loader, device, is_soft_voting)\n",
    "            preds_list.append(preds)\n",
    "        \n",
    "        # 최종 예측\n",
    "        if is_soft_voting:\n",
    "            final_pred = soft_voting(preds_list)\n",
    "        else:\n",
    "            final_pred = hard_voting(preds_list)\n",
    "\n",
    "        # csv 로 저장\n",
    "        csv_filename = f'pred_0808_hoho_{cnt_1}_{cnt_2}.csv'\n",
    "        common.preds_list_to_save_to_csv(final_pred, tst_loader, csv_filename)\n",
    "        print(f'prediction save to {csv_filename}.')\n",
    "        print()\n",
    "        \n",
    "        cnt_2 += 1\n",
    "    \n",
    "    cnt_1 += 1\n",
    "    cnt_2 = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
