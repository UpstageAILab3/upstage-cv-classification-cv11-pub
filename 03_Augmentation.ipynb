{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"OliaDaX_lwou"},"source":["# **ğŸ“„ Document type classification baseline code**\n","> ë¬¸ì„œ íƒ€ì… ë¶„ë¥˜ ëŒ€íšŒì— ì˜¤ì‹  ì—¬ëŸ¬ë¶„ í™˜ì˜í•©ë‹ˆë‹¤! ğŸ‰     \n","> ì•„ë˜ baselineì—ì„œëŠ” ResNet ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬, ëª¨ë¸ì„ í•™ìŠµ ë° ì˜ˆì¸¡ íŒŒì¼ ìƒì„±í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.\n","\n","## Contents\n","- Prepare Environments\n","- Import Library & Define Functions\n","- Hyper-parameters\n","- Load Data\n","- Train Model\n","- Inference & Save File\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"zkH9T_86lDSS"},"source":["## 1. Prepare Environments\n","\n","* ë°ì´í„° ë¡œë“œë¥¼ ìœ„í•œ êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ ë§ˆìš´íŠ¸í•©ë‹ˆë‹¤.\n","* í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PXa_FPM73R9f"},"source":["## 2. Import Library & Define Functions\n","* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n","* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•¨ìˆ˜ì™€ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":9396,"status":"ok","timestamp":1700314592802,"user":{"displayName":"Ynot(ì†¡ì›í˜¸)","userId":"16271863862696372773"},"user_tz":-540},"id":"3BaoIkv5Xwa0"},"outputs":[],"source":["import os\n","import time\n","import random\n","\n","import timm\n","import torch\n","import albumentations as A\n","import pandas as pd\n","import numpy as np\n","import torch.nn as nn\n","from albumentations.pytorch import ToTensorV2\n","from torch.optim import Adam\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score, f1_score"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import json\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay # sklearn ë‚´ confusion matrix ê³„ì‚° í•¨ìˆ˜\n","import matplotlib.pyplot as plt # ì‹œê°í™”ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","import torchvision.transforms as T # ì´ë¯¸ì§€ ë³€í™˜ì„ ìœ„í•œ ëª¨ë“ˆ"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n","SEED = 42\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","torch.backends.cudnn.benchmark = True"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":241,"status":"ok","timestamp":1700314772722,"user":{"displayName":"Ynot(ì†¡ì›í˜¸)","userId":"16271863862696372773"},"user_tz":-540},"id":"Hyl8oAy6TZAu"},"outputs":[],"source":["# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n","class ImageDataset(Dataset):\n","    def __init__(self, csv, path, transform=None):\n","        self.df = pd.read_csv(csv).values\n","        self.path = path\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        name, target = self.df[idx]\n","        img = np.array(Image.open(os.path.join(self.path, name)))\n","        if self.transform:\n","            img = self.transform(image=img)['image']\n","        return img, target"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":255,"status":"ok","timestamp":1700315066028,"user":{"displayName":"Ynot(ì†¡ì›í˜¸)","userId":"16271863862696372773"},"user_tz":-540},"id":"kTECBJfVTbdl"},"outputs":[],"source":["# one epoch í•™ìŠµì„ ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.\n","def train_one_epoch(loader, model, optimizer, loss_fn, device):\n","    model.train()\n","    train_loss = 0\n","    preds_list = []\n","    targets_list = []\n","\n","    pbar = tqdm(loader)\n","    for image, targets in pbar:\n","        image = image.to(device)\n","        targets = targets.to(device)\n","\n","        model.zero_grad(set_to_none=True)\n","\n","        preds = model(image)\n","        loss = loss_fn(preds, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n","        targets_list.extend(targets.detach().cpu().numpy())\n","\n","        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n","\n","    train_loss /= len(loader)\n","    train_acc = accuracy_score(targets_list, preds_list)\n","    train_f1 = f1_score(targets_list, preds_list, average='macro')\n","\n","    ret = {\n","        \"train_loss\": train_loss,\n","        \"train_acc\": train_acc,\n","        \"train_f1\": train_f1,\n","    }\n","\n","    return ret"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Wjom43UvoXcx"},"source":["## 3. Hyper-parameters\n","* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":436,"status":"ok","timestamp":1700315112439,"user":{"displayName":"Ynot(ì†¡ì›í˜¸)","userId":"16271863862696372773"},"user_tz":-540},"id":"KByfAeRmXwYk"},"outputs":[],"source":["# device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# data config\n","data_path = '/data/ephemeral/home/datasets_fin/'\n","\n","# model config\n","model_name = 'efficientnet_b3.ra2_in1k'#'densenet121.ra_in1k'# #'resnet101' #'resnet34' # 'resnet50' 'efficientnet-b0', ...\n","\n","# training config\n","img_size = 256\n","LR = 1e-3\n","EPOCHS = 1\n","BATCH_SIZE = 32\n","num_workers = 0"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"amum-FlIojc6"},"source":["## 4. Load Data\n","* í•™ìŠµ, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ê³¼ ë¡œë”ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["# https://lcyking.tistory.com/entry/Albumentations%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A6%9D%EA%B0%95-%EC%9D%B4%ED%95%B4\n","from PIL import Image\n","import numpy as np\n","import torch\n","from albumentations import Compose, Resize, RandomCrop, HorizontalFlip, Rotate, VerticalFlip, RandomRotate90, ShiftScaleRotate, GaussNoise, Cutout, CLAHE, Blur\n","\n","def create_augmentations():\n","    return Compose([\n","        #Resize(height=224, width=224),\n","        #RandomCrop(height=200, width=200), ì‚¬ìš©ë¶ˆê°€\n","        #Rotate(limit=90, p=1), #1\n","        #HorizontalFlip(p=0.5), #2\n","        #VerticalFlip(p=0.5), #3\n","        #RandomRotate90(p=1), #4\n","        #ShiftScaleRotate(shift_limit=0, scale_limit=(0.9, 1), rotate_limit=20, p=1), ì‚¬ìš©ë¶ˆê°€\n","        #ShiftScaleRotate(shift_limit=0, scale_limit=(0.5, 0.9), rotate_limit=0, p=1), # Only_Scale\n","        #ShiftScaleRotate(shift_limit=(0.4, 0.5), scale_limit=0, rotate_limit=0, p=1), # Only_Shift\n","        GaussNoise(p=1, var_limit=(600, 800)), #5\n","        #Cutout(p=1, num_holes=8, max_h_size=24, max_w_size=24),\n","        #Blur(p=1, blur_limit=(3, 5)) #6\n","        #CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=1) ì‚¬ìš©ì•ˆí•¨\n","    ])\n","\n","def to_tensor(image_np):\n","    return torch.tensor(image_np).permute(2, 0, 1).float() / 255.0\n","\n","def augment_and_save_image(image_path, save_dir, num_copies=1):\n","    image = Image.open(image_path).convert('RGB')  # RGBAë¥¼ RGBë¡œ ëª…ì‹œì  ë³€í™˜\n","    image_np = np.array(image)\n","\n","    if image_np.dtype != np.uint8:\n","        print(f\"Data type mismatch in image {image_path}, found {image_np.dtype}, expected uint8.\")\n","        return\n","    \n","    augmentation = create_augmentations()\n","    augmented_images = [augmentation(image=image_np) for _ in range(num_copies)]\n","\n","    for i, aug in enumerate(augmented_images):\n","        tensor_image = to_tensor(aug['image'])\n","        image_np = tensor_image.permute(1, 2, 0).numpy()  # CHW -> HWC\n","        image_np = (image_np * 255).astype(np.uint8)  # ë°ì´í„° ìŠ¤ì¼€ì¼ ë³µêµ¬\n","        augmented_image = Image.fromarray(image_np)  # numpy ë°°ì—´ì„ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜\n","        save_path = os.path.join(save_dir, f\"{os.path.splitext(os.path.basename(image_path))[0]}_9.jpg\")\n","        augmented_image.save(save_path)  # ì´ë¯¸ì§€ ì €ì¥\n","\n","# ì‚¬ìš© ì˜ˆì‹œ\n","import os\n","\n","image_dir = '/data/ephemeral/home/datasets_fin/HorizontalFlip'\n","save_dir = '/data/ephemeral/home/datasets_fin/HorizontalFlip_GaussNoise'\n","if not os.path.exists(save_dir):\n","     os.makedirs(save_dir)\n","\n","for filename in os.listdir(image_dir):\n","    if filename.endswith('.jpg'):\n","        augment_and_save_image(os.path.join(image_dir, filename), save_dir)\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
