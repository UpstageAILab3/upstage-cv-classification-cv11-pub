{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"OliaDaX_lwou"},"source":["# **📄 Document type classification baseline code**\n","> 문서 타입 분류 대회에 오신 여러분 환영합니다! 🎉     \n","> 아래 baseline에서는 ResNet 모델을 로드하여, 모델을 학습 및 예측 파일 생성하는 프로세스에 대해 알아보겠습니다.\n","\n","## Contents\n","- Prepare Environments\n","- Import Library & Define Functions\n","- Hyper-parameters\n","- Load Data\n","- Train Model\n","- Inference & Save File\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"zkH9T_86lDSS"},"source":["## 1. Prepare Environments\n","\n","* 데이터 로드를 위한 구글 드라이브를 마운트합니다.\n","* 필요한 라이브러리를 설치합니다."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PXa_FPM73R9f"},"source":["## 2. Import Library & Define Functions\n","* 학습 및 추론에 필요한 라이브러리를 로드합니다.\n","* 학습 및 추론에 필요한 함수와 클래스를 정의합니다."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":9396,"status":"ok","timestamp":1700314592802,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"3BaoIkv5Xwa0"},"outputs":[],"source":["import os\n","import time\n","import random\n","\n","import timm\n","import torch\n","import albumentations as A\n","import pandas as pd\n","import numpy as np\n","import torch.nn as nn\n","from albumentations.pytorch import ToTensorV2\n","from torch.optim import Adam\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score, f1_score"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import json\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay # sklearn 내 confusion matrix 계산 함수\n","import matplotlib.pyplot as plt # 시각화를 위한 라이브러리\n","import torchvision.transforms as T # 이미지 변환을 위한 모듈"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# 시드를 고정합니다.\n","SEED = 42\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","torch.backends.cudnn.benchmark = True"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":241,"status":"ok","timestamp":1700314772722,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"Hyl8oAy6TZAu"},"outputs":[],"source":["# 데이터셋 클래스를 정의합니다.\n","class ImageDataset(Dataset):\n","    def __init__(self, csv, path, transform=None):\n","        self.df = pd.read_csv(csv).values\n","        self.path = path\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        name, target = self.df[idx]\n","        img = np.array(Image.open(os.path.join(self.path, name)))\n","        if self.transform:\n","            img = self.transform(image=img)['image']\n","        return img, target"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":255,"status":"ok","timestamp":1700315066028,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"kTECBJfVTbdl"},"outputs":[],"source":["# one epoch 학습을 위한 함수입니다.\n","def train_one_epoch(loader, model, optimizer, loss_fn, device):\n","    model.train()\n","    train_loss = 0\n","    preds_list = []\n","    targets_list = []\n","\n","    pbar = tqdm(loader)\n","    for image, targets in pbar:\n","        image = image.to(device)\n","        targets = targets.to(device)\n","\n","        model.zero_grad(set_to_none=True)\n","\n","        preds = model(image)\n","        loss = loss_fn(preds, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n","        targets_list.extend(targets.detach().cpu().numpy())\n","\n","        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n","\n","    train_loss /= len(loader)\n","    train_acc = accuracy_score(targets_list, preds_list)\n","    train_f1 = f1_score(targets_list, preds_list, average='macro')\n","\n","    ret = {\n","        \"train_loss\": train_loss,\n","        \"train_acc\": train_acc,\n","        \"train_f1\": train_f1,\n","    }\n","\n","    return ret"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Wjom43UvoXcx"},"source":["## 3. Hyper-parameters\n","* 학습 및 추론에 필요한 하이퍼파라미터들을 정의합니다."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":436,"status":"ok","timestamp":1700315112439,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"KByfAeRmXwYk"},"outputs":[],"source":["# device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# data config\n","data_path = '/data/ephemeral/home/datasets_fin/'\n","\n","# model config\n","model_name = 'efficientnet_b3.ra2_in1k'#'densenet121.ra_in1k'# #'resnet101' #'resnet34' # 'resnet50' 'efficientnet-b0', ...\n","\n","# training config\n","img_size = 256\n","LR = 1e-3\n","EPOCHS = 1\n","BATCH_SIZE = 32\n","num_workers = 0"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"amum-FlIojc6"},"source":["## 4. Load Data\n","* 학습, 테스트 데이터셋과 로더를 정의합니다."]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["# https://lcyking.tistory.com/entry/Albumentations%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A6%9D%EA%B0%95-%EC%9D%B4%ED%95%B4\n","from PIL import Image\n","import numpy as np\n","import torch\n","from albumentations import Compose, Resize, RandomCrop, HorizontalFlip, Rotate, VerticalFlip, RandomRotate90, ShiftScaleRotate, GaussNoise, Cutout, CLAHE, Blur\n","\n","def create_augmentations():\n","    return Compose([\n","        #Resize(height=224, width=224),\n","        #RandomCrop(height=200, width=200), 사용불가\n","        #Rotate(limit=90, p=1), #1\n","        #HorizontalFlip(p=0.5), #2\n","        #VerticalFlip(p=0.5), #3\n","        #RandomRotate90(p=1), #4\n","        #ShiftScaleRotate(shift_limit=0, scale_limit=(0.9, 1), rotate_limit=20, p=1), 사용불가\n","        #ShiftScaleRotate(shift_limit=0, scale_limit=(0.5, 0.9), rotate_limit=0, p=1), # Only_Scale\n","        #ShiftScaleRotate(shift_limit=(0.4, 0.5), scale_limit=0, rotate_limit=0, p=1), # Only_Shift\n","        GaussNoise(p=1, var_limit=(600, 800)), #5\n","        #Cutout(p=1, num_holes=8, max_h_size=24, max_w_size=24),\n","        #Blur(p=1, blur_limit=(3, 5)) #6\n","        #CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=1) 사용안함\n","    ])\n","\n","def to_tensor(image_np):\n","    return torch.tensor(image_np).permute(2, 0, 1).float() / 255.0\n","\n","def augment_and_save_image(image_path, save_dir, num_copies=1):\n","    image = Image.open(image_path).convert('RGB')  # RGBA를 RGB로 명시적 변환\n","    image_np = np.array(image)\n","\n","    if image_np.dtype != np.uint8:\n","        print(f\"Data type mismatch in image {image_path}, found {image_np.dtype}, expected uint8.\")\n","        return\n","    \n","    augmentation = create_augmentations()\n","    augmented_images = [augmentation(image=image_np) for _ in range(num_copies)]\n","\n","    for i, aug in enumerate(augmented_images):\n","        tensor_image = to_tensor(aug['image'])\n","        image_np = tensor_image.permute(1, 2, 0).numpy()  # CHW -> HWC\n","        image_np = (image_np * 255).astype(np.uint8)  # 데이터 스케일 복구\n","        augmented_image = Image.fromarray(image_np)  # numpy 배열을 PIL 이미지로 변환\n","        save_path = os.path.join(save_dir, f\"{os.path.splitext(os.path.basename(image_path))[0]}_9.jpg\")\n","        augmented_image.save(save_path)  # 이미지 저장\n","\n","# 사용 예시\n","import os\n","\n","image_dir = '/data/ephemeral/home/datasets_fin/HorizontalFlip'\n","save_dir = '/data/ephemeral/home/datasets_fin/HorizontalFlip_GaussNoise'\n","if not os.path.exists(save_dir):\n","     os.makedirs(save_dir)\n","\n","for filename in os.listdir(image_dir):\n","    if filename.endswith('.jpg'):\n","        augment_and_save_image(os.path.join(image_dir, filename), save_dir)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import pandas as pd\n","\n","# 기존 CSV 파일 경로 및 이미지 경로 설정\n","original_csv_file = \"/data/ephemeral/home/datasets_fin/train.csv\"\n","augmented_image_dir = \"/data/ephemeral/home/datasets_fin/Blur\"\n","\n","# 원본 CSV 파일을 읽어옵니다.\n","df = pd.read_csv(original_csv_file)\n","\n","# 새로운 데이터를 저장할 리스트\n","new_data = []\n","\n","# 원본 데이터프레임을 순회하면서 새로운 파일 이름과 타겟 값을 기록합니다.\n","for index, row in df.iterrows():\n","    original_filename = row['ID']\n","    target = row['target']\n","    \n","    # 원본 파일 이름에 추가 번호가 붙은 파일들을 찾습니다.\n","    base_name, ext = os.path.splitext(original_filename)\n","    \n","    # 증강된 파일 이름을 찾기 위해 해당 디렉토리의 파일 목록을 가져옵니다.\n","    for filename in os.listdir(augmented_image_dir):\n","        if filename.startswith(base_name) and filename.endswith(ext):\n","            new_data.append((filename, target))\n","\n","# 새로운 CSV 파일로 저장합니다.\n","new_df = pd.DataFrame(new_data, columns=['ID', 'target'])\n","new_df.to_csv('/data/ephemeral/home/datasets_fin/train_Blur.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import pandas as pd\n","import glob\n","\n","# CSV 파일들이 위치한 디렉토리 설정\n","csv_dir = \"/data/ephemeral/home/datasets_fin/\"\n","output_csv_file = \"/data/ephemeral/home/datasets_fin/combined_train.csv\"\n","\n","# train으로 시작하는 모든 CSV 파일을 찾습니다.\n","csv_files = glob.glob(os.path.join(csv_dir, \"train*.csv\"))\n","\n","# 데이터프레임 리스트를 초기화합니다.\n","df_list = []\n","\n","# 각 CSV 파일을 읽어 데이터프레임 리스트에 추가합니다.\n","for file in csv_files:\n","    df = pd.read_csv(file)\n","    df_list.append(df)\n","\n","# 모든 데이터프레임을 수직으로 결합합니다.\n","combined_df = pd.concat(df_list, axis=0, ignore_index=True)\n","\n","# 결합된 데이터프레임을 새로운 CSV 파일로 저장합니다.\n","combined_df.to_csv(output_csv_file, index=False)\n","\n","print(f\"Combined {len(csv_files)} CSV files into {output_csv_file}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
