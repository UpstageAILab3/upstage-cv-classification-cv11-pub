{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OliaDaX_lwou"
   },
   "source": [
    "# **📄 Document type classification baseline code**\n",
    "> 문서 타입 분류 대회에 오신 여러분 환영합니다! 🎉     \n",
    "> 아래 baseline에서는 ResNet 모델을 로드하여, 모델을 학습 및 예측 파일 생성하는 프로세스에 대해 알아보겠습니다.\n",
    "\n",
    "## Contents\n",
    "- Import Library & Define Functions\n",
    "- Hyper-parameters\n",
    "- Load Data\n",
    "- Train Model\n",
    "- Inference & Save File\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## Import Library & Define Functions\n",
    "* 학습 및 추론에 필요한 라이브러리를 로드합니다.\n",
    "* 학습 및 추론에 필요한 함수와 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "from zoneinfo import ZoneInfo\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time = datetime.fromtimestamp(time.time(), tz=ZoneInfo(\"Asia/Seoul\")).strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_time\n",
    "\n",
    "wandb.init(project=\"document-classification\", name=f\"run-{train_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1700314772722,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "Hyl8oAy6TZAu"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 클래스를 정의합니다.\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1700315066028,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "kTECBJfVTbdl"
   },
   "outputs": [],
   "source": [
    "# one epoch 학습을 위한 함수입니다.\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    # wandb에 훈련 메트릭 로깅\n",
    "    wandb.log(ret)\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## Hyper-parameters\n",
    "* 학습 및 추론에 필요한 하이퍼파라미터들을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = 'data/'\n",
    "\n",
    "# model config\n",
    "model_name = 'resnet34' # 'resnet50' 'efficientnet-b0', ...\n",
    "\n",
    "# training config\n",
    "img_size = 32\n",
    "LR = 1e-3\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 0\n",
    "\n",
    "retrain_full_dataset = True # 최종 예측 시 전체 train 데이터로 재학습할지 여부\n",
    "reinitialize_model = False # 최종 예측 재학습 시 모델 초기화할지 여부\n",
    "\n",
    "# 설정 로깅\n",
    "wandb.config.update({\n",
    "    \"model\": model_name,\n",
    "    \"img_size\": img_size,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"retrain_full_dataset\": retrain_full_dataset,\n",
    "    \"reinitialize_model\": reinitialize_model\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## Load Data\n",
    "* 학습, 테스트 데이터셋과 로더를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "llh5C7ZKoq2S"
   },
   "outputs": [],
   "source": [
    "# augmentation을 위한 transform 코드\n",
    "train_transform = A.Compose([\n",
    "    # 이미지 크기 조정\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    # images normalization\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    # numpy 이미지나 PIL 이미지를 PyTorch 텐서로 변환\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# test image 변환을 위한 transform 코드\n",
    "pred_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_dataset_split(train_csv_path, img_dir, trn_transform, tst_transform, train_size=0.7, val_size=0.15, test_size=0.15, random_state=42):\n",
    "    # CSV 파일 읽기\n",
    "    train_df = pd.read_csv(train_csv_path)\n",
    "    \n",
    "    # 첫 번째 split: 훈련 세트와 나머지(검증+테스트) 세트로 분할\n",
    "    train_df, temp_df = train_test_split(\n",
    "        train_df, \n",
    "        train_size=train_size, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # 두 번째 split: 나머지를 검증 세트와 테스트 세트로 분할\n",
    "    val_size_adjusted = val_size / (val_size + test_size)\n",
    "    val_df, test_df = train_test_split(\n",
    "        temp_df, \n",
    "        train_size=val_size_adjusted, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    print(f\"훈련 세트: {len(train_df)} 샘플\")\n",
    "    print(f\"검증 세트: {len(val_df)} 샘플\")\n",
    "    print(f\"테스트 세트: {len(test_df)} 샘플\")\n",
    "    \n",
    "    # 각 데이터프레임을 임시 CSV 파일로 저장\n",
    "    train_df.to_csv('temp_train.csv', index=False)\n",
    "    val_df.to_csv('temp_val.csv', index=False)\n",
    "    test_df.to_csv('temp_test.csv', index=False)\n",
    "    \n",
    "    # ImageDataset 생성\n",
    "    train_dataset = ImageDataset('temp_train.csv', img_dir, transform=trn_transform)\n",
    "    val_dataset = ImageDataset('temp_val.csv', img_dir, transform=tst_transform)\n",
    "    test_dataset = ImageDataset('temp_test.csv', img_dir, transform=tst_transform)\n",
    "    \n",
    "    # 임시 파일 삭제\n",
    "    os.remove('temp_train.csv')\n",
    "    os.remove('temp_val.csv')\n",
    "    os.remove('temp_test.csv')\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700315112808,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "INxdmsStop2L",
    "outputId": "49f0d412-8ce6-4d2f-ae78-d5cf3d056340"
   },
   "outputs": [],
   "source": [
    "# Dataset 정의\n",
    "train_dataset, val_dataset, test_dataset = random_dataset_split(\n",
    "    'data/train.csv',\n",
    "    'data/train/',\n",
    "    train_transform,\n",
    "    pred_transform\n",
    ")\n",
    "\n",
    "pred_dataset = ImageDataset(\n",
    "    \"data/sample_submission.csv\",\n",
    "    \"data/test/\",\n",
    "    transform=pred_transform\n",
    ")\n",
    "\n",
    "print(len(train_dataset), len(val_dataset), len(test_dataset), len(pred_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112808,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "_sO03fWaQj1h"
   },
   "outputs": [],
   "source": [
    "# DataLoader 정의\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "pred_loader = DataLoader(\n",
    "    pred_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## Train Model\n",
    "* 모델을 로드하고, 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = timm.create_model(\n",
    "    model_name,\n",
    "    pretrained=True,\n",
    "    num_classes=17\n",
    ").to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    ret = train_one_epoch(train_loader, model, optimizer, loss_fn, device=device)\n",
    "    ret['epoch'] = epoch\n",
    "\n",
    "    # wandb에 에폭 로깅\n",
    "    wandb.log({\"epoch\": epoch})\n",
    "\n",
    "    log = \"\"\n",
    "    for k, v in ret.items():\n",
    "      log += f\"{k}: {v:.4f}\\n\"\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, targets in tqdm(loader, desc=\"Evaluating\"):\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            all_preds.extend(preds.argmax(dim=1).cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "\n",
    "    # wandb에 평가 메트릭 로깅\n",
    "    results = {\n",
    "        \"loss\": avg_loss,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "    wandb.log(results)\n",
    "\n",
    "    return avg_loss, accuracy, f1\n",
    "\n",
    "# 학습 후 각 데이터셋에 대한 평가\n",
    "model.to(device)\n",
    "train_results = evaluate(train_loader, model, loss_fn, device)\n",
    "valid_results = evaluate(val_loader, model, loss_fn, device)\n",
    "test_results = evaluate(test_loader, model, loss_fn, device)\n",
    "\n",
    "# 평가 결과 로깅\n",
    "wandb.log({\n",
    "    \"final_train_loss\": train_results[0],\n",
    "    \"final_train_accuracy\": train_results[1],\n",
    "    \"final_train_f1\": train_results[2],\n",
    "    \"final_valid_loss\": valid_results[0],\n",
    "    \"final_valid_accuracy\": valid_results[1],\n",
    "    \"final_valid_f1\": valid_results[2],\n",
    "    \"final_test_loss\": test_results[0],\n",
    "    \"final_test_accuracy\": test_results[1],\n",
    "    \"final_test_f1\": test_results[2]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_results(train_results, valid_results, test_results):\n",
    "    \"\"\"\n",
    "    훈련, 검증, 테스트 결과를 해석하는 함수\n",
    "    \n",
    "    :param train_results: (train_loss, train_acc, train_f1)\n",
    "    :param valid_results: (valid_loss, valid_acc, valid_f1)\n",
    "    :param test_results: (test_loss, test_acc, test_f1)\n",
    "    :return: 해석 문자열\n",
    "    \"\"\"\n",
    "    train_loss, train_acc, train_f1 = train_results\n",
    "    valid_loss, valid_acc, valid_f1 = valid_results\n",
    "    test_loss, test_acc, test_f1 = test_results\n",
    "    \n",
    "    interpretation = \"모델 성능 해석:\\n\\n\"\n",
    "    \n",
    "    # 각 세트의 성능 출력\n",
    "    interpretation += f\"훈련 세트 - Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}, F1: {train_f1:.4f}\\n\"\n",
    "    interpretation += f\"검증 세트 - Loss: {valid_loss:.4f}, Accuracy: {valid_acc:.4f}, F1: {valid_f1:.4f}\\n\"\n",
    "    interpretation += f\"테스트 세트 - Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1: {test_f1:.4f}\\n\\n\"\n",
    "    \n",
    "    # 과적합 여부 확인\n",
    "    if train_acc - valid_acc > 0.05 and train_acc - test_acc > 0.05:\n",
    "        interpretation += \"과적합 징후가 있습니다. 훈련 세트의 성능이 검증 및 테스트 세트보다 현저히 높습니다.\\n\"\n",
    "    elif valid_acc - test_acc > 0.05:\n",
    "        interpretation += \"검증 세트에 과적합되었을 가능성이 있습니다. 테스트 세트의 성능이 상대적으로 낮습니다.\\n\"\n",
    "    else:\n",
    "        interpretation += \"과적합의 징후가 크지 않습니다. 세 세트의 성능이 비교적 일관적입니다.\\n\"\n",
    "    \n",
    "    # 전반적인 성능 평가\n",
    "    avg_acc = (train_acc + valid_acc + test_acc) / 3\n",
    "    if avg_acc < 0.3:\n",
    "        interpretation += \"전반적인 성능이 낮습니다. 모델 개선이 필요합니다.\\n\"\n",
    "    elif avg_acc < 0.6:\n",
    "        interpretation += \"모델이 어느 정도의 학습을 보이지만, 상당한 개선의 여지가 있습니다.\\n\"\n",
    "    else:\n",
    "        interpretation += \"모델이 비교적 좋은 성능을 보이고 있습니다. 미세 조정을 통해 더 개선할 수 있습니다.\\n\"\n",
    "    \n",
    "    # F1 점수 해석\n",
    "    if min(train_f1, valid_f1, test_f1) < 0.3:\n",
    "        interpretation += \"F1 점수가 낮습니다. 클래스 불균형 문제를 고려해야 할 수 있습니다.\\n\"\n",
    "    \n",
    "    # 개선 제안\n",
    "    interpretation += \"\\n개선을 위한 제안:\\n\"\n",
    "    if train_acc - valid_acc > 0.05:\n",
    "        interpretation += \"- 정규화 기법 (예: dropout, L2 정규화)을 적용해 보세요.\\n\"\n",
    "        interpretation += \"- 데이터 증강 기법을 강화해 보세요.\\n\"\n",
    "    if avg_acc < 0.5:\n",
    "        interpretation += \"- 더 복잡한 모델 아키텍처를 시도해 보세요.\\n\"\n",
    "        interpretation += \"- 학습률과 배치 크기를 조정해 보세요.\\n\"\n",
    "        interpretation += \"- 전이 학습을 고려해 보세요.\\n\"\n",
    "    if min(train_f1, valid_f1, test_f1) < 0.3:\n",
    "        interpretation += \"- 클래스 가중치 조정을 통해 불균형 문제를 해결해 보세요.\\n\"\n",
    "        interpretation += \"- 앙상블 기법을 시도해 보세요.\\n\"\n",
    "    \n",
    "    return interpretation\n",
    "\n",
    "interpret = interpret_results(train_results, valid_results, test_results)\n",
    "print(interpret)\n",
    "wandb.log({\"interpretation\": interpret})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# Inference & Save File\n",
    "* 테스트 이미지에 대한 추론을 진행하고, 결과 파일을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if retrain_full_dataset:\n",
    "    print(\"Starting final training on entire dataset for submission...\")\n",
    "\n",
    "    # 전체 데이터셋 생성\n",
    "    full_dataset = ImageDataset(\n",
    "        \"data/train.csv\",\n",
    "        \"data/train/\",\n",
    "        transform=train_transform\n",
    "    )\n",
    "\n",
    "    full_loader = DataLoader(\n",
    "        full_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    # 모델 재초기화\n",
    "    if reinitialize_model:\n",
    "        model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "        optimizer = Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    # 전체 데이터셋으로 재학습\n",
    "    for epoch in range(EPOCHS):\n",
    "        ret = train_one_epoch(full_loader, model, optimizer, loss_fn, device=device)\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        print(f\"Loss: {ret['train_loss']:.4f}, Accuracy: {ret['train_acc']:.4f}, F1: {ret['train_f1']:.4f}\")\n",
    "\n",
    "    print(\"Final training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12776,
     "status": "ok",
     "timestamp": 1700315185336,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "uRYe6jlPU_Om",
    "outputId": "2a08690c-9ffe-418d-8679-eb9280147110"
   },
   "outputs": [],
   "source": [
    "print(\"Generating predictions for submission...\")\n",
    "preds_list = []\n",
    "\n",
    "model.eval()\n",
    "for image, _ in tqdm(pred_loader):\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(image)\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1700315216829,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "aClN7Qi7VZoh"
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315238836,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "VDBXQqAzVvLY"
   },
   "outputs": [],
   "source": [
    "sample_submission_df = pd.read_csv(\"data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1700315244710,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "ePx2vCELVnuS"
   },
   "outputs": [],
   "source": [
    "submission_file_path = os.path.join('output', f'{train_time}.csv')\n",
    "pred_df.to_csv(submission_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1700315247734,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "9yMO8s6GqAwZ",
    "outputId": "9a30616f-f0ea-439f-a906-dd806737ce00"
   },
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
