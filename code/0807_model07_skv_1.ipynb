{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code\n",
    "- stratified k-fold split\n",
    "- earlystopping\n",
    "#### data\n",
    "- csv파일에 label 변경\n",
    "- 1, 13, 14 클래스에 대해서 오버샘플링하여 class imbalance 완화\n",
    "- 7번 클래스를 7, 17로 나눈 후 예측 후 17을 7로 변경\n",
    "- 7번 17번 클래스가 약 6:4정도의 비율을 가지고 있어서 다시 class imbalance 발생, 회전, 크롭으로 오버샘플링하여 class imbalance 완화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "import wandb\n",
    "\n",
    "import pytesseract\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import timm\n",
    "import albumentations as A\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 사용할 장치를 설정합니다.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: alvlalvl92 (alvlalvl). Use `wandb login --relogin` to force relogin\n"
     ]
    }
   ],
   "source": [
    "# wandb 연동\n",
    "load_dotenv()\n",
    "api_key = os.getenv('WANDB_API_KEY')\n",
    "\n",
    "wandb.login(key=api_key)\n",
    "\n",
    "train_time = datetime.fromtimestamp(time.time(), tz=ZoneInfo(\"Asia/Seoul\")).strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data config\n",
    "data_path = '../data/'\n",
    "\n",
    "# model config\n",
    "model_name = 'efficientnet_b5' # 'resnet50' 'efficientnet-b0', ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training config\n",
    "img_size = 128\n",
    "LR = 1e-5\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 4\n",
    "num_workers = 0\n",
    "num_folds = 3\n",
    "augment_ratio = 2\n",
    "early_stopping_patience = 5  # Early Stopping 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스를 수정합니다.\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None, augment_ratio=1):\n",
    "        self.df = pd.read_csv(csv)\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.augment_ratio = augment_ratio\n",
    "\n",
    "        # 데이터 증강\n",
    "        if self.augment_ratio > 1:\n",
    "            self.df = self.df.loc[self.df.index.repeat(self.augment_ratio)].reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df.iloc[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one epoch 학습을 위한 함수입니다.\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader) # ,leave=False\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader) # leave=False\n",
    "        for image, targets in pbar:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).cpu().numpy())\n",
    "            targets_list.extend(targets.cpu().numpy())\n",
    "\n",
    "            pbar.set_description(f\"Val Loss: {loss.item():.4f}\")\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_f1\": val_f1,\n",
    "    }\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_loss\n",
    "        elif val_loss > self.best_score - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_loss\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # augmentation을 위한 transform 코드\n",
    "# trn_transform = A.Compose([\n",
    "#     # 이미지 크기 조정\n",
    "#     A.Resize(height=img_size, width=img_size),\n",
    "#     A.OneOf([\n",
    "#         A.GaussNoise(var_limit=(10.0, 800.0), p=0.75),\n",
    "#         A.GaussianBlur(blur_limit=(1, 7), p=0.5)\n",
    "#     ], p=0.75),\n",
    "#     A.RandomRotate90(p=0.5),\n",
    "#     A.HorizontalFlip(p=0.75),\n",
    "#     A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=0.5),\n",
    "#     A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=30, p=0.25),\n",
    "#     A.CoarseDropout(max_holes=6, max_height=32, max_width=32, p=0.5),\n",
    "#     A.ElasticTransform(alpha=1, sigma=30, alpha_affine=30, p=0.5),\n",
    "#     A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "#     A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "#     A.Rotate(limit=30, p=0.75),\n",
    "#     A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),\n",
    "#     A.MotionBlur(blur_limit=5, p=0.5),\n",
    "#     A.OpticalDistortion(p=0.5),\n",
    "#     A.Transpose(p=0.5),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 이미지 크기 조정\n",
    "trn_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    \n",
    "    # 레이아웃 관련 변환\n",
    "    A.OneOf([\n",
    "        A.RandomCrop(height=img_size, width=img_size, p=1.0),  # Random crop을 통해 다양한 크기의 이미지 생성\n",
    "        A.CenterCrop(height=img_size, width=img_size, p=1.0)   # Center crop을 통해 중심 부분을 강조\n",
    "    ], p=0.5),\n",
    "\n",
    "    # 기존 변환\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(var_limit=(10.0, 800.0), p=0.75),\n",
    "        A.GaussianBlur(blur_limit=(1, 7), p=0.5)\n",
    "    ], p=0.75),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.HorizontalFlip(p=0.75),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=30, p=0.25),\n",
    "    A.CoarseDropout(max_holes=6, max_height=32, max_width=32, p=0.5),\n",
    "    A.ElasticTransform(alpha=1, sigma=30, alpha_affine=30, p=0.5),\n",
    "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.Rotate(limit=30, p=0.75),\n",
    "    A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),\n",
    "    A.MotionBlur(blur_limit=5, p=0.5),\n",
    "    A.OpticalDistortion(p=0.5),\n",
    "    A.Transpose(p=0.5),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "\n",
    "# test image 변환을 위한 transform 코드\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3140 3140\n"
     ]
    }
   ],
   "source": [
    "# Dataset 정의\n",
    "trn_dataset = ImageDataset(\n",
    "    f\"{data_path}train.csv\",\n",
    "    f\"{data_path}train/\",\n",
    "    transform=trn_transform,\n",
    "    augment_ratio=augment_ratio  # 증강 비율 추가\n",
    ")\n",
    "tst_dataset = ImageDataset(\n",
    "    f\"{data_path}sample_submission.csv\",\n",
    "    f\"{data_path}test/\",\n",
    "    transform=tst_transform\n",
    ")\n",
    "print(len(trn_dataset), len(tst_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get targets for stratification\n",
    "targets = trn_dataset.df['target'].values\n",
    "\n",
    "# Stratified K-Fold Cross Validation\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ej_ja\\OneDrive\\Desktop\\ai_lab\\aistages_2_CV\\upstage-cv-classification-cv11\\code\\wandb\\run-20240807_200627-uvfsn8na</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alvlalvl/20240807-200621_one_vs_all/runs/uvfsn8na' target=\"_blank\">20240807-200621_fold1_efficientnet_b5</a></strong> to <a href='https://wandb.ai/alvlalvl/20240807-200621_one_vs_all' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alvlalvl/20240807-200621_one_vs_all' target=\"_blank\">https://wandb.ai/alvlalvl/20240807-200621_one_vs_all</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alvlalvl/20240807-200621_one_vs_all/runs/uvfsn8na' target=\"_blank\">https://wandb.ai/alvlalvl/20240807-200621_one_vs_all/runs/uvfsn8na</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.5159: 100%|██████████| 523/523 [00:57<00:00,  9.02it/s] \n",
      "Val Loss: 1.9777: 100%|██████████| 262/262 [00:14<00:00, 17.97it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 4.3587\n",
      "train_acc: 0.1209\n",
      "train_f1: 0.1134\n",
      "val_loss: 456852.1068\n",
      "val_acc: 0.1307\n",
      "val_f1: 0.1258\n",
      "epoch: 0.0000\n",
      "fold: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.9237: 100%|██████████| 523/523 [00:58<00:00,  8.91it/s]\n",
      "Val Loss: 3.6075: 100%|██████████| 262/262 [00:15<00:00, 16.86it/s]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 2.5583\n",
      "train_acc: 0.2304\n",
      "train_f1: 0.2057\n",
      "val_loss: 10825374.6443\n",
      "val_acc: 0.2099\n",
      "val_f1: 0.1980\n",
      "epoch: 1.0000\n",
      "fold: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3303: 100%|██████████| 523/523 [00:57<00:00,  9.08it/s]\n",
      "Val Loss: 2.7961: 100%|██████████| 262/262 [00:15<00:00, 17.24it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 2.2779\n",
      "train_acc: 0.3050\n",
      "train_f1: 0.2709\n",
      "val_loss: 1252438573.0387\n",
      "val_acc: 0.2490\n",
      "val_f1: 0.2312\n",
      "epoch: 2.0000\n",
      "fold: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9027: 100%|██████████| 523/523 [00:57<00:00,  9.12it/s]\n",
      "Val Loss: 131.1782: 100%|██████████| 262/262 [00:15<00:00, 17.32it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 2.0830\n",
      "train_acc: 0.3480\n",
      "train_f1: 0.3144\n",
      "val_loss: 13927376.1014\n",
      "val_acc: 0.2605\n",
      "val_f1: 0.2540\n",
      "epoch: 3.0000\n",
      "fold: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.6174: 100%|██████████| 523/523 [00:57<00:00,  9.09it/s]\n",
      "Val Loss: 3.1442: 100%|██████████| 262/262 [00:15<00:00, 17.36it/s]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.9377\n",
      "train_acc: 0.3886\n",
      "train_f1: 0.3458\n",
      "val_loss: 4072885.4884\n",
      "val_acc: 0.3473\n",
      "val_f1: 0.3449\n",
      "epoch: 4.0000\n",
      "fold: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2587: 100%|██████████| 523/523 [00:57<00:00,  9.11it/s]\n",
      "Val Loss: 1.6092: 100%|██████████| 262/262 [00:14<00:00, 17.62it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.8021\n",
      "train_acc: 0.4168\n",
      "train_f1: 0.3791\n",
      "val_loss: 14906.4307\n",
      "val_acc: 0.4113\n",
      "val_f1: 0.3889\n",
      "epoch: 5.0000\n",
      "fold: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3340: 100%|██████████| 523/523 [00:57<00:00,  9.15it/s]\n",
      "Val Loss: 3.4415: 100%|██████████| 262/262 [00:15<00:00, 17.26it/s]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.7034\n",
      "train_acc: 0.4565\n",
      "train_f1: 0.4158\n",
      "val_loss: 9734612.4643\n",
      "val_acc: 0.4523\n",
      "val_f1: 0.4203\n",
      "epoch: 6.0000\n",
      "fold: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3905: 100%|██████████| 523/523 [00:56<00:00,  9.22it/s]\n",
      "Val Loss: 13.4730: 100%|██████████| 262/262 [00:14<00:00, 17.71it/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.6052\n",
      "train_acc: 0.4919\n",
      "train_f1: 0.4532\n",
      "val_loss: 5135617.5313\n",
      "val_acc: 0.4160\n",
      "val_f1: 0.3885\n",
      "epoch: 7.0000\n",
      "fold: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6028: 100%|██████████| 523/523 [00:56<00:00,  9.21it/s]\n",
      "Val Loss: 2.4384: 100%|██████████| 262/262 [00:14<00:00, 17.77it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.5261\n",
      "train_acc: 0.5096\n",
      "train_f1: 0.4703\n",
      "val_loss: 1981752.9201\n",
      "val_acc: 0.4971\n",
      "val_f1: 0.4711\n",
      "epoch: 8.0000\n",
      "fold: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2721: 100%|██████████| 523/523 [00:56<00:00,  9.18it/s]\n",
      "Val Loss: 2.2212: 100%|██████████| 262/262 [00:14<00:00, 18.05it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.4397\n",
      "train_acc: 0.5335\n",
      "train_f1: 0.4955\n",
      "val_loss: 82598.9382\n",
      "val_acc: 0.5181\n",
      "val_f1: 0.4861\n",
      "epoch: 9.0000\n",
      "fold: 0.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f516151ed7604f9cac673747909ed1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>fold</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▆▇▇██</td></tr><tr><td>train_f1</td><td>▁▃▄▅▅▆▇▇██</td></tr><tr><td>train_loss</td><td>█▄▃▃▂▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▃▃▅▆▇▆██</td></tr><tr><td>val_f1</td><td>▁▂▃▃▅▆▇▆██</td></tr><tr><td>val_loss</td><td>▁▁█▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>fold</td><td>0</td></tr><tr><td>train_acc</td><td>0.53346</td></tr><tr><td>train_f1</td><td>0.49547</td></tr><tr><td>train_loss</td><td>1.43968</td></tr><tr><td>val_acc</td><td>0.51813</td></tr><tr><td>val_f1</td><td>0.48611</td></tr><tr><td>val_loss</td><td>82598.93815</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">20240807-200621_fold1_efficientnet_b5</strong> at: <a href='https://wandb.ai/alvlalvl/20240807-200621_one_vs_all/runs/uvfsn8na' target=\"_blank\">https://wandb.ai/alvlalvl/20240807-200621_one_vs_all/runs/uvfsn8na</a><br/> View project at: <a href='https://wandb.ai/alvlalvl/20240807-200621_one_vs_all' target=\"_blank\">https://wandb.ai/alvlalvl/20240807-200621_one_vs_all</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240807_200627-uvfsn8na\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ej_ja\\OneDrive\\Desktop\\ai_lab\\aistages_2_CV\\upstage-cv-classification-cv11\\code\\wandb\\run-20240807_201844-eeakx61d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alvlalvl/20240807-200621_one_vs_all/runs/eeakx61d' target=\"_blank\">20240807-200621_fold2_efficientnet_b5</a></strong> to <a href='https://wandb.ai/alvlalvl/20240807-200621_one_vs_all' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alvlalvl/20240807-200621_one_vs_all' target=\"_blank\">https://wandb.ai/alvlalvl/20240807-200621_one_vs_all</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alvlalvl/20240807-200621_one_vs_all/runs/eeakx61d' target=\"_blank\">https://wandb.ai/alvlalvl/20240807-200621_one_vs_all/runs/eeakx61d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3875: 100%|██████████| 524/524 [00:58<00:00,  9.00it/s]\n",
      "Val Loss: 3.7917: 100%|██████████| 262/262 [00:15<00:00, 17.43it/s]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 4.2691\n",
      "train_acc: 0.1313\n",
      "train_f1: 0.1240\n",
      "val_loss: 2018417.1926\n",
      "val_acc: 0.1195\n",
      "val_f1: 0.1036\n",
      "epoch: 0.0000\n",
      "fold: 1.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.1777: 100%|██████████| 524/524 [00:57<00:00,  9.10it/s]\n",
      "Val Loss: 1.7731: 100%|██████████| 262/262 [00:15<00:00, 17.30it/s]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 2.6525\n",
      "train_acc: 0.2297\n",
      "train_f1: 0.2005\n",
      "val_loss: 8780623.7581\n",
      "val_acc: 0.1979\n",
      "val_f1: 0.1612\n",
      "epoch: 1.0000\n",
      "fold: 1.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3970: 100%|██████████| 524/524 [00:57<00:00,  9.19it/s]\n",
      "Val Loss: 64.4234: 100%|██████████| 262/262 [00:14<00:00, 17.49it/s]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 2.2960\n",
      "train_acc: 0.2884\n",
      "train_f1: 0.2525\n",
      "val_loss: 13779500.8648\n",
      "val_acc: 0.2543\n",
      "val_f1: 0.2216\n",
      "epoch: 2.0000\n",
      "fold: 1.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 3.6406: 100%|██████████| 524/524 [00:57<00:00,  9.18it/s]\n",
      "Val Loss: 2.2141: 100%|██████████| 262/262 [00:14<00:00, 17.53it/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 2.0842\n",
      "train_acc: 0.3524\n",
      "train_f1: 0.3129\n",
      "val_loss: 83131.8305\n",
      "val_acc: 0.3222\n",
      "val_f1: 0.2808\n",
      "epoch: 3.0000\n",
      "fold: 1.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4983: 100%|██████████| 524/524 [00:57<00:00,  9.14it/s]\n",
      "Val Loss: 2.5608: 100%|██████████| 262/262 [00:15<00:00, 17.39it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.8917\n",
      "train_acc: 0.4054\n",
      "train_f1: 0.3678\n",
      "val_loss: 171170.9134\n",
      "val_acc: 0.3480\n",
      "val_f1: 0.3037\n",
      "epoch: 4.0000\n",
      "fold: 1.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.5151: 100%|██████████| 524/524 [00:57<00:00,  9.17it/s]\n",
      "Val Loss: 2.9953: 100%|██████████| 262/262 [00:15<00:00, 17.12it/s]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.7872\n",
      "train_acc: 0.4351\n",
      "train_f1: 0.3935\n",
      "val_loss: 12454434.0894\n",
      "val_acc: 0.4216\n",
      "val_f1: 0.3831\n",
      "epoch: 5.0000\n",
      "fold: 1.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.5739: 100%|██████████| 524/524 [00:57<00:00,  9.09it/s]\n",
      "Val Loss: 1.8028: 100%|██████████| 262/262 [00:14<00:00, 17.78it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.6674\n",
      "train_acc: 0.4632\n",
      "train_f1: 0.4244\n",
      "val_loss: 503122.5414\n",
      "val_acc: 0.4426\n",
      "val_f1: 0.4082\n",
      "epoch: 6.0000\n",
      "fold: 1.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9743: 100%|██████████| 524/524 [00:57<00:00,  9.10it/s]\n",
      "Val Loss: 1.2024: 100%|██████████| 262/262 [00:14<00:00, 17.58it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.6460\n",
      "train_acc: 0.4733\n",
      "train_f1: 0.4430\n",
      "val_loss: 215939.1698\n",
      "val_acc: 0.4857\n",
      "val_f1: 0.4484\n",
      "epoch: 7.0000\n",
      "fold: 1.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.9598: 100%|██████████| 524/524 [00:56<00:00,  9.21it/s]\n",
      "Val Loss: 2.2884: 100%|██████████| 262/262 [00:14<00:00, 17.50it/s]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.5280\n",
      "train_acc: 0.5148\n",
      "train_f1: 0.4750\n",
      "val_loss: 13124289.0478\n",
      "val_acc: 0.5096\n",
      "val_f1: 0.4612\n",
      "epoch: 8.0000\n",
      "fold: 1.0000\n",
      "\n",
      "Early stopping triggered at epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56210557ae0940c4bb7ec472cacb5092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▄▅▅▆▇█</td></tr><tr><td>fold</td><td>▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▇▇▇█</td></tr><tr><td>train_f1</td><td>▁▃▄▅▆▆▇▇█</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▃▅▅▆▇██</td></tr><tr><td>val_f1</td><td>▁▂▃▄▅▆▇██</td></tr><tr><td>val_loss</td><td>▂▅█▁▁▇▁▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>8</td></tr><tr><td>fold</td><td>1</td></tr><tr><td>train_acc</td><td>0.5148</td></tr><tr><td>train_f1</td><td>0.47495</td></tr><tr><td>train_loss</td><td>1.52804</td></tr><tr><td>val_acc</td><td>0.50956</td></tr><tr><td>val_f1</td><td>0.46121</td></tr><tr><td>val_loss</td><td>13124289.04777</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">20240807-200621_fold2_efficientnet_b5</strong> at: <a href='https://wandb.ai/alvlalvl/20240807-200621_one_vs_all/runs/eeakx61d' target=\"_blank\">https://wandb.ai/alvlalvl/20240807-200621_one_vs_all/runs/eeakx61d</a><br/> View project at: <a href='https://wandb.ai/alvlalvl/20240807-200621_one_vs_all' target=\"_blank\">https://wandb.ai/alvlalvl/20240807-200621_one_vs_all</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240807_201844-eeakx61d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fdcd97b4fad43a189d33168ed03cdae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ej_ja\\OneDrive\\Desktop\\ai_lab\\aistages_2_CV\\upstage-cv-classification-cv11\\code\\wandb\\run-20240807_202949-b011eynn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alvlalvl/20240807-200621_one_vs_all/runs/b011eynn' target=\"_blank\">20240807-200621_fold3_efficientnet_b5</a></strong> to <a href='https://wandb.ai/alvlalvl/20240807-200621_one_vs_all' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alvlalvl/20240807-200621_one_vs_all' target=\"_blank\">https://wandb.ai/alvlalvl/20240807-200621_one_vs_all</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alvlalvl/20240807-200621_one_vs_all/runs/b011eynn' target=\"_blank\">https://wandb.ai/alvlalvl/20240807-200621_one_vs_all/runs/b011eynn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0266: 100%|██████████| 524/524 [00:57<00:00,  9.15it/s]\n",
      "Val Loss: 2.6673: 100%|██████████| 262/262 [00:15<00:00, 17.30it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 4.3713\n",
      "train_acc: 0.1323\n",
      "train_f1: 0.1218\n",
      "val_loss: 142619.1560\n",
      "val_acc: 0.1205\n",
      "val_f1: 0.1142\n",
      "epoch: 0.0000\n",
      "fold: 2.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.8978: 100%|██████████| 524/524 [00:57<00:00,  9.11it/s]\n",
      "Val Loss: 3.4750: 100%|██████████| 262/262 [00:15<00:00, 17.43it/s]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 2.6714\n",
      "train_acc: 0.2273\n",
      "train_f1: 0.2053\n",
      "val_loss: 5502073.0724\n",
      "val_acc: 0.2055\n",
      "val_f1: 0.1851\n",
      "epoch: 1.0000\n",
      "fold: 2.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3648: 100%|██████████| 524/524 [00:57<00:00,  9.12it/s]\n",
      "Val Loss: 1.6926: 100%|██████████| 262/262 [00:15<00:00, 17.44it/s]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 2.3100\n",
      "train_acc: 0.2918\n",
      "train_f1: 0.2611\n",
      "val_loss: 11489279.7839\n",
      "val_acc: 0.2055\n",
      "val_f1: 0.1985\n",
      "epoch: 2.0000\n",
      "fold: 2.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 3.0180: 100%|██████████| 524/524 [00:57<00:00,  9.09it/s]\n",
      "Val Loss: 1.8093: 100%|██████████| 262/262 [00:14<00:00, 17.85it/s]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 2.0951\n",
      "train_acc: 0.3553\n",
      "train_f1: 0.3171\n",
      "val_loss: 2913682.3868\n",
      "val_acc: 0.3317\n",
      "val_f1: 0.3135\n",
      "epoch: 3.0000\n",
      "fold: 2.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 3.2995: 100%|██████████| 524/524 [01:24<00:00,  6.17it/s]\n",
      "Val Loss: 2.9374: 100%|██████████| 262/262 [00:13<00:00, 18.75it/s]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.8848\n",
      "train_acc: 0.4007\n",
      "train_f1: 0.3641\n",
      "val_loss: 6988615.9077\n",
      "val_acc: 0.3231\n",
      "val_f1: 0.3117\n",
      "epoch: 4.0000\n",
      "fold: 2.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.1565: 100%|██████████| 524/524 [00:54<00:00,  9.63it/s]\n",
      "Val Loss: 0.3520: 100%|██████████| 262/262 [00:14<00:00, 18.38it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.7640\n",
      "train_acc: 0.4542\n",
      "train_f1: 0.4171\n",
      "val_loss: 977.2811\n",
      "val_acc: 0.4340\n",
      "val_f1: 0.4078\n",
      "epoch: 5.0000\n",
      "fold: 2.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6564: 100%|██████████| 524/524 [00:54<00:00,  9.66it/s]\n",
      "Val Loss: 0.2651: 100%|██████████| 262/262 [00:14<00:00, 18.50it/s]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.6733\n",
      "train_acc: 0.4642\n",
      "train_f1: 0.4261\n",
      "val_loss: 674513.2906\n",
      "val_acc: 0.4761\n",
      "val_f1: 0.4568\n",
      "epoch: 6.0000\n",
      "fold: 2.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 3.5986: 100%|██████████| 524/524 [00:54<00:00,  9.66it/s]\n",
      "Val Loss: 0.0180: 100%|██████████| 262/262 [00:13<00:00, 18.75it/s]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.5965\n",
      "train_acc: 0.4971\n",
      "train_f1: 0.4623\n",
      "val_loss: 746766.0323\n",
      "val_acc: 0.3948\n",
      "val_f1: 0.3839\n",
      "epoch: 7.0000\n",
      "fold: 2.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7465: 100%|██████████| 524/524 [00:54<00:00,  9.61it/s]\n",
      "Val Loss: 21.3326: 100%|██████████| 262/262 [00:14<00:00, 18.25it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.4644\n",
      "train_acc: 0.5282\n",
      "train_f1: 0.4953\n",
      "val_loss: 115996.7093\n",
      "val_acc: 0.4675\n",
      "val_f1: 0.4490\n",
      "epoch: 8.0000\n",
      "fold: 2.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5604: 100%|██████████| 524/524 [00:53<00:00,  9.79it/s]\n",
      "Val Loss: 0.0140: 100%|██████████| 262/262 [00:14<00:00, 18.33it/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.3909\n",
      "train_acc: 0.5540\n",
      "train_f1: 0.5191\n",
      "val_loss: 201.1882\n",
      "val_acc: 0.5182\n",
      "val_f1: 0.4857\n",
      "epoch: 9.0000\n",
      "fold: 2.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39777ddc7d1e4fbe8fadb380d85fae94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>fold</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▅▆▇▇██</td></tr><tr><td>train_f1</td><td>▁▂▃▄▅▆▆▇██</td></tr><tr><td>train_loss</td><td>█▄▃▃▂▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▂▅▅▇▇▆▇█</td></tr><tr><td>val_f1</td><td>▁▂▃▅▅▇▇▆▇█</td></tr><tr><td>val_loss</td><td>▁▄█▃▅▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>fold</td><td>2</td></tr><tr><td>train_acc</td><td>0.55396</td></tr><tr><td>train_f1</td><td>0.51908</td></tr><tr><td>train_loss</td><td>1.39086</td></tr><tr><td>val_acc</td><td>0.51816</td></tr><tr><td>val_f1</td><td>0.48567</td></tr><tr><td>val_loss</td><td>201.18816</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">20240807-200621_fold3_efficientnet_b5</strong> at: <a href='https://wandb.ai/alvlalvl/20240807-200621_one_vs_all/runs/b011eynn' target=\"_blank\">https://wandb.ai/alvlalvl/20240807-200621_one_vs_all/runs/b011eynn</a><br/> View project at: <a href='https://wandb.ai/alvlalvl/20240807-200621_one_vs_all' target=\"_blank\">https://wandb.ai/alvlalvl/20240807-200621_one_vs_all</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240807_202949-b011eynn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_models = []\n",
    "best_val_accuracies = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(trn_dataset) // augment_ratio), targets[::augment_ratio])):\n",
    "    print(f'Fold {fold + 1}/{num_folds}')\n",
    "\n",
    "    wandb.init(\n",
    "        project=f\"{train_time}_one_vs_all\",\n",
    "        name=f\"{train_time}_fold{fold+1}_{model_name}\",\n",
    "        config={\n",
    "            \"learning_rate\": LR,\n",
    "            \"architecture\": model_name,\n",
    "            \"dataset\": \"custom-dataset\",\n",
    "            \"epochs\": EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"image_size\": img_size,\n",
    "            \"num_workers\": num_workers,\n",
    "            'augment_ratio': augment_ratio,\n",
    "            'early_stopping_patience': early_stopping_patience\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "    # 증강된 데이터에 맞게 인덱스 조정\n",
    "    train_idx = np.concatenate([train_idx * augment_ratio + i for i in range(augment_ratio)])\n",
    "    val_idx = np.concatenate([val_idx * augment_ratio + i for i in range(augment_ratio)])\n",
    "    \n",
    "    train_subset = Subset(trn_dataset, train_idx)\n",
    "    val_subset = Subset(trn_dataset, val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # load model\n",
    "    model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=True,\n",
    "        num_classes=17\n",
    "    ).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    best_val_accuracy = 0\n",
    "    best_model_state = None\n",
    "    early_stopping = EarlyStopping(patience=early_stopping_patience)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_results = train_one_epoch(train_loader, model, optimizer, loss_fn, device=device)\n",
    "        \n",
    "        # 검증 성능 평가 추가\n",
    "        val_results = validate(val_loader, model, loss_fn, device)\n",
    "        \n",
    "        # 결과 합치기\n",
    "        results = {**train_results, **val_results, 'epoch': epoch, 'fold': fold}\n",
    "\n",
    "        wandb.log(results)\n",
    "\n",
    "        log = \"\"\n",
    "        for k, v in results.items():\n",
    "            log += f\"{k}: {v:.4f}\\n\"\n",
    "        print(log)\n",
    "\n",
    "        # 최고 성능 모델 저장\n",
    "        if val_results['val_acc'] > best_val_accuracy:\n",
    "            best_val_accuracy = val_results['val_acc']\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "        # Early stopping 체크\n",
    "        early_stopping(val_results['val_loss'])\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # 폴드의 최고 성능 모델 저장\n",
    "    torch.save(best_model_state, f'best_model_fold_{fold}.pth')\n",
    "    best_models.append(best_model_state)\n",
    "    best_val_accuracies.append(best_val_accuracy)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 정의\n",
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [00:28<00:00, 27.66it/s]\n",
      "100%|██████████| 785/785 [00:27<00:00, 28.23it/s]\n",
      "100%|██████████| 785/785 [00:28<00:00, 28.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# 모든 폴드 완료 후 앙상블 예측\n",
    "preds_list = []\n",
    "for fold, model_state in enumerate(best_models):\n",
    "    model.load_state_dict(model_state)\n",
    "    model.eval()\n",
    "    fold_preds = []\n",
    "    for image, _ in tqdm(tst_loader):\n",
    "        image = image.to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = model(image)\n",
    "        fold_preds.extend(preds.detach().cpu().numpy())\n",
    "    preds_list.append(fold_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앙상블 (평균)\n",
    "final_preds = np.mean(preds_list, axis=0).argmax(axis=1) # 함수는 주어진 축(axis)을 따라 가장 큰 값의 인덱스를 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과를 데이터프레임으로 만들기\n",
    "pred_df = pd.DataFrame({\n",
    "    'ID': tst_dataset.df['ID'],  # ID 열\n",
    "    'target': final_preds  # 앙상블 예측 결과\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission.csv와 비교 확인\n",
    "sample_submission_df = pd.read_csv(f\"{data_path}/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "pred_df.to_csv(\"pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>ffb4b6f619fb60ea.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>ffb54299b1ad4159.jpg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>ffc2c91dff8cf2c0.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>ffc4e330a5353a2a.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>ffc71fed753d90c1.jpg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3140 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID  target\n",
       "0     0008fdb22ddce0ce.jpg       2\n",
       "1     00091bffdffd83de.jpg       6\n",
       "2     00396fbc1f6cc21d.jpg       5\n",
       "3     00471f8038d9c4b6.jpg      10\n",
       "4     00901f504008d884.jpg       2\n",
       "...                    ...     ...\n",
       "3135  ffb4b6f619fb60ea.jpg       6\n",
       "3136  ffb54299b1ad4159.jpg      10\n",
       "3137  ffc2c91dff8cf2c0.jpg       8\n",
       "3138  ffc4e330a5353a2a.jpg       0\n",
       "3139  ffc71fed753d90c1.jpg      10\n",
       "\n",
       "[3140 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
