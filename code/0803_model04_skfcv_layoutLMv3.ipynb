{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 초기 설정 및 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "import wandb\n",
    "\n",
    "from transformers import LayoutLMv3ForSequenceClassification, LayoutLMv3Processor\n",
    "import pytesseract\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:90mpcmw0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24ecde35299410ea93a0f411df2ebbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">layoutlmv3-20240803-211331</strong> at: <a href='https://wandb.ai/alvlalvl/competition2-cv/runs/90mpcmw0' target=\"_blank\">https://wandb.ai/alvlalvl/competition2-cv/runs/90mpcmw0</a><br/> View project at: <a href='https://wandb.ai/alvlalvl/competition2-cv' target=\"_blank\">https://wandb.ai/alvlalvl/competition2-cv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240803_211331-90mpcmw0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:90mpcmw0). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c82e99544a4d35b97990e079670a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01128888888876342, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ej_ja\\OneDrive\\Desktop\\ai_lab\\aistages_2_CV\\upstage-cv-classification-cv11\\code\\wandb\\run-20240803_213638-a49o1vog</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alvlalvl/competition2-cv/runs/a49o1vog' target=\"_blank\">layoutlmv3-20240803-213638</a></strong> to <a href='https://wandb.ai/alvlalvl/competition2-cv' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alvlalvl/competition2-cv' target=\"_blank\">https://wandb.ai/alvlalvl/competition2-cv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alvlalvl/competition2-cv/runs/a49o1vog' target=\"_blank\">https://wandb.ai/alvlalvl/competition2-cv/runs/a49o1vog</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240803-213638\n"
     ]
    }
   ],
   "source": [
    "# wandb 연동\n",
    "load_dotenv()\n",
    "api_key = os.getenv('WANDB_API_KEY')\n",
    "\n",
    "wandb.login(key=api_key)\n",
    "\n",
    "train_time = datetime.fromtimestamp(time.time(), tz=ZoneInfo(\"Asia/Seoul\")).strftime(\"%Y%m%d-%H%M%S\")\n",
    "wandb.init(project=\"competition2-cv\", name=f\"layoutlmv3-{train_time}\")\n",
    "\n",
    "print(train_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터셋 및 유틸리티 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스를 정의합니다.\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, processor, transform=None): \n",
    "        self.df = pd.read_csv(csv)\n",
    "        self.path = path\n",
    "        self.processor = processor\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df.iloc[idx]\n",
    "        image = Image.open(os.path.join(self.path, name)).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "\n",
    "        encoded_inputs = self.processor(image, return_tensors=\"pt\", padding=\"max_length\", truncation=True)\n",
    "        input_ids = encoded_inputs[\"input_ids\"].squeeze()\n",
    "        attention_mask = encoded_inputs[\"attention_mask\"].squeeze()\n",
    "        bbox = encoded_inputs[\"bbox\"].squeeze()\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"bbox\": bbox,\n",
    "            \"labels\": torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one epoch 학습을 위한 함수입니다.\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for batch in pbar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        bbox = batch[\"bbox\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, bbox=bbox, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        preds = outputs.logits\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    wandb.log(ret)\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증을 위한 함수입니다.\n",
    "def validate(loader, model, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            bbox = batch[\"bbox\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, bbox=bbox, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            preds = outputs.logits\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_f1\": val_f1,\n",
    "    }\n",
    "\n",
    "    wandb.log(ret)\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 설정 및 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = '../data/'\n",
    "\n",
    "# model config\n",
    "model_name = 'microsoft/layoutlmv3-base'\n",
    "\n",
    "# training config\n",
    "LR = 1e-3\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 4\n",
    "num_workers = 0\n",
    "N_FOLDS = 2  # 추가: fold 수\n",
    "PATIENCE = 3  # 얼리스탑핑을 위한 patience\n",
    "\n",
    "wandb.config.update({\n",
    "    \"learning_rate\": LR,\n",
    "    \"architecture\": model_name,\n",
    "    \"dataset\": \"custom-dataset\",\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"n_folds\": N_FOLDS,  # 추가\n",
    "    \"patience\": PATIENCE  # 추가\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'height': 224, 'width': 224}\n"
     ]
    }
   ],
   "source": [
    "# processor 정의\n",
    "processor = LayoutLMv3Processor.from_pretrained(model_name)\n",
    "print(processor.image_processor.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570 3140\n"
     ]
    }
   ],
   "source": [
    "# Dataset 정의\n",
    "trn_dataset = ImageDataset(\n",
    "    f\"{data_path}train.csv\",\n",
    "    f\"{data_path}train/\",\n",
    "    processor=processor\n",
    ")\n",
    "\n",
    "tst_dataset = ImageDataset(\n",
    "    f\"{data_path}sample_submission.csv\",\n",
    "    f\"{data_path}test/\",\n",
    "    processor=processor\n",
    ")\n",
    "\n",
    "print(len(trn_dataset), len(tst_dataset))\n",
    "\n",
    "# Stratified K-Fold 정의\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 학습 및 검증 (K-Fold Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/197 [00:00<?, ?it/s]c:\\Users\\ej_ja\\anaconda3\\envs\\venv\\lib\\site-packages\\transformers\\modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Loss: 2.9309: 100%|██████████| 197/197 [04:15<00:00,  1.30s/it]\n",
      "c:\\Users\\ej_ja\\anaconda3\\envs\\venv\\lib\\site-packages\\transformers\\modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "Train Loss: 2.9699, Train Acc: 0.0586, Train F1: 0.0513\n",
      "Val Loss: 2.8491, Val Acc: 0.0637, Val F1: 0.0070\n",
      "Fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/197 [00:00<?, ?it/s]c:\\Users\\ej_ja\\anaconda3\\envs\\venv\\lib\\site-packages\\transformers\\modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Loss: 2.5966: 100%|██████████| 197/197 [04:21<00:00,  1.33s/it]\n",
      "c:\\Users\\ej_ja\\anaconda3\\envs\\venv\\lib\\site-packages\\transformers\\modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "Train Loss: 3.0025, Train Acc: 0.0522, Train F1: 0.0462\n",
      "Val Loss: 2.8516, Val Acc: 0.0637, Val F1: 0.0070\n"
     ]
    }
   ],
   "source": [
    "# 각 fold의 결과를 저장할 리스트\n",
    "fold_results = []\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(trn_dataset.df, trn_dataset.df['target'])):\n",
    "    print(f\"Fold {fold+1}/{N_FOLDS}\")\n",
    "    \n",
    "    # 학습 및 검증 데이터셋 생성\n",
    "    train_subset = Subset(trn_dataset, train_idx)\n",
    "    val_subset = Subset(trn_dataset, val_idx)\n",
    "    \n",
    "    # DataLoader 정의\n",
    "    train_loader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # model 및 optimizer 정의\n",
    "    model = LayoutLMv3ForSequenceClassification.from_pretrained(model_name, num_labels=17).to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    # 학습 및 평가 루프\n",
    "    best_val_f1 = 0\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        train_ret = train_one_epoch(train_loader, model, optimizer, loss_fn=None, device=device) # 분류 작업을 위해 이미 loss function이 내장되어 있음(Cross Entropy Loss)\n",
    "        val_ret = validate(val_loader, model, device)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        print(f\"Train Loss: {train_ret['train_loss']:.4f}, Train Acc: {train_ret['train_acc']:.4f}, Train F1: {train_ret['train_f1']:.4f}\")\n",
    "        print(f\"Val Loss: {val_ret['val_loss']:.4f}, Val Acc: {val_ret['val_acc']:.4f}, Val F1: {val_ret['val_f1']:.4f}\")\n",
    "        \n",
    "        if val_ret['val_f1'] > best_val_f1:\n",
    "            best_val_f1 = val_ret['val_f1']\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), f\"best_model_fold{fold+1}.pth\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            \n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    fold_results.append(best_val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 score across 2 folds: 0.0070\n"
     ]
    }
   ],
   "source": [
    "# 전체 fold의 평균 성능 계산\n",
    "mean_f1 = np.mean(fold_results)\n",
    "print(f\"Mean F1 score across {N_FOLDS} folds: {mean_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 테스트 데이터 예측 및 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting fold 1:   0%|          | 0/785 [00:00<?, ?it/s]c:\\Users\\ej_ja\\anaconda3\\envs\\venv\\lib\\site-packages\\transformers\\modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Predicting fold 1: 100%|██████████| 785/785 [11:30<00:00,  1.14it/s]\n",
      "Predicting fold 2: 100%|██████████| 785/785 [11:40<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 대한 예측\n",
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "preds_list = []\n",
    "\n",
    "for fold in range(N_FOLDS):\n",
    "    model.load_state_dict(torch.load(f\"best_model_fold{fold+1}.pth\"))\n",
    "    model.eval()\n",
    "    fold_preds = []\n",
    "    \n",
    "    for batch in tqdm(tst_loader, desc=f\"Predicting fold {fold+1}\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        bbox = batch[\"bbox\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, bbox=bbox)\n",
    "            preds = outputs.logits\n",
    "\n",
    "        fold_preds.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "    \n",
    "    preds_list.append(fold_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902a099124ac488cbabf0a614bfc0ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>█▁</td></tr><tr><td>train_f1</td><td>█▁</td></tr><tr><td>train_loss</td><td>▁█</td></tr><tr><td>val_acc</td><td>▁▁</td></tr><tr><td>val_f1</td><td>▁▁</td></tr><tr><td>val_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.05223</td></tr><tr><td>train_f1</td><td>0.0462</td></tr><tr><td>train_loss</td><td>3.00255</td></tr><tr><td>val_acc</td><td>0.06369</td></tr><tr><td>val_f1</td><td>0.00704</td></tr><tr><td>val_loss</td><td>2.85159</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">layoutlmv3-20240803-213638</strong> at: <a href='https://wandb.ai/alvlalvl/competition2-cv/runs/a49o1vog' target=\"_blank\">https://wandb.ai/alvlalvl/competition2-cv/runs/a49o1vog</a><br/> View project at: <a href='https://wandb.ai/alvlalvl/competition2-cv' target=\"_blank\">https://wandb.ai/alvlalvl/competition2-cv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240803_213638-a49o1vog\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 각 fold의 예측을 평균내어 최종 예측 생성\n",
    "final_preds = np.mean(preds_list, axis=0).round().astype(int)\n",
    "\n",
    "pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = final_preds\n",
    "\n",
    "sample_submission_df = pd.read_csv(f\"{data_path}sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()\n",
    "\n",
    "pred_df.to_csv(\"pred.csv\", index=False)\n",
    "\n",
    "pred_df.head()\n",
    "\n",
    "# wandb 실행 종료\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
